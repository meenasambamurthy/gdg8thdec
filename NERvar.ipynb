{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NERvar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOc2KRyHlYFPBU978hpil5o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/meenasambamurthy/gdg8thdec/blob/master/NERvar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qU6yTw-z6CV",
        "colab_type": "code",
        "outputId": "518297d2-10ed-4394-8b7d-e9f20bdc1382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sentence = \"We are  based out of Bengaluru.\"\n",
        "i = nltk.ne_chunk(nltk.pos_tag(word_tokenize(sentence)), binary=True)\n",
        "[a for a in i if len(a)==1]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Tree('NE', [('Bengaluru', 'NNP')])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIrdmO7W2U5R",
        "colab_type": "code",
        "outputId": "14425f95-50d2-47a4-9616-04ab939eacaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "from spacy import displacy\n",
        "\n",
        "import en_core_web_sm\n",
        "\n",
        "nlp = en_core_web_sm.load()\n",
        "\n",
        "\n",
        "doc = nlp('God helps those who help themselves.')\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0a51167b48da4e35834fec7da1250f5a-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">God</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">helps</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">those</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">who</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">help</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">themselves.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0a51167b48da4e35834fec7da1250f5a-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0a51167b48da4e35834fec7da1250f5a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0a51167b48da4e35834fec7da1250f5a-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0a51167b48da4e35834fec7da1250f5a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0a51167b48da4e35834fec7da1250f5a-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0a51167b48da4e35834fec7da1250f5a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0a51167b48da4e35834fec7da1250f5a-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0a51167b48da4e35834fec7da1250f5a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-0a51167b48da4e35834fec7da1250f5a-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-0a51167b48da4e35834fec7da1250f5a-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQdzdsPBQk2e",
        "colab_type": "code",
        "outputId": "7e06ddc6-b0b2-488c-ea51-440d498ffdf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "doc = nlp('I have flown to LA. Now I am flying to Frisco.')\n",
        "for token in doc:\n",
        "  if token.ent_type != 0:\n",
        "    print(token.text, token.ent_type_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LA GPE\n",
            "Frisco ORG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Ol0gmBcPgh",
        "colab_type": "code",
        "outputId": "47c9eda8-cbc9-42cd-fbf7-31d5391cfa26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(open('sample_doc.html'), 'html.parser')\n",
        "#soup.find('p')\n",
        "soup.find_all('div')\n",
        "#table = soup.find('table')\n",
        "#for row in table.find_all('tr'):\n",
        "    #columns = row.find_all('td')\n",
        "    #print(columns)\n",
        "#table.find_all('tr')[3].find_all('td')[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-fe429baba79e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://devopedia.org/text-summarization'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#soup.find('p')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#table = soup.find('table')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://devopedia.org/text-summarization'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yOlFUzNcy4a",
        "colab_type": "code",
        "outputId": "a29208da-76c4-46ab-aa3d-384e1a5fc598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import requests\n",
        "r = requests.post('https://www.gutenberg.org/files/766/766-0.txt')\n",
        "r.status_code\n",
        "r.text[:1000]\n",
        "#open(\"sample_doc.html\", 'w').write(r.html)\n",
        "open(\"David_Copperfield.txt\", 'w').write(r.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2033139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1EDc3fbgQ-t",
        "colab_type": "code",
        "outputId": "bcb2e795-e654-4554-d541-7d230d18dcc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import requests\n",
        "r = requests.post('https://devopedia.org/text-summarization')\n",
        "r.status_code\n",
        "#r.text[:1000]\n",
        "open(\"sample_doc10.html\", 'w').write(r.text)\n",
        "#open(\"David_Copperfield.txt\", 'w').write(r.text)\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(open('sample_doc10.html'), 'html.parser')\n",
        "#soup.find('p')\n",
        "soup.find_all('div')\n",
        "#table = soup.find('table')\n",
        "#for row in table.find_all('tr'):\n",
        "    #columns = row.find_all('td')\n",
        "    #print(columns)\n",
        "#table.find_all('tr')[3].find_all('td')[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<div class=\"tm-navbar-container \">\n",
              " <nav class=\"tm-navbar uk-navbar\">\n",
              " <div class=\"uk-container uk-container-center\">\n",
              " <div class=\"uk-grid uk-flex-space-between uk-hidden-small\">\n",
              " <div class=\"uk-flex-order-first\">\n",
              " <a class=\"main-logo\" href=\"/\"><img alt=\"logo\" src=\"/images/logo/default.png\"/></a>\n",
              " <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div> </div>\n",
              " <div class=\"menu-search-box uk-flex-item-1\">\n",
              " <div class=\"uk-visible\">\n",
              " <form action=\"/\" class=\"uk-search\" data-uk-search=\"{'source': '/component/search/?tmpl=raw&amp;type=json&amp;ordering=&amp;searchphrase=all', 'param': 'searchword', 'msgResultsHeader': 'Search Results', 'msgMoreResults': 'More Results', 'msgNoResults': 'No results found', flipDropdown: 1}\" id=\"search-96-5ec127cf38b57\" method=\"post\">\n",
              " <input class=\"uk-search-field\" name=\"searchword\" placeholder=\"search...\" type=\"text\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"search\"/>\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_search\"/>\n",
              " <input name=\"Itemid\" type=\"hidden\" value=\"104\"/>\n",
              " </form>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-flex-order-last\">\n",
              " <ul class=\"uk-navbar-nav uk-hidden-small\"><li aria-expanded=\"false\" aria-haspopup=\"true\" class=\"uk-parent\" data-uk-dropdown=\"{'preventflip':'y','pos':'left-top'}\"><a href=\"#\"><i class=\"uk-icon-sitemap uk-icon-large\"></i></a>\n",
              " <div class=\"uk-dropdown uk-dropdown-navbar uk-dropdown-width-1\"><div class=\"uk-grid uk-dropdown-grid\"><div class=\"uk-width-1-1\"><ul class=\"uk-nav uk-nav-navbar\"><li><a href=\"/site-map/dashboard\" rel=\"nofollow\">Dashboard</a></li><li><a href=\"/site-map/browse-articles\" rel=\"nofollow\">Browse Articles</a></li><li><a class=\"menu-line-above\" href=\"/site-map/events\">Events</a></li><li><a class=\"menu-line-above\" href=\"/site-map/about-devopedia\">About Devopedia</a></li><li><a href=\"/site-map/author-guidelines\">Author Guidelines</a></li><li><a href=\"/site-map/site-stats\">Site Stats</a></li><li><a href=\"/site-map/faq-help\" rel=\"nofollow\">FAQ &amp; Help</a></li></ul></div></div></div></li></ul>\n",
              " <ul class=\"uk-navbar-nav uk-hidden-small\">\n",
              " <li class=\"uk-parent\" data-uk-dropdown=\"{pos:'left-top'}\">\n",
              " <a href=\"#\"><i class=\"vflipper uk-icon-sign-in uk-icon-large\"></i></a>\n",
              " <div class=\"uk-dropdown uk-dropdown-navbar\"><div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"menu-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"menu-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"menu-form-login-username\">\n",
              " <label for=\"menu-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-password\">\n",
              " <label for=\"menu-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"menu-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"menu-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\"/>\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\"/>\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>\n",
              " </div>\n",
              " </li>\n",
              " </ul> </div>\n",
              " </div>\n",
              " <div class=\"uk-flex uk-flex-middle uk-flex-space-between uk-visible-small\">\n",
              " <div id=\"logo-name-small\">\n",
              " <a class=\"main-logo\" href=\"/\"><img alt=\"logo\" src=\"/images/logo/default.png\"/></a>\n",
              " <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div></div>\n",
              " <a class=\"uk-navbar-toggle uk-visible-small\" data-uk-offcanvas=\"\" href=\"#offcanvas\"></a>\n",
              " </div>\n",
              " </div>\n",
              " </nav>\n",
              " </div>, <div class=\"uk-container uk-container-center\">\n",
              " <div class=\"uk-grid uk-flex-space-between uk-hidden-small\">\n",
              " <div class=\"uk-flex-order-first\">\n",
              " <a class=\"main-logo\" href=\"/\"><img alt=\"logo\" src=\"/images/logo/default.png\"/></a>\n",
              " <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div> </div>\n",
              " <div class=\"menu-search-box uk-flex-item-1\">\n",
              " <div class=\"uk-visible\">\n",
              " <form action=\"/\" class=\"uk-search\" data-uk-search=\"{'source': '/component/search/?tmpl=raw&amp;type=json&amp;ordering=&amp;searchphrase=all', 'param': 'searchword', 'msgResultsHeader': 'Search Results', 'msgMoreResults': 'More Results', 'msgNoResults': 'No results found', flipDropdown: 1}\" id=\"search-96-5ec127cf38b57\" method=\"post\">\n",
              " <input class=\"uk-search-field\" name=\"searchword\" placeholder=\"search...\" type=\"text\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"search\"/>\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_search\"/>\n",
              " <input name=\"Itemid\" type=\"hidden\" value=\"104\"/>\n",
              " </form>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-flex-order-last\">\n",
              " <ul class=\"uk-navbar-nav uk-hidden-small\"><li aria-expanded=\"false\" aria-haspopup=\"true\" class=\"uk-parent\" data-uk-dropdown=\"{'preventflip':'y','pos':'left-top'}\"><a href=\"#\"><i class=\"uk-icon-sitemap uk-icon-large\"></i></a>\n",
              " <div class=\"uk-dropdown uk-dropdown-navbar uk-dropdown-width-1\"><div class=\"uk-grid uk-dropdown-grid\"><div class=\"uk-width-1-1\"><ul class=\"uk-nav uk-nav-navbar\"><li><a href=\"/site-map/dashboard\" rel=\"nofollow\">Dashboard</a></li><li><a href=\"/site-map/browse-articles\" rel=\"nofollow\">Browse Articles</a></li><li><a class=\"menu-line-above\" href=\"/site-map/events\">Events</a></li><li><a class=\"menu-line-above\" href=\"/site-map/about-devopedia\">About Devopedia</a></li><li><a href=\"/site-map/author-guidelines\">Author Guidelines</a></li><li><a href=\"/site-map/site-stats\">Site Stats</a></li><li><a href=\"/site-map/faq-help\" rel=\"nofollow\">FAQ &amp; Help</a></li></ul></div></div></div></li></ul>\n",
              " <ul class=\"uk-navbar-nav uk-hidden-small\">\n",
              " <li class=\"uk-parent\" data-uk-dropdown=\"{pos:'left-top'}\">\n",
              " <a href=\"#\"><i class=\"vflipper uk-icon-sign-in uk-icon-large\"></i></a>\n",
              " <div class=\"uk-dropdown uk-dropdown-navbar\"><div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"menu-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"menu-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"menu-form-login-username\">\n",
              " <label for=\"menu-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-password\">\n",
              " <label for=\"menu-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"menu-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"menu-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\"/>\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\"/>\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>\n",
              " </div>\n",
              " </li>\n",
              " </ul> </div>\n",
              " </div>\n",
              " <div class=\"uk-flex uk-flex-middle uk-flex-space-between uk-visible-small\">\n",
              " <div id=\"logo-name-small\">\n",
              " <a class=\"main-logo\" href=\"/\"><img alt=\"logo\" src=\"/images/logo/default.png\"/></a>\n",
              " <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div></div>\n",
              " <a class=\"uk-navbar-toggle uk-visible-small\" data-uk-offcanvas=\"\" href=\"#offcanvas\"></a>\n",
              " </div>\n",
              " </div>, <div class=\"uk-grid uk-flex-space-between uk-hidden-small\">\n",
              " <div class=\"uk-flex-order-first\">\n",
              " <a class=\"main-logo\" href=\"/\"><img alt=\"logo\" src=\"/images/logo/default.png\"/></a>\n",
              " <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div> </div>\n",
              " <div class=\"menu-search-box uk-flex-item-1\">\n",
              " <div class=\"uk-visible\">\n",
              " <form action=\"/\" class=\"uk-search\" data-uk-search=\"{'source': '/component/search/?tmpl=raw&amp;type=json&amp;ordering=&amp;searchphrase=all', 'param': 'searchword', 'msgResultsHeader': 'Search Results', 'msgMoreResults': 'More Results', 'msgNoResults': 'No results found', flipDropdown: 1}\" id=\"search-96-5ec127cf38b57\" method=\"post\">\n",
              " <input class=\"uk-search-field\" name=\"searchword\" placeholder=\"search...\" type=\"text\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"search\"/>\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_search\"/>\n",
              " <input name=\"Itemid\" type=\"hidden\" value=\"104\"/>\n",
              " </form>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-flex-order-last\">\n",
              " <ul class=\"uk-navbar-nav uk-hidden-small\"><li aria-expanded=\"false\" aria-haspopup=\"true\" class=\"uk-parent\" data-uk-dropdown=\"{'preventflip':'y','pos':'left-top'}\"><a href=\"#\"><i class=\"uk-icon-sitemap uk-icon-large\"></i></a>\n",
              " <div class=\"uk-dropdown uk-dropdown-navbar uk-dropdown-width-1\"><div class=\"uk-grid uk-dropdown-grid\"><div class=\"uk-width-1-1\"><ul class=\"uk-nav uk-nav-navbar\"><li><a href=\"/site-map/dashboard\" rel=\"nofollow\">Dashboard</a></li><li><a href=\"/site-map/browse-articles\" rel=\"nofollow\">Browse Articles</a></li><li><a class=\"menu-line-above\" href=\"/site-map/events\">Events</a></li><li><a class=\"menu-line-above\" href=\"/site-map/about-devopedia\">About Devopedia</a></li><li><a href=\"/site-map/author-guidelines\">Author Guidelines</a></li><li><a href=\"/site-map/site-stats\">Site Stats</a></li><li><a href=\"/site-map/faq-help\" rel=\"nofollow\">FAQ &amp; Help</a></li></ul></div></div></div></li></ul>\n",
              " <ul class=\"uk-navbar-nav uk-hidden-small\">\n",
              " <li class=\"uk-parent\" data-uk-dropdown=\"{pos:'left-top'}\">\n",
              " <a href=\"#\"><i class=\"vflipper uk-icon-sign-in uk-icon-large\"></i></a>\n",
              " <div class=\"uk-dropdown uk-dropdown-navbar\"><div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"menu-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"menu-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"menu-form-login-username\">\n",
              " <label for=\"menu-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-password\">\n",
              " <label for=\"menu-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"menu-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"menu-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\"/>\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\"/>\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>\n",
              " </div>\n",
              " </li>\n",
              " </ul> </div>\n",
              " </div>, <div class=\"uk-flex-order-first\">\n",
              " <a class=\"main-logo\" href=\"/\"><img alt=\"logo\" src=\"/images/logo/default.png\"/></a>\n",
              " <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div> </div>, <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div>, <div class=\"trademark\"><sup>TM</sup></div>, <div class=\"main-tagline\">for developers. by developers.</div>, <div class=\"menu-search-box uk-flex-item-1\">\n",
              " <div class=\"uk-visible\">\n",
              " <form action=\"/\" class=\"uk-search\" data-uk-search=\"{'source': '/component/search/?tmpl=raw&amp;type=json&amp;ordering=&amp;searchphrase=all', 'param': 'searchword', 'msgResultsHeader': 'Search Results', 'msgMoreResults': 'More Results', 'msgNoResults': 'No results found', flipDropdown: 1}\" id=\"search-96-5ec127cf38b57\" method=\"post\">\n",
              " <input class=\"uk-search-field\" name=\"searchword\" placeholder=\"search...\" type=\"text\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"search\"/>\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_search\"/>\n",
              " <input name=\"Itemid\" type=\"hidden\" value=\"104\"/>\n",
              " </form>\n",
              " </div>\n",
              " </div>, <div class=\"uk-visible\">\n",
              " <form action=\"/\" class=\"uk-search\" data-uk-search=\"{'source': '/component/search/?tmpl=raw&amp;type=json&amp;ordering=&amp;searchphrase=all', 'param': 'searchword', 'msgResultsHeader': 'Search Results', 'msgMoreResults': 'More Results', 'msgNoResults': 'No results found', flipDropdown: 1}\" id=\"search-96-5ec127cf38b57\" method=\"post\">\n",
              " <input class=\"uk-search-field\" name=\"searchword\" placeholder=\"search...\" type=\"text\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"search\"/>\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_search\"/>\n",
              " <input name=\"Itemid\" type=\"hidden\" value=\"104\"/>\n",
              " </form>\n",
              " </div>, <div class=\"uk-flex-order-last\">\n",
              " <ul class=\"uk-navbar-nav uk-hidden-small\"><li aria-expanded=\"false\" aria-haspopup=\"true\" class=\"uk-parent\" data-uk-dropdown=\"{'preventflip':'y','pos':'left-top'}\"><a href=\"#\"><i class=\"uk-icon-sitemap uk-icon-large\"></i></a>\n",
              " <div class=\"uk-dropdown uk-dropdown-navbar uk-dropdown-width-1\"><div class=\"uk-grid uk-dropdown-grid\"><div class=\"uk-width-1-1\"><ul class=\"uk-nav uk-nav-navbar\"><li><a href=\"/site-map/dashboard\" rel=\"nofollow\">Dashboard</a></li><li><a href=\"/site-map/browse-articles\" rel=\"nofollow\">Browse Articles</a></li><li><a class=\"menu-line-above\" href=\"/site-map/events\">Events</a></li><li><a class=\"menu-line-above\" href=\"/site-map/about-devopedia\">About Devopedia</a></li><li><a href=\"/site-map/author-guidelines\">Author Guidelines</a></li><li><a href=\"/site-map/site-stats\">Site Stats</a></li><li><a href=\"/site-map/faq-help\" rel=\"nofollow\">FAQ &amp; Help</a></li></ul></div></div></div></li></ul>\n",
              " <ul class=\"uk-navbar-nav uk-hidden-small\">\n",
              " <li class=\"uk-parent\" data-uk-dropdown=\"{pos:'left-top'}\">\n",
              " <a href=\"#\"><i class=\"vflipper uk-icon-sign-in uk-icon-large\"></i></a>\n",
              " <div class=\"uk-dropdown uk-dropdown-navbar\"><div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"menu-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"menu-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"menu-form-login-username\">\n",
              " <label for=\"menu-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-password\">\n",
              " <label for=\"menu-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"menu-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"menu-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\"/>\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\"/>\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>\n",
              " </div>\n",
              " </li>\n",
              " </ul> </div>, <div class=\"uk-dropdown uk-dropdown-navbar uk-dropdown-width-1\"><div class=\"uk-grid uk-dropdown-grid\"><div class=\"uk-width-1-1\"><ul class=\"uk-nav uk-nav-navbar\"><li><a href=\"/site-map/dashboard\" rel=\"nofollow\">Dashboard</a></li><li><a href=\"/site-map/browse-articles\" rel=\"nofollow\">Browse Articles</a></li><li><a class=\"menu-line-above\" href=\"/site-map/events\">Events</a></li><li><a class=\"menu-line-above\" href=\"/site-map/about-devopedia\">About Devopedia</a></li><li><a href=\"/site-map/author-guidelines\">Author Guidelines</a></li><li><a href=\"/site-map/site-stats\">Site Stats</a></li><li><a href=\"/site-map/faq-help\" rel=\"nofollow\">FAQ &amp; Help</a></li></ul></div></div></div>, <div class=\"uk-grid uk-dropdown-grid\"><div class=\"uk-width-1-1\"><ul class=\"uk-nav uk-nav-navbar\"><li><a href=\"/site-map/dashboard\" rel=\"nofollow\">Dashboard</a></li><li><a href=\"/site-map/browse-articles\" rel=\"nofollow\">Browse Articles</a></li><li><a class=\"menu-line-above\" href=\"/site-map/events\">Events</a></li><li><a class=\"menu-line-above\" href=\"/site-map/about-devopedia\">About Devopedia</a></li><li><a href=\"/site-map/author-guidelines\">Author Guidelines</a></li><li><a href=\"/site-map/site-stats\">Site Stats</a></li><li><a href=\"/site-map/faq-help\" rel=\"nofollow\">FAQ &amp; Help</a></li></ul></div></div>, <div class=\"uk-width-1-1\"><ul class=\"uk-nav uk-nav-navbar\"><li><a href=\"/site-map/dashboard\" rel=\"nofollow\">Dashboard</a></li><li><a href=\"/site-map/browse-articles\" rel=\"nofollow\">Browse Articles</a></li><li><a class=\"menu-line-above\" href=\"/site-map/events\">Events</a></li><li><a class=\"menu-line-above\" href=\"/site-map/about-devopedia\">About Devopedia</a></li><li><a href=\"/site-map/author-guidelines\">Author Guidelines</a></li><li><a href=\"/site-map/site-stats\">Site Stats</a></li><li><a href=\"/site-map/faq-help\" rel=\"nofollow\">FAQ &amp; Help</a></li></ul></div>, <div class=\"uk-dropdown uk-dropdown-navbar\"><div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"menu-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"menu-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"menu-form-login-username\">\n",
              " <label for=\"menu-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-password\">\n",
              " <label for=\"menu-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"menu-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"menu-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\"/>\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\"/>\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>\n",
              " </div>, <div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"menu-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"menu-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"menu-form-login-username\">\n",
              " <label for=\"menu-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-password\">\n",
              " <label for=\"menu-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"menu-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"menu-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"menu-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"menu-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\"/>\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\"/>\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>, <div class=\"slogin-buttons slogin-compact\" id=\"menu-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>, <div class=\"slogin-clear\"></div>, <div class=\"slogin-clear\"></div>, <div class=\"uk-flex uk-flex-middle uk-flex-space-between uk-visible-small\">\n",
              " <div id=\"logo-name-small\">\n",
              " <a class=\"main-logo\" href=\"/\"><img alt=\"logo\" src=\"/images/logo/default.png\"/></a>\n",
              " <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div></div>\n",
              " <a class=\"uk-navbar-toggle uk-visible-small\" data-uk-offcanvas=\"\" href=\"#offcanvas\"></a>\n",
              " </div>, <div id=\"logo-name-small\">\n",
              " <a class=\"main-logo\" href=\"/\"><img alt=\"logo\" src=\"/images/logo/default.png\"/></a>\n",
              " <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div></div>, <div class=\"main-logo-text\">\n",
              " <a href=\"/\">DEVOPEDIA</a>\n",
              " <div class=\"trademark\"><sup>TM</sup></div>\n",
              " <div class=\"main-tagline\">for developers. by developers.</div>\n",
              " </div>, <div class=\"trademark\"><sup>TM</sup></div>, <div class=\"main-tagline\">for developers. by developers.</div>, <div class=\"tm-block-main uk-block uk-block-default tm-block-small\" id=\"tm-main\">\n",
              " <div class=\"uk-container uk-container-center\">\n",
              " <div class=\"tm-main uk-grid uk-position-relative\" data-uk-grid-margin=\"\" data-uk-grid-match=\"\">\n",
              " <div class=\"tm-main uk-width-medium-1-1 uk-flex-order-last\">\n",
              " <main class=\"tm-content\" id=\"tm-content\">\n",
              " <div id=\"system-message-container\">\n",
              " </div>\n",
              " <div id=\"base-url\" style=\"display:none\"></div><input id=\"token-for-diff\" name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> <a class=\"outer-close-icon\" style=\"display:none\"><i class=\"uk-icon-close\"></i></a>\n",
              " <div class=\"uk-modal\" id=\"diff-draft-modal\"></div>\n",
              " <div class=\"pull-right\">\n",
              " <nav class=\"article-hover-links\" data-aid=\"261\" data-ispub=\"\">\n",
              " <span class=\"article-page-like\" data-vid=\"0\">\n",
              " <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Like this page\"></i><br/>\n",
              " </span>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-share\" id=\"offcanvas-share-link\"><i class=\"uk-icon-justify uk-icon-share-alt\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Share article\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-share\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <div class=\"a2a_kit a2a_kit_size_32 a2a_default_style\">\n",
              " <a class=\"a2a_button_facebook\"></a>\n",
              " <a class=\"a2a_button_twitter\"></a>\n",
              " <a class=\"a2a_button_linkedin\"></a>\n",
              " <a class=\"a2a_button_reddit\"></a>\n",
              " <a class=\"a2a_button_whatsapp\"></a>\n",
              " <a class=\"a2a_button_email\"></a>\n",
              " </div>\n",
              " <script>\n",
              "                         var a2a_config = a2a_config || {};\n",
              "                         a2a_config.onclick = 1;\n",
              "                     </script>\n",
              " <script async=\"\" src=\"https://static.addtoany.com/menu/page.js\"></script>\n",
              " </div>\n",
              " </div>\n",
              " <i class=\"uk-icon-justify article-showhide-links uk-icon-unlink\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Toggle hyperlinks\"></i><br/>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-compare\" id=\"offcanvas-compare-link\"><i class=\"uk-icon-justify uk-icon-files-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Compare versions\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-compare\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Article Versions</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-hover-versions\">\n",
              " <li class=\" \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">2</span> <span class=\"user-datetime\">2020-02-21 17:22:09</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1977\"><i class=\"icon-blank uk-icon-justify\"></i><a class=\"diff-versions uk-icon-justify uk-icon-exchange\" data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" href=\"#diff-modal\" title=\"Diff with\n",
              " previous\"><span class=\"hidden-ids\">1977,1975</span></a> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  Content done. Images added. Publishing.<br/></li><li class=\"last-one \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">1</span> <span class=\"user-datetime\">2020-02-20 06:53:06</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1975\"><i class=\"uk-icon-justify uk-icon-eye-slash\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Unpublished\n",
              " version\"></i> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  First version, no content yet.<br/></li> </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-versions\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older versions\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-modal\" id=\"diff-modal\"></div>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-chatroom\" id=\"offcanvas-chatroom-link\"><i class=\"uk-icon-justify uk-icon-comments-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Discuss this page\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-chatroom\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Chat Room</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-chat-msgs\">\n",
              " <li>\n",
              " <div id=\"chat-save-error\"></div>\n",
              " <div class=\"savenewmsg pull-right\" style=\"display:none\">Submitting ...</div>\n",
              " <div class=\"uk-alert uk-alert-warning\" id=\"chat-edit-desc\" style=\"display:none\">You are editing an existing chat message.</div>\n",
              " <form id=\"chat-form\">\n",
              " <input id=\"savedVersion\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"savedSection\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"chatid\" type=\"hidden\" value=\"0\"/>\n",
              " <select id=\"chat-article-version\" name=\"version\">\n",
              " <option selected=\"selected\" value=\"0\">All Versions</option><option class=\"user-datetime\" value=\"1977\">2020-02-21 17:22:09 by arvindpdmn</option><option class=\"user-datetime\" value=\"1975\">2020-02-20 06:53:06 by arvindpdmn</option> </select>\n",
              " <select id=\"chat-article-section\" name=\"section\">\n",
              " <option selected=\"selected\" value=\"All Sections\">All Sections</option><option value=\"Summary\">Summary</option><option value=\"Discussion\">Discussion</option><option value=\"Sample Code\">Sample Code</option><option value=\"References\">References</option><option value=\"Milestones\">Milestones</option><option value=\"Tags\">Tags</option><option value=\"See Also\">See Also</option><option value=\"Further Reading\">Further Reading</option> </select>\n",
              " </form>\n",
              " </li>\n",
              " </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-msgs\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older messages\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " </nav>\n",
              " </div>\n",
              " <div class=\"uk-modal\" id=\"image-slideshow\"> <div class=\"image-slideshow uk-modal-dialog\"><a class=\"uk-modal-close uk-close\"></a><a href=\"/\"></a> <i class=\"uk-icon uk-icon-chevron-left pull-left\" id=\"prev-img\"></i> <i class=\"uk-icon uk-icon-chevron-right pull-right\" id=\"next-img\"></i> <ul id=\"inner-slides\"><li id=\"slide-0\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/></div></li><li id=\"slide-1\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/></div></li><li id=\"slide-2\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/></div></li><li id=\"slide-3\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/></div></li><li id=\"slide-4\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Multi-document graph. Source: Radev 2000, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/></div></li><li id=\"slide-5\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/></div></li><li id=\"slide-6\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/></div></li><li id=\"slide-7\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/></div></li><li id=\"slide-8\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Architecture of BERTSUM. Source: Liu 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/></div></li><li id=\"slide-9\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/></div></li><li id=\"slide-10\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/></div></li><li id=\"slide-11\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/></div></li><li id=\"slide-12\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/></div></li><li id=\"slide-13\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/></div></li><li id=\"slide-14\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/></div></li> </ul> </div></div>\n",
              " <article class=\"uk-article tm-blog-single \">\n",
              " <h1 class=\"uk-article-title\">\n",
              " \t\t\t\t\tText Summarization\t\t\t</h1>\n",
              " <div class=\"uk-grid article-top-authors\" data-uk-grid-margin=\"\"><div class=\"uk-width-medium-3-5\"><div class=\"uk-grid star-contribs\"><div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><br/><a href=\"/user/arvindpdmn\">arvindpdmn</a><br/>1638 DevCoins</div></div></div><div class=\"uk-width-medium-2-5\"><a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">1 author has contributed to this article</a><br/>Last updated by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-21 17:22:09</span><br/>Created by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-20 06:53:06</span></div></div><div class=\"uk-grid\" data-uk-grid-margin=\"\"><div class=\"article-left uk-width-medium-3-5\"><h2 class=\"topper\">Summary</h2>\n",
              " <div id=\"summary-text-wrapper\"><div id=\"summary-text\"><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-0\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/><div class=\"uk-thumbnail-caption\">Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>On the web, everyone can be a publisher. We're already seeing vast amounts of information being published daily in the form of restaurant/movie/book reviews, blogs, status updates, and more. In addition, traditional print publications (newspapers, magazines, technical journals, whitepapers) are also available online. It's impossible for anyone to keep track of recent publications even if limited to one domain. This is where text summarization can help.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup>\n",
              " </p>\n",
              " <p>A summary, created automatically by algorithms, typically contains the most important information. The summary should be mindful of the reader and the communication goals. It may also help the reader decide if the original text is worth reading in full. The summary can also help improve document indexing for information retrieval. An automated summary is often less biased than a human-written summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> </p></div></div><h2 class=\"sec-milestones-small\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones-small\" id=\"cd-timeline-small\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Discussion</h2>\n",
              " <ul class=\"uk-list uk-list-space article-discussion-list\"><li><article-question>What are some real-world applications of text summarization?</article-question>\n",
              " <article-answer><p>Here are some everyday examples of text summarization: news headlines, outlines for students, movie previews, meeting minutes, biographies for resumes or obituaries, abridged versions of books,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> newsletter production, financial research, patent research, legal contract analysis, tweeting about new content, chatbots that answer questions, email summaries, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>When Google Search presents search results, some entries are accompanied by auto-generated summaries. Google may be leveraging a knowledge graph for this purpose. Google's approach to summarization is mainly entity centric. Summarization extends to timelines and events about entities.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-2017\" title=\"Li 2017\"></a></sup> </p>\n",
              " <p>Doctors write long medical notes containing nutritional information for pregnant mothers. When these were reduced to short crisp summaries, pregnant mothers found them a lot easier to understand.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#i2-Decisions-2019\" title=\"i2 Decisions 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Which are the main approaches to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-9\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/><div class=\"uk-thumbnail-caption\">Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>With <strong>extractive summarization</strong>, summary contains sentences picked and reproduced verbatim from the original text. With <strong>abstractive summarization</strong>, the algorithm interprets the text and generates a summary, possibly using new phrases and sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>Extractive summarization is data-driven, easier and often gives better results. Abstractive summarization is how humans tend to summarize text but it's hard for algorithms since it involves semantic representation, inference and natural language generation. Often abstractive summarization relies on text extracts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> </p>\n",
              " <p>For extraction, sentences are scored and those with highest scores are selected. Scoring criteria may include word frequencies, location heuristics, sentence similarity, rhetorical relations, and semantic roles.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995, sec. 2\"></a></sup> </p>\n",
              " <p>Typically an intermediate representation is used to select relevant summary content. With <strong>topic representation</strong>, the intent is to identify the main topics in the text. Topic words, word frequencies (including <abbr data-title=\"» Term Frequency Inverse Document Frequency\">TF-IDF</abbr>), clustering, <abbr data-title=\"» Latent Semantic Analysis\">LSA</abbr> and <abbr data-title=\"» Latent Dirichlet Allocation\">LDA</abbr> have been applied to summarization. With <strong>indicator representation</strong>, a feature set is used to rank and select sentences. Examples of this approach are graph-based methods and machine learning.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>What are the challenges and requirements of multi-document summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-10\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/><div class=\"uk-thumbnail-caption\">Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The pipeline for multi-document summarization (<abbr data-title=\"» Multi Document Summarization\">MDS</abbr>) has the same basic steps as for single-document summarization (<abbr data-title=\"» Single Document Summarization\">SDS</abbr>): content selection, information ordering, and sentence realization. However, <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> has some unique challenges:<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 1\"></a></sup> <ul class=\"list-in-ans\"><li><strong>Redundancy</strong>: A single document has far less redundancy than a topically-related group of documents. Summary shouldn't repeat similar sentences. <em>Maximal Marginal Relevance (<abbr data-title=\"» Maximal Marginal Relevance\">MMR</abbr>)</em> is a scoring system to penalize similar sentences.</li><li><strong>Temporal Ordering</strong>: A stream of news articles might be reporting the unfolding of an event. Summary should order them correctly and be sensitive to later developments overriding earlier ones.</li><li><strong>Cohesion and Coreference</strong>: Both are important for information ordering. Sometimes cohesion might demand a certain ordering but cause coreference problems, such as a person's shortened name appearing before the full name.</li><li><strong>Compression Ratio</strong>: Summarization becomes more difficult when more compression is demanded.</li></ul>\n",
              " <p><abbr data-title=\"» Multi Document Summarization\">MDS</abbr> may cluster similar documents and passages. Summary should include sufficient context and right level of detail. Factual inconsistencies across documents can be reported. Finally, users must be allowed to filter out irrelevant content, dig deeper into the the sources via attribution, or compare related passages across documents.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 3\"></a></sup> </p></p></article-answer></li>\n",
              " <li><article-question>How does text summarization vary across domains or contexts?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-11\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/><div class=\"uk-thumbnail-caption\">IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Summarization must tune its output to each domain or context. For example, summarization of a news article would involve different considerations from that of a corporate sales report.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>General text summarization techniques might not do well for specific domains. Summarizers therefore might wish to use domain-specific knowledge. For legal document summarization, <em>CaseSummarizer</em> is a tool.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Polsley-et-al.-2016\" title=\"Polsley et al. 2016\"></a></sup> In biomedical domain, summaries are created of literature, treatments, drug information, clinical notes, health records, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Moradi-and-Ghadiri-2019\" title=\"Moradi and Ghadiri 2019\"></a></sup> </p>\n",
              " <p>Summarizing scientific literature is a challenge due to length, complexity, and structure (tables and figures). <em>IBM Science Summarizer</em> is a tool that IBM created to summarize computer science publications. It extracts domain-specific entities of types task, dataset and metric.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019\"></a></sup> </p>\n",
              " <p>Often there are extra clues about what might be important in a document. Summarization can use these for content selection. For example, comments and discussions on a blog post point to interesting content segments. Likewise, citations in scientific papers are useful pointers. For web summarization, it's possible to look at other pages linking to a particular page and determine the most suitable sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 5\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How has machine learning been applied to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-12\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/><div class=\"uk-thumbnail-caption\">Some features used by an <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The common <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> approach is to view text summarization as a classification problem. Algorithm is trained in a supervised manner on original text, an extractive summary and a set of features. Algorithm learns to classify sentences as either summary sentences or non-summary sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p>\n",
              " <p>Classifiers could be based on naive-Bayes, decision trees, <abbr data-title=\"» Support Vector Machines\">SVM</abbr>, <abbr data-title=\"» Hidden Markov Model\">HMM</abbr>, and <abbr data-title=\"» Conditional Random Field\">CRF</abbr>. Often each sentence is classified independently of others. However, since <abbr data-title=\"» Hidden Markov Model\">HMM</abbr> and <abbr data-title=\"» Conditional Random Field\">CRF</abbr> capture dependencies, they outperform other techniques.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 2.2\"></a></sup> </p>\n",
              " <p>The problem with supervised algorithms is in creating labelled data for training. This problem is worse for <abbr data-title=\"» Multi Document Summarization\">MDS</abbr>.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> In a semi-supervised approach, a small amount of labelled data is used along with much larger amount of unlabelled data. The algorithm learns iteratively by classifying some unlabelled data in each iteration.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Could you describe neural network architectures for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-13\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/><div class=\"uk-thumbnail-caption\">Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The typical approach is to do <strong>sequence-to-sequence modelling</strong> since input is a sequence of words and the summary is also a sequence of words. In an encoder-decoder architecture, the encoder uses <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> to give an input representation. The decoder is also an <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> that generates the output sequence. An attention layer between the encoder and the decoder helps in determining the most relevant words for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pawar-2018\" title=\"Pawar 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pai-2019\" title=\"Pai 2019\"></a></sup> </p>\n",
              " <p>Seq2seq models, <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr>s and attention layers have made abstractive summarization possible, even if they're not yet state-of-the-art compared to extractive summarization methods. These models are trained <strong>end-to-end</strong> without bothering to model each step of a traditional summarization pipeline. They also don't need access to specialized vocabulary or do pre-processing.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> This end-to-end approach has been applied successfully to short output sequences, such as news headlines or short email responses.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>In a <strong>pointer-generator</strong> network, a generator provides new words whereas a pointer copies words from source text. Seq2seq models often produce repetitive sentences. A <strong>coverage model</strong> avoids repetitions.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017\"></a></sup> </p>\n",
              " <p>Fernandes et al. showed that sequence encoders with a graph component does better at capturing long-distance relationships.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fernandes-et-al.-2019\" title=\"Fernandes et al. 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How do I evaluate text summarization algorithms?</article-question>\n",
              " <article-answer><p>Human evaluation is the simplest. In 2004, <strong>Recall-Oriented Understudy for Gisting Evaluation (ROUGE)</strong> was created to automate evaluation by comparing against hand-crafted summaries. ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S, and ROUGE-SU are some metrics in this family.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 5.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p>\n",
              " <p>Different people produce different summaries of the same text. Meaning shared across different human summaries is called Summary Content Unit (<abbr data-title=\"» Summary Content Unit\">SCU</abbr>). With a focus on meaning, <strong>Pyramid Method</strong> evaluates a summary using <abbr data-title=\"» Summary Content Unit\">SCU</abbr>s.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.6\"></a></sup> </p>\n",
              " <p>While there's no universal system of metrics, text summarizers are typically evaluated based on TREC, DUC and <abbr data-title=\"» Message Understanding Conference\">MUC</abbr> systems.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 1\"></a></sup> DUC (2001-2007) became a summarization track in TAC (2008-).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#DUC-2014\" title=\"DUC 2014\"></a></sup> </p>\n",
              " <p>Datasets for supervised training of <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> algorithms are not common. For summarizing a single or a few documents, commonly used datasets are Gigaword,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail, TAC (2008-2011) and DUC (2003-2004).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> ELI5 and WikiSum can be used for longform question answering and <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> respectively.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, sec. 5.1\"></a></sup> <a class=\"article-link\" href=\"http://kavita-ganesan.com/opinosis-opinion-dataset\" rel=\"nofollow\">Opinosis</a> is a dataset of 51 article-summary pairs.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Released in 2018, <a class=\"article-link\" href=\"https://summari.es/\" rel=\"nofollow\">Cornell Newsroom</a> is the largest dataset for training and evaluating summarization systems. Spanning 1998-2017 and containing 1.3 million articles, it's been collected from newsrooms of 38 major publications. Summaries are obtained from search and social metadata.</p></article-answer></li>\n",
              " <li><article-question>What are some useful resources for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-14\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/><div class=\"uk-thumbnail-caption\">MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Pengfei Liu has curated a <a class=\"article-link\" href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">useful list</a> of datasets, research papers, and groups researching on text summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2020\" title=\"Liu 2020\"></a></sup> </p>\n",
              " <p>In Python, Gensim has a module for text summarization, which implements <em>TextRank</em> algorithm. An original implementation of the same algorithm is available as PyTextRank package. PyTeaser is a Python implementation of Scala's TextTeaser.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Back in 2016, Google released a baseline TensorFlow implementation for summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p></article-answer></li></ul><h2>References<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-citations\"><li id=\"Allahyari-et-al.-2017\"><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Barzilay-and-Lee-2004\"><a href=\"https://www.aclweb.org/anthology/N04-1015/\" rel=\"nofollow\">Barzilay, Regina, and Lillian Lee. 2004. \"Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization.\" Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004, pp. 113-120, May. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Brownlee-2017\"><a href=\"https://machinelearningmastery.com/gentle-introduction-text-summarization/\" rel=\"nofollow\">Brownlee, Jason. 2017. \"A Gentle Introduction to Text Summarization.\" Machine Learning Mastery, August 7. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Chauhan-2018\"><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"DUC-2014\"><a href=\"https://duc.nist.gov/\" rel=\"nofollow\">DUC. 2014. \"Document Understanding Conferences: Homepage.\" NIST, September 9. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Das-and-Martins-2007\"><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Edmundson-1969\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/edmonson69.pdf\" rel=\"nofollow\">Edmundson, H. P. 1969. \"New Methods in Automatic Extracting.\" Journal of the ACM, vol. 16, no. 2, pp. 264-285, April. doi:10.1145/321510.321519. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Erera-et-al.-2019\"><a href=\"https://www.aclweb.org/anthology/D19-3036/\" rel=\"nofollow\">Erera, Shai, Michal Shmueli-Scheuer, Guy Feigenblat, Ora Peled Nakash, Odellia Boni, Haggai Roitman, Doron Cohen, Bar Weiner, Yosi Mass, Or Rivlin, Guy Lev, Achiya Jerbi, Jonathan Herzig, Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin, Francesca Bonin, and David Konopnicki. 2019. \"A Summarization System for Scientific Documents.\" Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 211-216, November. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fan-et-al.-2019\"><a href=\"https://arxiv.org/abs/1910.08435\" rel=\"nofollow\">Fan, Angela, Claire Gardent, Chloe Braud, and Antoine Bordes. 2019. \"Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs.\" arXiv, v1, October 18. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fernandes-et-al.-2019\"><a href=\"https://arxiv.org/abs/1811.01824\" rel=\"nofollow\">Fernandes, Patrick, Miltiadis Allamanis, and Marc Brockschmidt. 2019. \"Structured Neural Summarization.\" arXiv, v2, February 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Goldstein-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0405/\" rel=\"nofollow\">Goldstein, Jade, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. \"Multi-Document Summarization By Sentence Extraction.\" NAACL-ANLP 2000 Workshop: Automatic Summarization. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Jurafsky-and-Martin-2009\"><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel, and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kumar-et-al.-2016\"><a href=\"https://thescipub.com/PDF/jcssp.2016.178.190.pdf\" rel=\"nofollow\">Kumar, Yogan Jaya, Ong Sing Goh, Halizah Basiron, Ngo Hea Choon, and Puspalata C Suppiah. 2016. \"A Review on Automatic Text Summarization Approaches.\" J. of Comp. Sci., Science Publications, April 29. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kupiec-et-al.-1995\"><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.7100&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">Kupiec, Julian, Jan Pedersen, and Francine Chen. 1995. \"A trainable document summarizer.\" SIGIR '95: Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 68-73, July. doi:10.1145/215206.215333. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Lebanoff-et-al.-2018\"><a href=\"https://arxiv.org/abs/1808.06218\" rel=\"nofollow\">Lebanoff, Logan, Kaiqiang Song, and Fei Liu. 2018. \"Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization.\" arXiv, v2, August 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-2017\"><a href=\"https://medium.com/@wenchen.li/text-summarization-applications-ed319f0bb13c\" rel=\"nofollow\">Li, Wenchen. 2017. \"Text summarization: applications.\" Medium, May 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-et-al.-2006\"><a href=\"https://www.aclweb.org/anthology/P06-1047/\" rel=\"nofollow\">Li, Wenjie, Mingli Wu, Qin Lu, Wei Xu, and Chunfa Yuan. 2006. \"Extractive Summarization using Inter- and Intra- Event Relevance.\" Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pp. 369-376, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2019\"><a href=\"https://arxiv.org/abs/1903.10318\" rel=\"nofollow\">Liu, Yang. 2019. \"Fine-tune BERT for Extractive Summarization.\" arXiv, v2, September 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2020\"><a href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">Liu, Pengfei. 2020. \"Modern History for Text Summarization.\" NLP Historiograpy. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-and-Pan-2016\"><a href=\"https://ai.googleblog.com/2016/08/text-summarization-with-tensorflow.html\" rel=\"nofollow\">Liu, Peter, and Xin Pan. 2016. \"Text summarization with TensorFlow.\" Google AI Blog, August 24. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-et-al.-2018\"><a href=\"https://arxiv.org/abs/1801.10198\" rel=\"nofollow\">Liu, Peter J., Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. 2018. \"Generating Wikipedia by Summarizing Long Sequences.\" arXiv, v1, January 30. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Luhn-1958\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf\" rel=\"nofollow\">Luhn, H. P. 1958. \"The automatic creation of literature abstracts.\" IBM Journal of Research and Development, pp. 159-165, April. doi:10.1147/rd.22.0159. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Marcu-1997\"><a href=\"https://www.cs.toronto.edu/pub/gh/Marcu-PhDthesis.pdf\" rel=\"nofollow\">Marcu, Daniel. 1997. \"The Rhetorical Parsing, Summarization, and Generation of Natural Language Texts.\" PhD Thesis, University of Toronto, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mathur-et-al.-2017\"><a href=\"https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/\" rel=\"nofollow\">Mathur, Pranay, Aman Gill, and Aayush Yadav. 2017. \"Text Summarization in Python: Extractive vs. Abstractive techniques revisited.\" Rare Technologies, April 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Meyer-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/P16-4017/\" rel=\"nofollow\">Meyer, Christian M., Darina Benikova, Margot Mieskes, and Iryna Gurevych. 2016. \"MDSWriter: Annotation Tool for Creating High-Quality Multi-Document Summarization Corpora.\" Proceedings of ACL-2016 System Demonstrations, pp. 97-102, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mihalcea-2004\"><a href=\"https://www.aclweb.org/anthology/P04-3020/\" rel=\"nofollow\">Mihalcea, Rada. 2004. \"Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization.\" Proceedings of the ACL Interactive Poster and Demonstration Sessions, pp. 170-173, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Moradi-and-Ghadiri-2019\"><a href=\"https://arxiv.org/abs/1908.02285\" rel=\"nofollow\">Moradi, Milad, and Nasser Ghadiri. 2019. \"Text Summarization in the Biomedical Domain.\" arXiv, v1, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Nallapati-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/K16-1028/\" rel=\"nofollow\">Nallapati, Ramesh, Bowen Zhou, Cicero dos Santos, Çağlar Gu̇lçehre, and Bing Xiang. 2016. \"Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.\" Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, ACL, pp. 280-290, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Opidi-2019\"><a href=\"https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/\" rel=\"nofollow\">Opidi, Alfrick. 2019. \"A Gentle Introduction to Text Summarization in Machine Learning.\" Blog, FloydHub, April 15. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pai-2019\"><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pawar-2018\"><a href=\"https://medium.com/@i_am_manish/ai-text-summarizer-2de0b07bc27\" rel=\"nofollow\">Pawar, Manish. 2018. \"Ai Text Summarizer.\" Medium, November 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Polsley-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/C16-2054/\" rel=\"nofollow\">Polsley, Seth, Pooja Jhunjhunwala, and Ruihong Huang. 2016. \"CaseSummarizer: A System for Automated Summarization of Legal Texts.\" Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pp. 258-262, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-2000\"><a href=\"https://www.aclweb.org/anthology/W00-1009/\" rel=\"nofollow\">Radev, Dragomir. 2000. \"A Common Theory of Information Fusion from Multiple Text Sources Step One: Cross-Document Structure.\" 1st SIGdial Workshop on Discourse and Dialogue, ACL, pp. 74-83, October. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0403/\" rel=\"nofollow\">Radev, Dragomir R., Hongyan Jing, and Malgorzata Budzikowska. 2000. \"Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies.\" NAACL-ANLP 2000 Workshop: Automatic Summarization, v2, April. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Ratia-2018\"><a href=\"https://blog.frase.io/20-applications-of-automatic-summarization-in-the-enterprise/\" rel=\"nofollow\">Ratia, Tomas. 2018. \"20 Applications of Automatic Summarization in the Enterprise.\" Blog, Frase, July 17. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Rush-et-al.-2015\"><a href=\"https://www.aclweb.org/anthology/D15-1044/\" rel=\"nofollow\">Rush, Alexander M., Sumit Chopra, and Jason Weston. 2015. \"A Neural Attention Model for Abstractive Sentence Summarization.\" Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 379-389, September. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"See-et-al.-2017\"><a href=\"https://arxiv.org/abs/1704.04368\" rel=\"nofollow\">See, Abigail, Peter J. Liu, and Christopher D. Manning. 2017. \"Get To The Point: Summarization with Pointer-Generator Networks.\" arXiv, v2, April 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wong-et-al.-2008\"><a href=\"https://www.aclweb.org/anthology/C08-1124/\" rel=\"nofollow\">Wong, Kam-Fai, Mingli Wu, and Wenjie Li. 2008. \"Extractive Summarization Using Supervised and Semi-Supervised Learning.\" Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pp. 985-992, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wu-2006\"><a href=\"https://www.aclweb.org/anthology/P06-3007/\" rel=\"nofollow\">Wu, Mingli. 2006. \"Investigations on Event-Based Summarization.\" Proceedings of the COLING/ACL 2006 Student Research Workshop, pp. 37-42, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"i2-Decisions-2019\"><a href=\"https://www.i2decisions.com/case-studies/text-summarization\" rel=\"nofollow\">i2 Decisions. 2019. \"Text Summarization.\" Case Studies, i2 Decisions, April 5. Updated 2019-05-21. Accessed 2020-02-20.</a></li></ol></div><div class=\"article-right uk-width-medium-2-5\"><h2 class=\"sec-milestones\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones\" id=\"cd-timeline\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Tags</h2>\n",
              " <i class=\"uk-icon-tags uk-icon-large pull-left\"></i>\n",
              " <div class=\"article-tags\">\n",
              " <a href=\"/site-map/browse-articles/algorithms\" rel=\"nofollow\">algorithms</a>\n",
              " <a href=\"/site-map/browse-articles/natural+language+processing\" rel=\"nofollow\">natural language processing</a>\n",
              " <a href=\"/site-map/browse-articles/text+analytics\" rel=\"nofollow\">text analytics</a>\n",
              " </div><h2>See Also</h2>\n",
              " <ul><li><a href=\"/natural-language-generation\">Natural Language Generation</a></li>\n",
              " <li><a href=\"/natural-language-understanding\">Natural Language Understanding</a></li>\n",
              " <li>Computational Discourse <a href=\"/site-map/add-article?title=Computational+Discourse\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/question-answering\">Question Answering</a></li>\n",
              " <li>Chatbot <a href=\"/site-map/add-article?title=Chatbot\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/speech-recognition\">Speech Recognition</a></li></ul><h2>Further Reading<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-further-reading\"><li><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/\" rel=\"nofollow\">Paulus, Romain, Caiming Xiong, and Richard Socher. 2020. \"Your TL;DR by an AI: A Deep Reinforced Model for Abstractive Summarization.\" Salesforce Einstein, Salesforce. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li></ol><h2>Article Stats</h2>\n",
              " <div class=\"uk-modal\" id=\"author-stats-modal\">\n",
              " <div class=\"author-stats-modal uk-modal-dialog\">\n",
              " <a class=\"uk-modal-close uk-close\"></a>\n",
              " <h2>Author-wise Stats for Article Edits</h2><a href=\"\"></a>\n",
              " <div class=\"uk-grid table-head\">\n",
              " <div class=\"uk-width-medium-1-3\">Author</div>\n",
              " <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid dashboard-table\">\n",
              " <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>\n",
              " <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid author-stats-table-footer\"><div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div></div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>\n",
              " Words<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Chats<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>\n",
              " Authors<br/>\n",
              " </div>\n",
              " </a>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>\n",
              " Edits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Likes<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>\n",
              " Hits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div><h2>Cite As</h2>\n",
              " <div class=\"article-cite-as\">Devopedia. 2020. \"Text Summarization.\" Version 2, February 21. Accessed 2020-05-17. https://devopedia.org/text-summarization</div><button class=\"uk-button uk-button-mini\" type=\"button\">Copy citation</button></div></div>\n",
              " </article>\n",
              " </main>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>, <div class=\"uk-container uk-container-center\">\n",
              " <div class=\"tm-main uk-grid uk-position-relative\" data-uk-grid-margin=\"\" data-uk-grid-match=\"\">\n",
              " <div class=\"tm-main uk-width-medium-1-1 uk-flex-order-last\">\n",
              " <main class=\"tm-content\" id=\"tm-content\">\n",
              " <div id=\"system-message-container\">\n",
              " </div>\n",
              " <div id=\"base-url\" style=\"display:none\"></div><input id=\"token-for-diff\" name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> <a class=\"outer-close-icon\" style=\"display:none\"><i class=\"uk-icon-close\"></i></a>\n",
              " <div class=\"uk-modal\" id=\"diff-draft-modal\"></div>\n",
              " <div class=\"pull-right\">\n",
              " <nav class=\"article-hover-links\" data-aid=\"261\" data-ispub=\"\">\n",
              " <span class=\"article-page-like\" data-vid=\"0\">\n",
              " <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Like this page\"></i><br/>\n",
              " </span>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-share\" id=\"offcanvas-share-link\"><i class=\"uk-icon-justify uk-icon-share-alt\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Share article\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-share\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <div class=\"a2a_kit a2a_kit_size_32 a2a_default_style\">\n",
              " <a class=\"a2a_button_facebook\"></a>\n",
              " <a class=\"a2a_button_twitter\"></a>\n",
              " <a class=\"a2a_button_linkedin\"></a>\n",
              " <a class=\"a2a_button_reddit\"></a>\n",
              " <a class=\"a2a_button_whatsapp\"></a>\n",
              " <a class=\"a2a_button_email\"></a>\n",
              " </div>\n",
              " <script>\n",
              "                         var a2a_config = a2a_config || {};\n",
              "                         a2a_config.onclick = 1;\n",
              "                     </script>\n",
              " <script async=\"\" src=\"https://static.addtoany.com/menu/page.js\"></script>\n",
              " </div>\n",
              " </div>\n",
              " <i class=\"uk-icon-justify article-showhide-links uk-icon-unlink\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Toggle hyperlinks\"></i><br/>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-compare\" id=\"offcanvas-compare-link\"><i class=\"uk-icon-justify uk-icon-files-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Compare versions\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-compare\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Article Versions</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-hover-versions\">\n",
              " <li class=\" \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">2</span> <span class=\"user-datetime\">2020-02-21 17:22:09</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1977\"><i class=\"icon-blank uk-icon-justify\"></i><a class=\"diff-versions uk-icon-justify uk-icon-exchange\" data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" href=\"#diff-modal\" title=\"Diff with\n",
              " previous\"><span class=\"hidden-ids\">1977,1975</span></a> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  Content done. Images added. Publishing.<br/></li><li class=\"last-one \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">1</span> <span class=\"user-datetime\">2020-02-20 06:53:06</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1975\"><i class=\"uk-icon-justify uk-icon-eye-slash\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Unpublished\n",
              " version\"></i> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  First version, no content yet.<br/></li> </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-versions\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older versions\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-modal\" id=\"diff-modal\"></div>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-chatroom\" id=\"offcanvas-chatroom-link\"><i class=\"uk-icon-justify uk-icon-comments-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Discuss this page\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-chatroom\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Chat Room</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-chat-msgs\">\n",
              " <li>\n",
              " <div id=\"chat-save-error\"></div>\n",
              " <div class=\"savenewmsg pull-right\" style=\"display:none\">Submitting ...</div>\n",
              " <div class=\"uk-alert uk-alert-warning\" id=\"chat-edit-desc\" style=\"display:none\">You are editing an existing chat message.</div>\n",
              " <form id=\"chat-form\">\n",
              " <input id=\"savedVersion\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"savedSection\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"chatid\" type=\"hidden\" value=\"0\"/>\n",
              " <select id=\"chat-article-version\" name=\"version\">\n",
              " <option selected=\"selected\" value=\"0\">All Versions</option><option class=\"user-datetime\" value=\"1977\">2020-02-21 17:22:09 by arvindpdmn</option><option class=\"user-datetime\" value=\"1975\">2020-02-20 06:53:06 by arvindpdmn</option> </select>\n",
              " <select id=\"chat-article-section\" name=\"section\">\n",
              " <option selected=\"selected\" value=\"All Sections\">All Sections</option><option value=\"Summary\">Summary</option><option value=\"Discussion\">Discussion</option><option value=\"Sample Code\">Sample Code</option><option value=\"References\">References</option><option value=\"Milestones\">Milestones</option><option value=\"Tags\">Tags</option><option value=\"See Also\">See Also</option><option value=\"Further Reading\">Further Reading</option> </select>\n",
              " </form>\n",
              " </li>\n",
              " </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-msgs\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older messages\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " </nav>\n",
              " </div>\n",
              " <div class=\"uk-modal\" id=\"image-slideshow\"> <div class=\"image-slideshow uk-modal-dialog\"><a class=\"uk-modal-close uk-close\"></a><a href=\"/\"></a> <i class=\"uk-icon uk-icon-chevron-left pull-left\" id=\"prev-img\"></i> <i class=\"uk-icon uk-icon-chevron-right pull-right\" id=\"next-img\"></i> <ul id=\"inner-slides\"><li id=\"slide-0\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/></div></li><li id=\"slide-1\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/></div></li><li id=\"slide-2\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/></div></li><li id=\"slide-3\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/></div></li><li id=\"slide-4\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Multi-document graph. Source: Radev 2000, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/></div></li><li id=\"slide-5\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/></div></li><li id=\"slide-6\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/></div></li><li id=\"slide-7\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/></div></li><li id=\"slide-8\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Architecture of BERTSUM. Source: Liu 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/></div></li><li id=\"slide-9\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/></div></li><li id=\"slide-10\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/></div></li><li id=\"slide-11\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/></div></li><li id=\"slide-12\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/></div></li><li id=\"slide-13\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/></div></li><li id=\"slide-14\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/></div></li> </ul> </div></div>\n",
              " <article class=\"uk-article tm-blog-single \">\n",
              " <h1 class=\"uk-article-title\">\n",
              " \t\t\t\t\tText Summarization\t\t\t</h1>\n",
              " <div class=\"uk-grid article-top-authors\" data-uk-grid-margin=\"\"><div class=\"uk-width-medium-3-5\"><div class=\"uk-grid star-contribs\"><div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><br/><a href=\"/user/arvindpdmn\">arvindpdmn</a><br/>1638 DevCoins</div></div></div><div class=\"uk-width-medium-2-5\"><a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">1 author has contributed to this article</a><br/>Last updated by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-21 17:22:09</span><br/>Created by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-20 06:53:06</span></div></div><div class=\"uk-grid\" data-uk-grid-margin=\"\"><div class=\"article-left uk-width-medium-3-5\"><h2 class=\"topper\">Summary</h2>\n",
              " <div id=\"summary-text-wrapper\"><div id=\"summary-text\"><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-0\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/><div class=\"uk-thumbnail-caption\">Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>On the web, everyone can be a publisher. We're already seeing vast amounts of information being published daily in the form of restaurant/movie/book reviews, blogs, status updates, and more. In addition, traditional print publications (newspapers, magazines, technical journals, whitepapers) are also available online. It's impossible for anyone to keep track of recent publications even if limited to one domain. This is where text summarization can help.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup>\n",
              " </p>\n",
              " <p>A summary, created automatically by algorithms, typically contains the most important information. The summary should be mindful of the reader and the communication goals. It may also help the reader decide if the original text is worth reading in full. The summary can also help improve document indexing for information retrieval. An automated summary is often less biased than a human-written summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> </p></div></div><h2 class=\"sec-milestones-small\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones-small\" id=\"cd-timeline-small\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Discussion</h2>\n",
              " <ul class=\"uk-list uk-list-space article-discussion-list\"><li><article-question>What are some real-world applications of text summarization?</article-question>\n",
              " <article-answer><p>Here are some everyday examples of text summarization: news headlines, outlines for students, movie previews, meeting minutes, biographies for resumes or obituaries, abridged versions of books,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> newsletter production, financial research, patent research, legal contract analysis, tweeting about new content, chatbots that answer questions, email summaries, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>When Google Search presents search results, some entries are accompanied by auto-generated summaries. Google may be leveraging a knowledge graph for this purpose. Google's approach to summarization is mainly entity centric. Summarization extends to timelines and events about entities.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-2017\" title=\"Li 2017\"></a></sup> </p>\n",
              " <p>Doctors write long medical notes containing nutritional information for pregnant mothers. When these were reduced to short crisp summaries, pregnant mothers found them a lot easier to understand.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#i2-Decisions-2019\" title=\"i2 Decisions 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Which are the main approaches to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-9\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/><div class=\"uk-thumbnail-caption\">Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>With <strong>extractive summarization</strong>, summary contains sentences picked and reproduced verbatim from the original text. With <strong>abstractive summarization</strong>, the algorithm interprets the text and generates a summary, possibly using new phrases and sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>Extractive summarization is data-driven, easier and often gives better results. Abstractive summarization is how humans tend to summarize text but it's hard for algorithms since it involves semantic representation, inference and natural language generation. Often abstractive summarization relies on text extracts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> </p>\n",
              " <p>For extraction, sentences are scored and those with highest scores are selected. Scoring criteria may include word frequencies, location heuristics, sentence similarity, rhetorical relations, and semantic roles.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995, sec. 2\"></a></sup> </p>\n",
              " <p>Typically an intermediate representation is used to select relevant summary content. With <strong>topic representation</strong>, the intent is to identify the main topics in the text. Topic words, word frequencies (including <abbr data-title=\"» Term Frequency Inverse Document Frequency\">TF-IDF</abbr>), clustering, <abbr data-title=\"» Latent Semantic Analysis\">LSA</abbr> and <abbr data-title=\"» Latent Dirichlet Allocation\">LDA</abbr> have been applied to summarization. With <strong>indicator representation</strong>, a feature set is used to rank and select sentences. Examples of this approach are graph-based methods and machine learning.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>What are the challenges and requirements of multi-document summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-10\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/><div class=\"uk-thumbnail-caption\">Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The pipeline for multi-document summarization (<abbr data-title=\"» Multi Document Summarization\">MDS</abbr>) has the same basic steps as for single-document summarization (<abbr data-title=\"» Single Document Summarization\">SDS</abbr>): content selection, information ordering, and sentence realization. However, <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> has some unique challenges:<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 1\"></a></sup> <ul class=\"list-in-ans\"><li><strong>Redundancy</strong>: A single document has far less redundancy than a topically-related group of documents. Summary shouldn't repeat similar sentences. <em>Maximal Marginal Relevance (<abbr data-title=\"» Maximal Marginal Relevance\">MMR</abbr>)</em> is a scoring system to penalize similar sentences.</li><li><strong>Temporal Ordering</strong>: A stream of news articles might be reporting the unfolding of an event. Summary should order them correctly and be sensitive to later developments overriding earlier ones.</li><li><strong>Cohesion and Coreference</strong>: Both are important for information ordering. Sometimes cohesion might demand a certain ordering but cause coreference problems, such as a person's shortened name appearing before the full name.</li><li><strong>Compression Ratio</strong>: Summarization becomes more difficult when more compression is demanded.</li></ul>\n",
              " <p><abbr data-title=\"» Multi Document Summarization\">MDS</abbr> may cluster similar documents and passages. Summary should include sufficient context and right level of detail. Factual inconsistencies across documents can be reported. Finally, users must be allowed to filter out irrelevant content, dig deeper into the the sources via attribution, or compare related passages across documents.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 3\"></a></sup> </p></p></article-answer></li>\n",
              " <li><article-question>How does text summarization vary across domains or contexts?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-11\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/><div class=\"uk-thumbnail-caption\">IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Summarization must tune its output to each domain or context. For example, summarization of a news article would involve different considerations from that of a corporate sales report.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>General text summarization techniques might not do well for specific domains. Summarizers therefore might wish to use domain-specific knowledge. For legal document summarization, <em>CaseSummarizer</em> is a tool.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Polsley-et-al.-2016\" title=\"Polsley et al. 2016\"></a></sup> In biomedical domain, summaries are created of literature, treatments, drug information, clinical notes, health records, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Moradi-and-Ghadiri-2019\" title=\"Moradi and Ghadiri 2019\"></a></sup> </p>\n",
              " <p>Summarizing scientific literature is a challenge due to length, complexity, and structure (tables and figures). <em>IBM Science Summarizer</em> is a tool that IBM created to summarize computer science publications. It extracts domain-specific entities of types task, dataset and metric.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019\"></a></sup> </p>\n",
              " <p>Often there are extra clues about what might be important in a document. Summarization can use these for content selection. For example, comments and discussions on a blog post point to interesting content segments. Likewise, citations in scientific papers are useful pointers. For web summarization, it's possible to look at other pages linking to a particular page and determine the most suitable sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 5\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How has machine learning been applied to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-12\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/><div class=\"uk-thumbnail-caption\">Some features used by an <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The common <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> approach is to view text summarization as a classification problem. Algorithm is trained in a supervised manner on original text, an extractive summary and a set of features. Algorithm learns to classify sentences as either summary sentences or non-summary sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p>\n",
              " <p>Classifiers could be based on naive-Bayes, decision trees, <abbr data-title=\"» Support Vector Machines\">SVM</abbr>, <abbr data-title=\"» Hidden Markov Model\">HMM</abbr>, and <abbr data-title=\"» Conditional Random Field\">CRF</abbr>. Often each sentence is classified independently of others. However, since <abbr data-title=\"» Hidden Markov Model\">HMM</abbr> and <abbr data-title=\"» Conditional Random Field\">CRF</abbr> capture dependencies, they outperform other techniques.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 2.2\"></a></sup> </p>\n",
              " <p>The problem with supervised algorithms is in creating labelled data for training. This problem is worse for <abbr data-title=\"» Multi Document Summarization\">MDS</abbr>.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> In a semi-supervised approach, a small amount of labelled data is used along with much larger amount of unlabelled data. The algorithm learns iteratively by classifying some unlabelled data in each iteration.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Could you describe neural network architectures for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-13\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/><div class=\"uk-thumbnail-caption\">Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The typical approach is to do <strong>sequence-to-sequence modelling</strong> since input is a sequence of words and the summary is also a sequence of words. In an encoder-decoder architecture, the encoder uses <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> to give an input representation. The decoder is also an <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> that generates the output sequence. An attention layer between the encoder and the decoder helps in determining the most relevant words for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pawar-2018\" title=\"Pawar 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pai-2019\" title=\"Pai 2019\"></a></sup> </p>\n",
              " <p>Seq2seq models, <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr>s and attention layers have made abstractive summarization possible, even if they're not yet state-of-the-art compared to extractive summarization methods. These models are trained <strong>end-to-end</strong> without bothering to model each step of a traditional summarization pipeline. They also don't need access to specialized vocabulary or do pre-processing.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> This end-to-end approach has been applied successfully to short output sequences, such as news headlines or short email responses.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>In a <strong>pointer-generator</strong> network, a generator provides new words whereas a pointer copies words from source text. Seq2seq models often produce repetitive sentences. A <strong>coverage model</strong> avoids repetitions.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017\"></a></sup> </p>\n",
              " <p>Fernandes et al. showed that sequence encoders with a graph component does better at capturing long-distance relationships.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fernandes-et-al.-2019\" title=\"Fernandes et al. 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How do I evaluate text summarization algorithms?</article-question>\n",
              " <article-answer><p>Human evaluation is the simplest. In 2004, <strong>Recall-Oriented Understudy for Gisting Evaluation (ROUGE)</strong> was created to automate evaluation by comparing against hand-crafted summaries. ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S, and ROUGE-SU are some metrics in this family.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 5.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p>\n",
              " <p>Different people produce different summaries of the same text. Meaning shared across different human summaries is called Summary Content Unit (<abbr data-title=\"» Summary Content Unit\">SCU</abbr>). With a focus on meaning, <strong>Pyramid Method</strong> evaluates a summary using <abbr data-title=\"» Summary Content Unit\">SCU</abbr>s.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.6\"></a></sup> </p>\n",
              " <p>While there's no universal system of metrics, text summarizers are typically evaluated based on TREC, DUC and <abbr data-title=\"» Message Understanding Conference\">MUC</abbr> systems.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 1\"></a></sup> DUC (2001-2007) became a summarization track in TAC (2008-).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#DUC-2014\" title=\"DUC 2014\"></a></sup> </p>\n",
              " <p>Datasets for supervised training of <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> algorithms are not common. For summarizing a single or a few documents, commonly used datasets are Gigaword,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail, TAC (2008-2011) and DUC (2003-2004).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> ELI5 and WikiSum can be used for longform question answering and <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> respectively.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, sec. 5.1\"></a></sup> <a class=\"article-link\" href=\"http://kavita-ganesan.com/opinosis-opinion-dataset\" rel=\"nofollow\">Opinosis</a> is a dataset of 51 article-summary pairs.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Released in 2018, <a class=\"article-link\" href=\"https://summari.es/\" rel=\"nofollow\">Cornell Newsroom</a> is the largest dataset for training and evaluating summarization systems. Spanning 1998-2017 and containing 1.3 million articles, it's been collected from newsrooms of 38 major publications. Summaries are obtained from search and social metadata.</p></article-answer></li>\n",
              " <li><article-question>What are some useful resources for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-14\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/><div class=\"uk-thumbnail-caption\">MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Pengfei Liu has curated a <a class=\"article-link\" href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">useful list</a> of datasets, research papers, and groups researching on text summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2020\" title=\"Liu 2020\"></a></sup> </p>\n",
              " <p>In Python, Gensim has a module for text summarization, which implements <em>TextRank</em> algorithm. An original implementation of the same algorithm is available as PyTextRank package. PyTeaser is a Python implementation of Scala's TextTeaser.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Back in 2016, Google released a baseline TensorFlow implementation for summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p></article-answer></li></ul><h2>References<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-citations\"><li id=\"Allahyari-et-al.-2017\"><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Barzilay-and-Lee-2004\"><a href=\"https://www.aclweb.org/anthology/N04-1015/\" rel=\"nofollow\">Barzilay, Regina, and Lillian Lee. 2004. \"Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization.\" Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004, pp. 113-120, May. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Brownlee-2017\"><a href=\"https://machinelearningmastery.com/gentle-introduction-text-summarization/\" rel=\"nofollow\">Brownlee, Jason. 2017. \"A Gentle Introduction to Text Summarization.\" Machine Learning Mastery, August 7. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Chauhan-2018\"><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"DUC-2014\"><a href=\"https://duc.nist.gov/\" rel=\"nofollow\">DUC. 2014. \"Document Understanding Conferences: Homepage.\" NIST, September 9. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Das-and-Martins-2007\"><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Edmundson-1969\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/edmonson69.pdf\" rel=\"nofollow\">Edmundson, H. P. 1969. \"New Methods in Automatic Extracting.\" Journal of the ACM, vol. 16, no. 2, pp. 264-285, April. doi:10.1145/321510.321519. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Erera-et-al.-2019\"><a href=\"https://www.aclweb.org/anthology/D19-3036/\" rel=\"nofollow\">Erera, Shai, Michal Shmueli-Scheuer, Guy Feigenblat, Ora Peled Nakash, Odellia Boni, Haggai Roitman, Doron Cohen, Bar Weiner, Yosi Mass, Or Rivlin, Guy Lev, Achiya Jerbi, Jonathan Herzig, Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin, Francesca Bonin, and David Konopnicki. 2019. \"A Summarization System for Scientific Documents.\" Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 211-216, November. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fan-et-al.-2019\"><a href=\"https://arxiv.org/abs/1910.08435\" rel=\"nofollow\">Fan, Angela, Claire Gardent, Chloe Braud, and Antoine Bordes. 2019. \"Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs.\" arXiv, v1, October 18. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fernandes-et-al.-2019\"><a href=\"https://arxiv.org/abs/1811.01824\" rel=\"nofollow\">Fernandes, Patrick, Miltiadis Allamanis, and Marc Brockschmidt. 2019. \"Structured Neural Summarization.\" arXiv, v2, February 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Goldstein-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0405/\" rel=\"nofollow\">Goldstein, Jade, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. \"Multi-Document Summarization By Sentence Extraction.\" NAACL-ANLP 2000 Workshop: Automatic Summarization. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Jurafsky-and-Martin-2009\"><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel, and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kumar-et-al.-2016\"><a href=\"https://thescipub.com/PDF/jcssp.2016.178.190.pdf\" rel=\"nofollow\">Kumar, Yogan Jaya, Ong Sing Goh, Halizah Basiron, Ngo Hea Choon, and Puspalata C Suppiah. 2016. \"A Review on Automatic Text Summarization Approaches.\" J. of Comp. Sci., Science Publications, April 29. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kupiec-et-al.-1995\"><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.7100&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">Kupiec, Julian, Jan Pedersen, and Francine Chen. 1995. \"A trainable document summarizer.\" SIGIR '95: Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 68-73, July. doi:10.1145/215206.215333. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Lebanoff-et-al.-2018\"><a href=\"https://arxiv.org/abs/1808.06218\" rel=\"nofollow\">Lebanoff, Logan, Kaiqiang Song, and Fei Liu. 2018. \"Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization.\" arXiv, v2, August 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-2017\"><a href=\"https://medium.com/@wenchen.li/text-summarization-applications-ed319f0bb13c\" rel=\"nofollow\">Li, Wenchen. 2017. \"Text summarization: applications.\" Medium, May 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-et-al.-2006\"><a href=\"https://www.aclweb.org/anthology/P06-1047/\" rel=\"nofollow\">Li, Wenjie, Mingli Wu, Qin Lu, Wei Xu, and Chunfa Yuan. 2006. \"Extractive Summarization using Inter- and Intra- Event Relevance.\" Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pp. 369-376, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2019\"><a href=\"https://arxiv.org/abs/1903.10318\" rel=\"nofollow\">Liu, Yang. 2019. \"Fine-tune BERT for Extractive Summarization.\" arXiv, v2, September 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2020\"><a href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">Liu, Pengfei. 2020. \"Modern History for Text Summarization.\" NLP Historiograpy. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-and-Pan-2016\"><a href=\"https://ai.googleblog.com/2016/08/text-summarization-with-tensorflow.html\" rel=\"nofollow\">Liu, Peter, and Xin Pan. 2016. \"Text summarization with TensorFlow.\" Google AI Blog, August 24. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-et-al.-2018\"><a href=\"https://arxiv.org/abs/1801.10198\" rel=\"nofollow\">Liu, Peter J., Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. 2018. \"Generating Wikipedia by Summarizing Long Sequences.\" arXiv, v1, January 30. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Luhn-1958\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf\" rel=\"nofollow\">Luhn, H. P. 1958. \"The automatic creation of literature abstracts.\" IBM Journal of Research and Development, pp. 159-165, April. doi:10.1147/rd.22.0159. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Marcu-1997\"><a href=\"https://www.cs.toronto.edu/pub/gh/Marcu-PhDthesis.pdf\" rel=\"nofollow\">Marcu, Daniel. 1997. \"The Rhetorical Parsing, Summarization, and Generation of Natural Language Texts.\" PhD Thesis, University of Toronto, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mathur-et-al.-2017\"><a href=\"https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/\" rel=\"nofollow\">Mathur, Pranay, Aman Gill, and Aayush Yadav. 2017. \"Text Summarization in Python: Extractive vs. Abstractive techniques revisited.\" Rare Technologies, April 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Meyer-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/P16-4017/\" rel=\"nofollow\">Meyer, Christian M., Darina Benikova, Margot Mieskes, and Iryna Gurevych. 2016. \"MDSWriter: Annotation Tool for Creating High-Quality Multi-Document Summarization Corpora.\" Proceedings of ACL-2016 System Demonstrations, pp. 97-102, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mihalcea-2004\"><a href=\"https://www.aclweb.org/anthology/P04-3020/\" rel=\"nofollow\">Mihalcea, Rada. 2004. \"Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization.\" Proceedings of the ACL Interactive Poster and Demonstration Sessions, pp. 170-173, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Moradi-and-Ghadiri-2019\"><a href=\"https://arxiv.org/abs/1908.02285\" rel=\"nofollow\">Moradi, Milad, and Nasser Ghadiri. 2019. \"Text Summarization in the Biomedical Domain.\" arXiv, v1, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Nallapati-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/K16-1028/\" rel=\"nofollow\">Nallapati, Ramesh, Bowen Zhou, Cicero dos Santos, Çağlar Gu̇lçehre, and Bing Xiang. 2016. \"Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.\" Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, ACL, pp. 280-290, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Opidi-2019\"><a href=\"https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/\" rel=\"nofollow\">Opidi, Alfrick. 2019. \"A Gentle Introduction to Text Summarization in Machine Learning.\" Blog, FloydHub, April 15. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pai-2019\"><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pawar-2018\"><a href=\"https://medium.com/@i_am_manish/ai-text-summarizer-2de0b07bc27\" rel=\"nofollow\">Pawar, Manish. 2018. \"Ai Text Summarizer.\" Medium, November 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Polsley-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/C16-2054/\" rel=\"nofollow\">Polsley, Seth, Pooja Jhunjhunwala, and Ruihong Huang. 2016. \"CaseSummarizer: A System for Automated Summarization of Legal Texts.\" Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pp. 258-262, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-2000\"><a href=\"https://www.aclweb.org/anthology/W00-1009/\" rel=\"nofollow\">Radev, Dragomir. 2000. \"A Common Theory of Information Fusion from Multiple Text Sources Step One: Cross-Document Structure.\" 1st SIGdial Workshop on Discourse and Dialogue, ACL, pp. 74-83, October. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0403/\" rel=\"nofollow\">Radev, Dragomir R., Hongyan Jing, and Malgorzata Budzikowska. 2000. \"Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies.\" NAACL-ANLP 2000 Workshop: Automatic Summarization, v2, April. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Ratia-2018\"><a href=\"https://blog.frase.io/20-applications-of-automatic-summarization-in-the-enterprise/\" rel=\"nofollow\">Ratia, Tomas. 2018. \"20 Applications of Automatic Summarization in the Enterprise.\" Blog, Frase, July 17. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Rush-et-al.-2015\"><a href=\"https://www.aclweb.org/anthology/D15-1044/\" rel=\"nofollow\">Rush, Alexander M., Sumit Chopra, and Jason Weston. 2015. \"A Neural Attention Model for Abstractive Sentence Summarization.\" Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 379-389, September. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"See-et-al.-2017\"><a href=\"https://arxiv.org/abs/1704.04368\" rel=\"nofollow\">See, Abigail, Peter J. Liu, and Christopher D. Manning. 2017. \"Get To The Point: Summarization with Pointer-Generator Networks.\" arXiv, v2, April 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wong-et-al.-2008\"><a href=\"https://www.aclweb.org/anthology/C08-1124/\" rel=\"nofollow\">Wong, Kam-Fai, Mingli Wu, and Wenjie Li. 2008. \"Extractive Summarization Using Supervised and Semi-Supervised Learning.\" Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pp. 985-992, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wu-2006\"><a href=\"https://www.aclweb.org/anthology/P06-3007/\" rel=\"nofollow\">Wu, Mingli. 2006. \"Investigations on Event-Based Summarization.\" Proceedings of the COLING/ACL 2006 Student Research Workshop, pp. 37-42, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"i2-Decisions-2019\"><a href=\"https://www.i2decisions.com/case-studies/text-summarization\" rel=\"nofollow\">i2 Decisions. 2019. \"Text Summarization.\" Case Studies, i2 Decisions, April 5. Updated 2019-05-21. Accessed 2020-02-20.</a></li></ol></div><div class=\"article-right uk-width-medium-2-5\"><h2 class=\"sec-milestones\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones\" id=\"cd-timeline\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Tags</h2>\n",
              " <i class=\"uk-icon-tags uk-icon-large pull-left\"></i>\n",
              " <div class=\"article-tags\">\n",
              " <a href=\"/site-map/browse-articles/algorithms\" rel=\"nofollow\">algorithms</a>\n",
              " <a href=\"/site-map/browse-articles/natural+language+processing\" rel=\"nofollow\">natural language processing</a>\n",
              " <a href=\"/site-map/browse-articles/text+analytics\" rel=\"nofollow\">text analytics</a>\n",
              " </div><h2>See Also</h2>\n",
              " <ul><li><a href=\"/natural-language-generation\">Natural Language Generation</a></li>\n",
              " <li><a href=\"/natural-language-understanding\">Natural Language Understanding</a></li>\n",
              " <li>Computational Discourse <a href=\"/site-map/add-article?title=Computational+Discourse\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/question-answering\">Question Answering</a></li>\n",
              " <li>Chatbot <a href=\"/site-map/add-article?title=Chatbot\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/speech-recognition\">Speech Recognition</a></li></ul><h2>Further Reading<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-further-reading\"><li><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/\" rel=\"nofollow\">Paulus, Romain, Caiming Xiong, and Richard Socher. 2020. \"Your TL;DR by an AI: A Deep Reinforced Model for Abstractive Summarization.\" Salesforce Einstein, Salesforce. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li></ol><h2>Article Stats</h2>\n",
              " <div class=\"uk-modal\" id=\"author-stats-modal\">\n",
              " <div class=\"author-stats-modal uk-modal-dialog\">\n",
              " <a class=\"uk-modal-close uk-close\"></a>\n",
              " <h2>Author-wise Stats for Article Edits</h2><a href=\"\"></a>\n",
              " <div class=\"uk-grid table-head\">\n",
              " <div class=\"uk-width-medium-1-3\">Author</div>\n",
              " <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid dashboard-table\">\n",
              " <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>\n",
              " <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid author-stats-table-footer\"><div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div></div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>\n",
              " Words<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Chats<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>\n",
              " Authors<br/>\n",
              " </div>\n",
              " </a>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>\n",
              " Edits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Likes<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>\n",
              " Hits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div><h2>Cite As</h2>\n",
              " <div class=\"article-cite-as\">Devopedia. 2020. \"Text Summarization.\" Version 2, February 21. Accessed 2020-05-17. https://devopedia.org/text-summarization</div><button class=\"uk-button uk-button-mini\" type=\"button\">Copy citation</button></div></div>\n",
              " </article>\n",
              " </main>\n",
              " </div>\n",
              " </div>\n",
              " </div>, <div class=\"tm-main uk-grid uk-position-relative\" data-uk-grid-margin=\"\" data-uk-grid-match=\"\">\n",
              " <div class=\"tm-main uk-width-medium-1-1 uk-flex-order-last\">\n",
              " <main class=\"tm-content\" id=\"tm-content\">\n",
              " <div id=\"system-message-container\">\n",
              " </div>\n",
              " <div id=\"base-url\" style=\"display:none\"></div><input id=\"token-for-diff\" name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> <a class=\"outer-close-icon\" style=\"display:none\"><i class=\"uk-icon-close\"></i></a>\n",
              " <div class=\"uk-modal\" id=\"diff-draft-modal\"></div>\n",
              " <div class=\"pull-right\">\n",
              " <nav class=\"article-hover-links\" data-aid=\"261\" data-ispub=\"\">\n",
              " <span class=\"article-page-like\" data-vid=\"0\">\n",
              " <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Like this page\"></i><br/>\n",
              " </span>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-share\" id=\"offcanvas-share-link\"><i class=\"uk-icon-justify uk-icon-share-alt\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Share article\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-share\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <div class=\"a2a_kit a2a_kit_size_32 a2a_default_style\">\n",
              " <a class=\"a2a_button_facebook\"></a>\n",
              " <a class=\"a2a_button_twitter\"></a>\n",
              " <a class=\"a2a_button_linkedin\"></a>\n",
              " <a class=\"a2a_button_reddit\"></a>\n",
              " <a class=\"a2a_button_whatsapp\"></a>\n",
              " <a class=\"a2a_button_email\"></a>\n",
              " </div>\n",
              " <script>\n",
              "                         var a2a_config = a2a_config || {};\n",
              "                         a2a_config.onclick = 1;\n",
              "                     </script>\n",
              " <script async=\"\" src=\"https://static.addtoany.com/menu/page.js\"></script>\n",
              " </div>\n",
              " </div>\n",
              " <i class=\"uk-icon-justify article-showhide-links uk-icon-unlink\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Toggle hyperlinks\"></i><br/>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-compare\" id=\"offcanvas-compare-link\"><i class=\"uk-icon-justify uk-icon-files-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Compare versions\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-compare\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Article Versions</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-hover-versions\">\n",
              " <li class=\" \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">2</span> <span class=\"user-datetime\">2020-02-21 17:22:09</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1977\"><i class=\"icon-blank uk-icon-justify\"></i><a class=\"diff-versions uk-icon-justify uk-icon-exchange\" data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" href=\"#diff-modal\" title=\"Diff with\n",
              " previous\"><span class=\"hidden-ids\">1977,1975</span></a> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  Content done. Images added. Publishing.<br/></li><li class=\"last-one \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">1</span> <span class=\"user-datetime\">2020-02-20 06:53:06</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1975\"><i class=\"uk-icon-justify uk-icon-eye-slash\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Unpublished\n",
              " version\"></i> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  First version, no content yet.<br/></li> </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-versions\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older versions\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-modal\" id=\"diff-modal\"></div>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-chatroom\" id=\"offcanvas-chatroom-link\"><i class=\"uk-icon-justify uk-icon-comments-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Discuss this page\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-chatroom\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Chat Room</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-chat-msgs\">\n",
              " <li>\n",
              " <div id=\"chat-save-error\"></div>\n",
              " <div class=\"savenewmsg pull-right\" style=\"display:none\">Submitting ...</div>\n",
              " <div class=\"uk-alert uk-alert-warning\" id=\"chat-edit-desc\" style=\"display:none\">You are editing an existing chat message.</div>\n",
              " <form id=\"chat-form\">\n",
              " <input id=\"savedVersion\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"savedSection\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"chatid\" type=\"hidden\" value=\"0\"/>\n",
              " <select id=\"chat-article-version\" name=\"version\">\n",
              " <option selected=\"selected\" value=\"0\">All Versions</option><option class=\"user-datetime\" value=\"1977\">2020-02-21 17:22:09 by arvindpdmn</option><option class=\"user-datetime\" value=\"1975\">2020-02-20 06:53:06 by arvindpdmn</option> </select>\n",
              " <select id=\"chat-article-section\" name=\"section\">\n",
              " <option selected=\"selected\" value=\"All Sections\">All Sections</option><option value=\"Summary\">Summary</option><option value=\"Discussion\">Discussion</option><option value=\"Sample Code\">Sample Code</option><option value=\"References\">References</option><option value=\"Milestones\">Milestones</option><option value=\"Tags\">Tags</option><option value=\"See Also\">See Also</option><option value=\"Further Reading\">Further Reading</option> </select>\n",
              " </form>\n",
              " </li>\n",
              " </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-msgs\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older messages\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " </nav>\n",
              " </div>\n",
              " <div class=\"uk-modal\" id=\"image-slideshow\"> <div class=\"image-slideshow uk-modal-dialog\"><a class=\"uk-modal-close uk-close\"></a><a href=\"/\"></a> <i class=\"uk-icon uk-icon-chevron-left pull-left\" id=\"prev-img\"></i> <i class=\"uk-icon uk-icon-chevron-right pull-right\" id=\"next-img\"></i> <ul id=\"inner-slides\"><li id=\"slide-0\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/></div></li><li id=\"slide-1\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/></div></li><li id=\"slide-2\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/></div></li><li id=\"slide-3\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/></div></li><li id=\"slide-4\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Multi-document graph. Source: Radev 2000, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/></div></li><li id=\"slide-5\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/></div></li><li id=\"slide-6\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/></div></li><li id=\"slide-7\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/></div></li><li id=\"slide-8\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Architecture of BERTSUM. Source: Liu 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/></div></li><li id=\"slide-9\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/></div></li><li id=\"slide-10\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/></div></li><li id=\"slide-11\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/></div></li><li id=\"slide-12\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/></div></li><li id=\"slide-13\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/></div></li><li id=\"slide-14\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/></div></li> </ul> </div></div>\n",
              " <article class=\"uk-article tm-blog-single \">\n",
              " <h1 class=\"uk-article-title\">\n",
              " \t\t\t\t\tText Summarization\t\t\t</h1>\n",
              " <div class=\"uk-grid article-top-authors\" data-uk-grid-margin=\"\"><div class=\"uk-width-medium-3-5\"><div class=\"uk-grid star-contribs\"><div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><br/><a href=\"/user/arvindpdmn\">arvindpdmn</a><br/>1638 DevCoins</div></div></div><div class=\"uk-width-medium-2-5\"><a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">1 author has contributed to this article</a><br/>Last updated by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-21 17:22:09</span><br/>Created by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-20 06:53:06</span></div></div><div class=\"uk-grid\" data-uk-grid-margin=\"\"><div class=\"article-left uk-width-medium-3-5\"><h2 class=\"topper\">Summary</h2>\n",
              " <div id=\"summary-text-wrapper\"><div id=\"summary-text\"><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-0\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/><div class=\"uk-thumbnail-caption\">Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>On the web, everyone can be a publisher. We're already seeing vast amounts of information being published daily in the form of restaurant/movie/book reviews, blogs, status updates, and more. In addition, traditional print publications (newspapers, magazines, technical journals, whitepapers) are also available online. It's impossible for anyone to keep track of recent publications even if limited to one domain. This is where text summarization can help.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup>\n",
              " </p>\n",
              " <p>A summary, created automatically by algorithms, typically contains the most important information. The summary should be mindful of the reader and the communication goals. It may also help the reader decide if the original text is worth reading in full. The summary can also help improve document indexing for information retrieval. An automated summary is often less biased than a human-written summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> </p></div></div><h2 class=\"sec-milestones-small\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones-small\" id=\"cd-timeline-small\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Discussion</h2>\n",
              " <ul class=\"uk-list uk-list-space article-discussion-list\"><li><article-question>What are some real-world applications of text summarization?</article-question>\n",
              " <article-answer><p>Here are some everyday examples of text summarization: news headlines, outlines for students, movie previews, meeting minutes, biographies for resumes or obituaries, abridged versions of books,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> newsletter production, financial research, patent research, legal contract analysis, tweeting about new content, chatbots that answer questions, email summaries, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>When Google Search presents search results, some entries are accompanied by auto-generated summaries. Google may be leveraging a knowledge graph for this purpose. Google's approach to summarization is mainly entity centric. Summarization extends to timelines and events about entities.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-2017\" title=\"Li 2017\"></a></sup> </p>\n",
              " <p>Doctors write long medical notes containing nutritional information for pregnant mothers. When these were reduced to short crisp summaries, pregnant mothers found them a lot easier to understand.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#i2-Decisions-2019\" title=\"i2 Decisions 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Which are the main approaches to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-9\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/><div class=\"uk-thumbnail-caption\">Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>With <strong>extractive summarization</strong>, summary contains sentences picked and reproduced verbatim from the original text. With <strong>abstractive summarization</strong>, the algorithm interprets the text and generates a summary, possibly using new phrases and sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>Extractive summarization is data-driven, easier and often gives better results. Abstractive summarization is how humans tend to summarize text but it's hard for algorithms since it involves semantic representation, inference and natural language generation. Often abstractive summarization relies on text extracts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> </p>\n",
              " <p>For extraction, sentences are scored and those with highest scores are selected. Scoring criteria may include word frequencies, location heuristics, sentence similarity, rhetorical relations, and semantic roles.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995, sec. 2\"></a></sup> </p>\n",
              " <p>Typically an intermediate representation is used to select relevant summary content. With <strong>topic representation</strong>, the intent is to identify the main topics in the text. Topic words, word frequencies (including <abbr data-title=\"» Term Frequency Inverse Document Frequency\">TF-IDF</abbr>), clustering, <abbr data-title=\"» Latent Semantic Analysis\">LSA</abbr> and <abbr data-title=\"» Latent Dirichlet Allocation\">LDA</abbr> have been applied to summarization. With <strong>indicator representation</strong>, a feature set is used to rank and select sentences. Examples of this approach are graph-based methods and machine learning.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>What are the challenges and requirements of multi-document summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-10\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/><div class=\"uk-thumbnail-caption\">Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The pipeline for multi-document summarization (<abbr data-title=\"» Multi Document Summarization\">MDS</abbr>) has the same basic steps as for single-document summarization (<abbr data-title=\"» Single Document Summarization\">SDS</abbr>): content selection, information ordering, and sentence realization. However, <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> has some unique challenges:<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 1\"></a></sup> <ul class=\"list-in-ans\"><li><strong>Redundancy</strong>: A single document has far less redundancy than a topically-related group of documents. Summary shouldn't repeat similar sentences. <em>Maximal Marginal Relevance (<abbr data-title=\"» Maximal Marginal Relevance\">MMR</abbr>)</em> is a scoring system to penalize similar sentences.</li><li><strong>Temporal Ordering</strong>: A stream of news articles might be reporting the unfolding of an event. Summary should order them correctly and be sensitive to later developments overriding earlier ones.</li><li><strong>Cohesion and Coreference</strong>: Both are important for information ordering. Sometimes cohesion might demand a certain ordering but cause coreference problems, such as a person's shortened name appearing before the full name.</li><li><strong>Compression Ratio</strong>: Summarization becomes more difficult when more compression is demanded.</li></ul>\n",
              " <p><abbr data-title=\"» Multi Document Summarization\">MDS</abbr> may cluster similar documents and passages. Summary should include sufficient context and right level of detail. Factual inconsistencies across documents can be reported. Finally, users must be allowed to filter out irrelevant content, dig deeper into the the sources via attribution, or compare related passages across documents.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 3\"></a></sup> </p></p></article-answer></li>\n",
              " <li><article-question>How does text summarization vary across domains or contexts?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-11\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/><div class=\"uk-thumbnail-caption\">IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Summarization must tune its output to each domain or context. For example, summarization of a news article would involve different considerations from that of a corporate sales report.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>General text summarization techniques might not do well for specific domains. Summarizers therefore might wish to use domain-specific knowledge. For legal document summarization, <em>CaseSummarizer</em> is a tool.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Polsley-et-al.-2016\" title=\"Polsley et al. 2016\"></a></sup> In biomedical domain, summaries are created of literature, treatments, drug information, clinical notes, health records, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Moradi-and-Ghadiri-2019\" title=\"Moradi and Ghadiri 2019\"></a></sup> </p>\n",
              " <p>Summarizing scientific literature is a challenge due to length, complexity, and structure (tables and figures). <em>IBM Science Summarizer</em> is a tool that IBM created to summarize computer science publications. It extracts domain-specific entities of types task, dataset and metric.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019\"></a></sup> </p>\n",
              " <p>Often there are extra clues about what might be important in a document. Summarization can use these for content selection. For example, comments and discussions on a blog post point to interesting content segments. Likewise, citations in scientific papers are useful pointers. For web summarization, it's possible to look at other pages linking to a particular page and determine the most suitable sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 5\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How has machine learning been applied to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-12\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/><div class=\"uk-thumbnail-caption\">Some features used by an <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The common <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> approach is to view text summarization as a classification problem. Algorithm is trained in a supervised manner on original text, an extractive summary and a set of features. Algorithm learns to classify sentences as either summary sentences or non-summary sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p>\n",
              " <p>Classifiers could be based on naive-Bayes, decision trees, <abbr data-title=\"» Support Vector Machines\">SVM</abbr>, <abbr data-title=\"» Hidden Markov Model\">HMM</abbr>, and <abbr data-title=\"» Conditional Random Field\">CRF</abbr>. Often each sentence is classified independently of others. However, since <abbr data-title=\"» Hidden Markov Model\">HMM</abbr> and <abbr data-title=\"» Conditional Random Field\">CRF</abbr> capture dependencies, they outperform other techniques.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 2.2\"></a></sup> </p>\n",
              " <p>The problem with supervised algorithms is in creating labelled data for training. This problem is worse for <abbr data-title=\"» Multi Document Summarization\">MDS</abbr>.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> In a semi-supervised approach, a small amount of labelled data is used along with much larger amount of unlabelled data. The algorithm learns iteratively by classifying some unlabelled data in each iteration.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Could you describe neural network architectures for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-13\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/><div class=\"uk-thumbnail-caption\">Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The typical approach is to do <strong>sequence-to-sequence modelling</strong> since input is a sequence of words and the summary is also a sequence of words. In an encoder-decoder architecture, the encoder uses <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> to give an input representation. The decoder is also an <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> that generates the output sequence. An attention layer between the encoder and the decoder helps in determining the most relevant words for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pawar-2018\" title=\"Pawar 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pai-2019\" title=\"Pai 2019\"></a></sup> </p>\n",
              " <p>Seq2seq models, <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr>s and attention layers have made abstractive summarization possible, even if they're not yet state-of-the-art compared to extractive summarization methods. These models are trained <strong>end-to-end</strong> without bothering to model each step of a traditional summarization pipeline. They also don't need access to specialized vocabulary or do pre-processing.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> This end-to-end approach has been applied successfully to short output sequences, such as news headlines or short email responses.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>In a <strong>pointer-generator</strong> network, a generator provides new words whereas a pointer copies words from source text. Seq2seq models often produce repetitive sentences. A <strong>coverage model</strong> avoids repetitions.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017\"></a></sup> </p>\n",
              " <p>Fernandes et al. showed that sequence encoders with a graph component does better at capturing long-distance relationships.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fernandes-et-al.-2019\" title=\"Fernandes et al. 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How do I evaluate text summarization algorithms?</article-question>\n",
              " <article-answer><p>Human evaluation is the simplest. In 2004, <strong>Recall-Oriented Understudy for Gisting Evaluation (ROUGE)</strong> was created to automate evaluation by comparing against hand-crafted summaries. ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S, and ROUGE-SU are some metrics in this family.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 5.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p>\n",
              " <p>Different people produce different summaries of the same text. Meaning shared across different human summaries is called Summary Content Unit (<abbr data-title=\"» Summary Content Unit\">SCU</abbr>). With a focus on meaning, <strong>Pyramid Method</strong> evaluates a summary using <abbr data-title=\"» Summary Content Unit\">SCU</abbr>s.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.6\"></a></sup> </p>\n",
              " <p>While there's no universal system of metrics, text summarizers are typically evaluated based on TREC, DUC and <abbr data-title=\"» Message Understanding Conference\">MUC</abbr> systems.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 1\"></a></sup> DUC (2001-2007) became a summarization track in TAC (2008-).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#DUC-2014\" title=\"DUC 2014\"></a></sup> </p>\n",
              " <p>Datasets for supervised training of <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> algorithms are not common. For summarizing a single or a few documents, commonly used datasets are Gigaword,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail, TAC (2008-2011) and DUC (2003-2004).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> ELI5 and WikiSum can be used for longform question answering and <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> respectively.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, sec. 5.1\"></a></sup> <a class=\"article-link\" href=\"http://kavita-ganesan.com/opinosis-opinion-dataset\" rel=\"nofollow\">Opinosis</a> is a dataset of 51 article-summary pairs.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Released in 2018, <a class=\"article-link\" href=\"https://summari.es/\" rel=\"nofollow\">Cornell Newsroom</a> is the largest dataset for training and evaluating summarization systems. Spanning 1998-2017 and containing 1.3 million articles, it's been collected from newsrooms of 38 major publications. Summaries are obtained from search and social metadata.</p></article-answer></li>\n",
              " <li><article-question>What are some useful resources for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-14\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/><div class=\"uk-thumbnail-caption\">MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Pengfei Liu has curated a <a class=\"article-link\" href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">useful list</a> of datasets, research papers, and groups researching on text summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2020\" title=\"Liu 2020\"></a></sup> </p>\n",
              " <p>In Python, Gensim has a module for text summarization, which implements <em>TextRank</em> algorithm. An original implementation of the same algorithm is available as PyTextRank package. PyTeaser is a Python implementation of Scala's TextTeaser.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Back in 2016, Google released a baseline TensorFlow implementation for summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p></article-answer></li></ul><h2>References<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-citations\"><li id=\"Allahyari-et-al.-2017\"><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Barzilay-and-Lee-2004\"><a href=\"https://www.aclweb.org/anthology/N04-1015/\" rel=\"nofollow\">Barzilay, Regina, and Lillian Lee. 2004. \"Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization.\" Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004, pp. 113-120, May. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Brownlee-2017\"><a href=\"https://machinelearningmastery.com/gentle-introduction-text-summarization/\" rel=\"nofollow\">Brownlee, Jason. 2017. \"A Gentle Introduction to Text Summarization.\" Machine Learning Mastery, August 7. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Chauhan-2018\"><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"DUC-2014\"><a href=\"https://duc.nist.gov/\" rel=\"nofollow\">DUC. 2014. \"Document Understanding Conferences: Homepage.\" NIST, September 9. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Das-and-Martins-2007\"><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Edmundson-1969\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/edmonson69.pdf\" rel=\"nofollow\">Edmundson, H. P. 1969. \"New Methods in Automatic Extracting.\" Journal of the ACM, vol. 16, no. 2, pp. 264-285, April. doi:10.1145/321510.321519. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Erera-et-al.-2019\"><a href=\"https://www.aclweb.org/anthology/D19-3036/\" rel=\"nofollow\">Erera, Shai, Michal Shmueli-Scheuer, Guy Feigenblat, Ora Peled Nakash, Odellia Boni, Haggai Roitman, Doron Cohen, Bar Weiner, Yosi Mass, Or Rivlin, Guy Lev, Achiya Jerbi, Jonathan Herzig, Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin, Francesca Bonin, and David Konopnicki. 2019. \"A Summarization System for Scientific Documents.\" Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 211-216, November. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fan-et-al.-2019\"><a href=\"https://arxiv.org/abs/1910.08435\" rel=\"nofollow\">Fan, Angela, Claire Gardent, Chloe Braud, and Antoine Bordes. 2019. \"Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs.\" arXiv, v1, October 18. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fernandes-et-al.-2019\"><a href=\"https://arxiv.org/abs/1811.01824\" rel=\"nofollow\">Fernandes, Patrick, Miltiadis Allamanis, and Marc Brockschmidt. 2019. \"Structured Neural Summarization.\" arXiv, v2, February 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Goldstein-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0405/\" rel=\"nofollow\">Goldstein, Jade, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. \"Multi-Document Summarization By Sentence Extraction.\" NAACL-ANLP 2000 Workshop: Automatic Summarization. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Jurafsky-and-Martin-2009\"><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel, and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kumar-et-al.-2016\"><a href=\"https://thescipub.com/PDF/jcssp.2016.178.190.pdf\" rel=\"nofollow\">Kumar, Yogan Jaya, Ong Sing Goh, Halizah Basiron, Ngo Hea Choon, and Puspalata C Suppiah. 2016. \"A Review on Automatic Text Summarization Approaches.\" J. of Comp. Sci., Science Publications, April 29. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kupiec-et-al.-1995\"><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.7100&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">Kupiec, Julian, Jan Pedersen, and Francine Chen. 1995. \"A trainable document summarizer.\" SIGIR '95: Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 68-73, July. doi:10.1145/215206.215333. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Lebanoff-et-al.-2018\"><a href=\"https://arxiv.org/abs/1808.06218\" rel=\"nofollow\">Lebanoff, Logan, Kaiqiang Song, and Fei Liu. 2018. \"Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization.\" arXiv, v2, August 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-2017\"><a href=\"https://medium.com/@wenchen.li/text-summarization-applications-ed319f0bb13c\" rel=\"nofollow\">Li, Wenchen. 2017. \"Text summarization: applications.\" Medium, May 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-et-al.-2006\"><a href=\"https://www.aclweb.org/anthology/P06-1047/\" rel=\"nofollow\">Li, Wenjie, Mingli Wu, Qin Lu, Wei Xu, and Chunfa Yuan. 2006. \"Extractive Summarization using Inter- and Intra- Event Relevance.\" Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pp. 369-376, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2019\"><a href=\"https://arxiv.org/abs/1903.10318\" rel=\"nofollow\">Liu, Yang. 2019. \"Fine-tune BERT for Extractive Summarization.\" arXiv, v2, September 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2020\"><a href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">Liu, Pengfei. 2020. \"Modern History for Text Summarization.\" NLP Historiograpy. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-and-Pan-2016\"><a href=\"https://ai.googleblog.com/2016/08/text-summarization-with-tensorflow.html\" rel=\"nofollow\">Liu, Peter, and Xin Pan. 2016. \"Text summarization with TensorFlow.\" Google AI Blog, August 24. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-et-al.-2018\"><a href=\"https://arxiv.org/abs/1801.10198\" rel=\"nofollow\">Liu, Peter J., Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. 2018. \"Generating Wikipedia by Summarizing Long Sequences.\" arXiv, v1, January 30. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Luhn-1958\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf\" rel=\"nofollow\">Luhn, H. P. 1958. \"The automatic creation of literature abstracts.\" IBM Journal of Research and Development, pp. 159-165, April. doi:10.1147/rd.22.0159. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Marcu-1997\"><a href=\"https://www.cs.toronto.edu/pub/gh/Marcu-PhDthesis.pdf\" rel=\"nofollow\">Marcu, Daniel. 1997. \"The Rhetorical Parsing, Summarization, and Generation of Natural Language Texts.\" PhD Thesis, University of Toronto, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mathur-et-al.-2017\"><a href=\"https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/\" rel=\"nofollow\">Mathur, Pranay, Aman Gill, and Aayush Yadav. 2017. \"Text Summarization in Python: Extractive vs. Abstractive techniques revisited.\" Rare Technologies, April 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Meyer-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/P16-4017/\" rel=\"nofollow\">Meyer, Christian M., Darina Benikova, Margot Mieskes, and Iryna Gurevych. 2016. \"MDSWriter: Annotation Tool for Creating High-Quality Multi-Document Summarization Corpora.\" Proceedings of ACL-2016 System Demonstrations, pp. 97-102, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mihalcea-2004\"><a href=\"https://www.aclweb.org/anthology/P04-3020/\" rel=\"nofollow\">Mihalcea, Rada. 2004. \"Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization.\" Proceedings of the ACL Interactive Poster and Demonstration Sessions, pp. 170-173, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Moradi-and-Ghadiri-2019\"><a href=\"https://arxiv.org/abs/1908.02285\" rel=\"nofollow\">Moradi, Milad, and Nasser Ghadiri. 2019. \"Text Summarization in the Biomedical Domain.\" arXiv, v1, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Nallapati-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/K16-1028/\" rel=\"nofollow\">Nallapati, Ramesh, Bowen Zhou, Cicero dos Santos, Çağlar Gu̇lçehre, and Bing Xiang. 2016. \"Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.\" Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, ACL, pp. 280-290, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Opidi-2019\"><a href=\"https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/\" rel=\"nofollow\">Opidi, Alfrick. 2019. \"A Gentle Introduction to Text Summarization in Machine Learning.\" Blog, FloydHub, April 15. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pai-2019\"><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pawar-2018\"><a href=\"https://medium.com/@i_am_manish/ai-text-summarizer-2de0b07bc27\" rel=\"nofollow\">Pawar, Manish. 2018. \"Ai Text Summarizer.\" Medium, November 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Polsley-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/C16-2054/\" rel=\"nofollow\">Polsley, Seth, Pooja Jhunjhunwala, and Ruihong Huang. 2016. \"CaseSummarizer: A System for Automated Summarization of Legal Texts.\" Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pp. 258-262, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-2000\"><a href=\"https://www.aclweb.org/anthology/W00-1009/\" rel=\"nofollow\">Radev, Dragomir. 2000. \"A Common Theory of Information Fusion from Multiple Text Sources Step One: Cross-Document Structure.\" 1st SIGdial Workshop on Discourse and Dialogue, ACL, pp. 74-83, October. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0403/\" rel=\"nofollow\">Radev, Dragomir R., Hongyan Jing, and Malgorzata Budzikowska. 2000. \"Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies.\" NAACL-ANLP 2000 Workshop: Automatic Summarization, v2, April. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Ratia-2018\"><a href=\"https://blog.frase.io/20-applications-of-automatic-summarization-in-the-enterprise/\" rel=\"nofollow\">Ratia, Tomas. 2018. \"20 Applications of Automatic Summarization in the Enterprise.\" Blog, Frase, July 17. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Rush-et-al.-2015\"><a href=\"https://www.aclweb.org/anthology/D15-1044/\" rel=\"nofollow\">Rush, Alexander M., Sumit Chopra, and Jason Weston. 2015. \"A Neural Attention Model for Abstractive Sentence Summarization.\" Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 379-389, September. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"See-et-al.-2017\"><a href=\"https://arxiv.org/abs/1704.04368\" rel=\"nofollow\">See, Abigail, Peter J. Liu, and Christopher D. Manning. 2017. \"Get To The Point: Summarization with Pointer-Generator Networks.\" arXiv, v2, April 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wong-et-al.-2008\"><a href=\"https://www.aclweb.org/anthology/C08-1124/\" rel=\"nofollow\">Wong, Kam-Fai, Mingli Wu, and Wenjie Li. 2008. \"Extractive Summarization Using Supervised and Semi-Supervised Learning.\" Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pp. 985-992, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wu-2006\"><a href=\"https://www.aclweb.org/anthology/P06-3007/\" rel=\"nofollow\">Wu, Mingli. 2006. \"Investigations on Event-Based Summarization.\" Proceedings of the COLING/ACL 2006 Student Research Workshop, pp. 37-42, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"i2-Decisions-2019\"><a href=\"https://www.i2decisions.com/case-studies/text-summarization\" rel=\"nofollow\">i2 Decisions. 2019. \"Text Summarization.\" Case Studies, i2 Decisions, April 5. Updated 2019-05-21. Accessed 2020-02-20.</a></li></ol></div><div class=\"article-right uk-width-medium-2-5\"><h2 class=\"sec-milestones\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones\" id=\"cd-timeline\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Tags</h2>\n",
              " <i class=\"uk-icon-tags uk-icon-large pull-left\"></i>\n",
              " <div class=\"article-tags\">\n",
              " <a href=\"/site-map/browse-articles/algorithms\" rel=\"nofollow\">algorithms</a>\n",
              " <a href=\"/site-map/browse-articles/natural+language+processing\" rel=\"nofollow\">natural language processing</a>\n",
              " <a href=\"/site-map/browse-articles/text+analytics\" rel=\"nofollow\">text analytics</a>\n",
              " </div><h2>See Also</h2>\n",
              " <ul><li><a href=\"/natural-language-generation\">Natural Language Generation</a></li>\n",
              " <li><a href=\"/natural-language-understanding\">Natural Language Understanding</a></li>\n",
              " <li>Computational Discourse <a href=\"/site-map/add-article?title=Computational+Discourse\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/question-answering\">Question Answering</a></li>\n",
              " <li>Chatbot <a href=\"/site-map/add-article?title=Chatbot\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/speech-recognition\">Speech Recognition</a></li></ul><h2>Further Reading<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-further-reading\"><li><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/\" rel=\"nofollow\">Paulus, Romain, Caiming Xiong, and Richard Socher. 2020. \"Your TL;DR by an AI: A Deep Reinforced Model for Abstractive Summarization.\" Salesforce Einstein, Salesforce. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li></ol><h2>Article Stats</h2>\n",
              " <div class=\"uk-modal\" id=\"author-stats-modal\">\n",
              " <div class=\"author-stats-modal uk-modal-dialog\">\n",
              " <a class=\"uk-modal-close uk-close\"></a>\n",
              " <h2>Author-wise Stats for Article Edits</h2><a href=\"\"></a>\n",
              " <div class=\"uk-grid table-head\">\n",
              " <div class=\"uk-width-medium-1-3\">Author</div>\n",
              " <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid dashboard-table\">\n",
              " <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>\n",
              " <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid author-stats-table-footer\"><div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div></div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>\n",
              " Words<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Chats<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>\n",
              " Authors<br/>\n",
              " </div>\n",
              " </a>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>\n",
              " Edits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Likes<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>\n",
              " Hits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div><h2>Cite As</h2>\n",
              " <div class=\"article-cite-as\">Devopedia. 2020. \"Text Summarization.\" Version 2, February 21. Accessed 2020-05-17. https://devopedia.org/text-summarization</div><button class=\"uk-button uk-button-mini\" type=\"button\">Copy citation</button></div></div>\n",
              " </article>\n",
              " </main>\n",
              " </div>\n",
              " </div>, <div class=\"tm-main uk-width-medium-1-1 uk-flex-order-last\">\n",
              " <main class=\"tm-content\" id=\"tm-content\">\n",
              " <div id=\"system-message-container\">\n",
              " </div>\n",
              " <div id=\"base-url\" style=\"display:none\"></div><input id=\"token-for-diff\" name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> <a class=\"outer-close-icon\" style=\"display:none\"><i class=\"uk-icon-close\"></i></a>\n",
              " <div class=\"uk-modal\" id=\"diff-draft-modal\"></div>\n",
              " <div class=\"pull-right\">\n",
              " <nav class=\"article-hover-links\" data-aid=\"261\" data-ispub=\"\">\n",
              " <span class=\"article-page-like\" data-vid=\"0\">\n",
              " <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Like this page\"></i><br/>\n",
              " </span>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-share\" id=\"offcanvas-share-link\"><i class=\"uk-icon-justify uk-icon-share-alt\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Share article\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-share\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <div class=\"a2a_kit a2a_kit_size_32 a2a_default_style\">\n",
              " <a class=\"a2a_button_facebook\"></a>\n",
              " <a class=\"a2a_button_twitter\"></a>\n",
              " <a class=\"a2a_button_linkedin\"></a>\n",
              " <a class=\"a2a_button_reddit\"></a>\n",
              " <a class=\"a2a_button_whatsapp\"></a>\n",
              " <a class=\"a2a_button_email\"></a>\n",
              " </div>\n",
              " <script>\n",
              "                         var a2a_config = a2a_config || {};\n",
              "                         a2a_config.onclick = 1;\n",
              "                     </script>\n",
              " <script async=\"\" src=\"https://static.addtoany.com/menu/page.js\"></script>\n",
              " </div>\n",
              " </div>\n",
              " <i class=\"uk-icon-justify article-showhide-links uk-icon-unlink\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Toggle hyperlinks\"></i><br/>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-compare\" id=\"offcanvas-compare-link\"><i class=\"uk-icon-justify uk-icon-files-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Compare versions\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-compare\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Article Versions</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-hover-versions\">\n",
              " <li class=\" \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">2</span> <span class=\"user-datetime\">2020-02-21 17:22:09</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1977\"><i class=\"icon-blank uk-icon-justify\"></i><a class=\"diff-versions uk-icon-justify uk-icon-exchange\" data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" href=\"#diff-modal\" title=\"Diff with\n",
              " previous\"><span class=\"hidden-ids\">1977,1975</span></a> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  Content done. Images added. Publishing.<br/></li><li class=\"last-one \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">1</span> <span class=\"user-datetime\">2020-02-20 06:53:06</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1975\"><i class=\"uk-icon-justify uk-icon-eye-slash\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Unpublished\n",
              " version\"></i> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  First version, no content yet.<br/></li> </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-versions\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older versions\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-modal\" id=\"diff-modal\"></div>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-chatroom\" id=\"offcanvas-chatroom-link\"><i class=\"uk-icon-justify uk-icon-comments-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Discuss this page\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-chatroom\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Chat Room</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-chat-msgs\">\n",
              " <li>\n",
              " <div id=\"chat-save-error\"></div>\n",
              " <div class=\"savenewmsg pull-right\" style=\"display:none\">Submitting ...</div>\n",
              " <div class=\"uk-alert uk-alert-warning\" id=\"chat-edit-desc\" style=\"display:none\">You are editing an existing chat message.</div>\n",
              " <form id=\"chat-form\">\n",
              " <input id=\"savedVersion\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"savedSection\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"chatid\" type=\"hidden\" value=\"0\"/>\n",
              " <select id=\"chat-article-version\" name=\"version\">\n",
              " <option selected=\"selected\" value=\"0\">All Versions</option><option class=\"user-datetime\" value=\"1977\">2020-02-21 17:22:09 by arvindpdmn</option><option class=\"user-datetime\" value=\"1975\">2020-02-20 06:53:06 by arvindpdmn</option> </select>\n",
              " <select id=\"chat-article-section\" name=\"section\">\n",
              " <option selected=\"selected\" value=\"All Sections\">All Sections</option><option value=\"Summary\">Summary</option><option value=\"Discussion\">Discussion</option><option value=\"Sample Code\">Sample Code</option><option value=\"References\">References</option><option value=\"Milestones\">Milestones</option><option value=\"Tags\">Tags</option><option value=\"See Also\">See Also</option><option value=\"Further Reading\">Further Reading</option> </select>\n",
              " </form>\n",
              " </li>\n",
              " </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-msgs\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older messages\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " </nav>\n",
              " </div>\n",
              " <div class=\"uk-modal\" id=\"image-slideshow\"> <div class=\"image-slideshow uk-modal-dialog\"><a class=\"uk-modal-close uk-close\"></a><a href=\"/\"></a> <i class=\"uk-icon uk-icon-chevron-left pull-left\" id=\"prev-img\"></i> <i class=\"uk-icon uk-icon-chevron-right pull-right\" id=\"next-img\"></i> <ul id=\"inner-slides\"><li id=\"slide-0\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/></div></li><li id=\"slide-1\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/></div></li><li id=\"slide-2\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/></div></li><li id=\"slide-3\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/></div></li><li id=\"slide-4\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Multi-document graph. Source: Radev 2000, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/></div></li><li id=\"slide-5\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/></div></li><li id=\"slide-6\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/></div></li><li id=\"slide-7\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/></div></li><li id=\"slide-8\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Architecture of BERTSUM. Source: Liu 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/></div></li><li id=\"slide-9\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/></div></li><li id=\"slide-10\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/></div></li><li id=\"slide-11\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/></div></li><li id=\"slide-12\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/></div></li><li id=\"slide-13\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/></div></li><li id=\"slide-14\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/></div></li> </ul> </div></div>\n",
              " <article class=\"uk-article tm-blog-single \">\n",
              " <h1 class=\"uk-article-title\">\n",
              " \t\t\t\t\tText Summarization\t\t\t</h1>\n",
              " <div class=\"uk-grid article-top-authors\" data-uk-grid-margin=\"\"><div class=\"uk-width-medium-3-5\"><div class=\"uk-grid star-contribs\"><div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><br/><a href=\"/user/arvindpdmn\">arvindpdmn</a><br/>1638 DevCoins</div></div></div><div class=\"uk-width-medium-2-5\"><a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">1 author has contributed to this article</a><br/>Last updated by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-21 17:22:09</span><br/>Created by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-20 06:53:06</span></div></div><div class=\"uk-grid\" data-uk-grid-margin=\"\"><div class=\"article-left uk-width-medium-3-5\"><h2 class=\"topper\">Summary</h2>\n",
              " <div id=\"summary-text-wrapper\"><div id=\"summary-text\"><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-0\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/><div class=\"uk-thumbnail-caption\">Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>On the web, everyone can be a publisher. We're already seeing vast amounts of information being published daily in the form of restaurant/movie/book reviews, blogs, status updates, and more. In addition, traditional print publications (newspapers, magazines, technical journals, whitepapers) are also available online. It's impossible for anyone to keep track of recent publications even if limited to one domain. This is where text summarization can help.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup>\n",
              " </p>\n",
              " <p>A summary, created automatically by algorithms, typically contains the most important information. The summary should be mindful of the reader and the communication goals. It may also help the reader decide if the original text is worth reading in full. The summary can also help improve document indexing for information retrieval. An automated summary is often less biased than a human-written summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> </p></div></div><h2 class=\"sec-milestones-small\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones-small\" id=\"cd-timeline-small\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Discussion</h2>\n",
              " <ul class=\"uk-list uk-list-space article-discussion-list\"><li><article-question>What are some real-world applications of text summarization?</article-question>\n",
              " <article-answer><p>Here are some everyday examples of text summarization: news headlines, outlines for students, movie previews, meeting minutes, biographies for resumes or obituaries, abridged versions of books,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> newsletter production, financial research, patent research, legal contract analysis, tweeting about new content, chatbots that answer questions, email summaries, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>When Google Search presents search results, some entries are accompanied by auto-generated summaries. Google may be leveraging a knowledge graph for this purpose. Google's approach to summarization is mainly entity centric. Summarization extends to timelines and events about entities.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-2017\" title=\"Li 2017\"></a></sup> </p>\n",
              " <p>Doctors write long medical notes containing nutritional information for pregnant mothers. When these were reduced to short crisp summaries, pregnant mothers found them a lot easier to understand.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#i2-Decisions-2019\" title=\"i2 Decisions 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Which are the main approaches to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-9\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/><div class=\"uk-thumbnail-caption\">Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>With <strong>extractive summarization</strong>, summary contains sentences picked and reproduced verbatim from the original text. With <strong>abstractive summarization</strong>, the algorithm interprets the text and generates a summary, possibly using new phrases and sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>Extractive summarization is data-driven, easier and often gives better results. Abstractive summarization is how humans tend to summarize text but it's hard for algorithms since it involves semantic representation, inference and natural language generation. Often abstractive summarization relies on text extracts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> </p>\n",
              " <p>For extraction, sentences are scored and those with highest scores are selected. Scoring criteria may include word frequencies, location heuristics, sentence similarity, rhetorical relations, and semantic roles.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995, sec. 2\"></a></sup> </p>\n",
              " <p>Typically an intermediate representation is used to select relevant summary content. With <strong>topic representation</strong>, the intent is to identify the main topics in the text. Topic words, word frequencies (including <abbr data-title=\"» Term Frequency Inverse Document Frequency\">TF-IDF</abbr>), clustering, <abbr data-title=\"» Latent Semantic Analysis\">LSA</abbr> and <abbr data-title=\"» Latent Dirichlet Allocation\">LDA</abbr> have been applied to summarization. With <strong>indicator representation</strong>, a feature set is used to rank and select sentences. Examples of this approach are graph-based methods and machine learning.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>What are the challenges and requirements of multi-document summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-10\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/><div class=\"uk-thumbnail-caption\">Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The pipeline for multi-document summarization (<abbr data-title=\"» Multi Document Summarization\">MDS</abbr>) has the same basic steps as for single-document summarization (<abbr data-title=\"» Single Document Summarization\">SDS</abbr>): content selection, information ordering, and sentence realization. However, <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> has some unique challenges:<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 1\"></a></sup> <ul class=\"list-in-ans\"><li><strong>Redundancy</strong>: A single document has far less redundancy than a topically-related group of documents. Summary shouldn't repeat similar sentences. <em>Maximal Marginal Relevance (<abbr data-title=\"» Maximal Marginal Relevance\">MMR</abbr>)</em> is a scoring system to penalize similar sentences.</li><li><strong>Temporal Ordering</strong>: A stream of news articles might be reporting the unfolding of an event. Summary should order them correctly and be sensitive to later developments overriding earlier ones.</li><li><strong>Cohesion and Coreference</strong>: Both are important for information ordering. Sometimes cohesion might demand a certain ordering but cause coreference problems, such as a person's shortened name appearing before the full name.</li><li><strong>Compression Ratio</strong>: Summarization becomes more difficult when more compression is demanded.</li></ul>\n",
              " <p><abbr data-title=\"» Multi Document Summarization\">MDS</abbr> may cluster similar documents and passages. Summary should include sufficient context and right level of detail. Factual inconsistencies across documents can be reported. Finally, users must be allowed to filter out irrelevant content, dig deeper into the the sources via attribution, or compare related passages across documents.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 3\"></a></sup> </p></p></article-answer></li>\n",
              " <li><article-question>How does text summarization vary across domains or contexts?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-11\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/><div class=\"uk-thumbnail-caption\">IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Summarization must tune its output to each domain or context. For example, summarization of a news article would involve different considerations from that of a corporate sales report.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>General text summarization techniques might not do well for specific domains. Summarizers therefore might wish to use domain-specific knowledge. For legal document summarization, <em>CaseSummarizer</em> is a tool.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Polsley-et-al.-2016\" title=\"Polsley et al. 2016\"></a></sup> In biomedical domain, summaries are created of literature, treatments, drug information, clinical notes, health records, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Moradi-and-Ghadiri-2019\" title=\"Moradi and Ghadiri 2019\"></a></sup> </p>\n",
              " <p>Summarizing scientific literature is a challenge due to length, complexity, and structure (tables and figures). <em>IBM Science Summarizer</em> is a tool that IBM created to summarize computer science publications. It extracts domain-specific entities of types task, dataset and metric.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019\"></a></sup> </p>\n",
              " <p>Often there are extra clues about what might be important in a document. Summarization can use these for content selection. For example, comments and discussions on a blog post point to interesting content segments. Likewise, citations in scientific papers are useful pointers. For web summarization, it's possible to look at other pages linking to a particular page and determine the most suitable sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 5\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How has machine learning been applied to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-12\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/><div class=\"uk-thumbnail-caption\">Some features used by an <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The common <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> approach is to view text summarization as a classification problem. Algorithm is trained in a supervised manner on original text, an extractive summary and a set of features. Algorithm learns to classify sentences as either summary sentences or non-summary sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p>\n",
              " <p>Classifiers could be based on naive-Bayes, decision trees, <abbr data-title=\"» Support Vector Machines\">SVM</abbr>, <abbr data-title=\"» Hidden Markov Model\">HMM</abbr>, and <abbr data-title=\"» Conditional Random Field\">CRF</abbr>. Often each sentence is classified independently of others. However, since <abbr data-title=\"» Hidden Markov Model\">HMM</abbr> and <abbr data-title=\"» Conditional Random Field\">CRF</abbr> capture dependencies, they outperform other techniques.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 2.2\"></a></sup> </p>\n",
              " <p>The problem with supervised algorithms is in creating labelled data for training. This problem is worse for <abbr data-title=\"» Multi Document Summarization\">MDS</abbr>.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> In a semi-supervised approach, a small amount of labelled data is used along with much larger amount of unlabelled data. The algorithm learns iteratively by classifying some unlabelled data in each iteration.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Could you describe neural network architectures for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-13\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/><div class=\"uk-thumbnail-caption\">Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The typical approach is to do <strong>sequence-to-sequence modelling</strong> since input is a sequence of words and the summary is also a sequence of words. In an encoder-decoder architecture, the encoder uses <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> to give an input representation. The decoder is also an <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> that generates the output sequence. An attention layer between the encoder and the decoder helps in determining the most relevant words for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pawar-2018\" title=\"Pawar 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pai-2019\" title=\"Pai 2019\"></a></sup> </p>\n",
              " <p>Seq2seq models, <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr>s and attention layers have made abstractive summarization possible, even if they're not yet state-of-the-art compared to extractive summarization methods. These models are trained <strong>end-to-end</strong> without bothering to model each step of a traditional summarization pipeline. They also don't need access to specialized vocabulary or do pre-processing.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> This end-to-end approach has been applied successfully to short output sequences, such as news headlines or short email responses.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>In a <strong>pointer-generator</strong> network, a generator provides new words whereas a pointer copies words from source text. Seq2seq models often produce repetitive sentences. A <strong>coverage model</strong> avoids repetitions.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017\"></a></sup> </p>\n",
              " <p>Fernandes et al. showed that sequence encoders with a graph component does better at capturing long-distance relationships.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fernandes-et-al.-2019\" title=\"Fernandes et al. 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How do I evaluate text summarization algorithms?</article-question>\n",
              " <article-answer><p>Human evaluation is the simplest. In 2004, <strong>Recall-Oriented Understudy for Gisting Evaluation (ROUGE)</strong> was created to automate evaluation by comparing against hand-crafted summaries. ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S, and ROUGE-SU are some metrics in this family.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 5.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p>\n",
              " <p>Different people produce different summaries of the same text. Meaning shared across different human summaries is called Summary Content Unit (<abbr data-title=\"» Summary Content Unit\">SCU</abbr>). With a focus on meaning, <strong>Pyramid Method</strong> evaluates a summary using <abbr data-title=\"» Summary Content Unit\">SCU</abbr>s.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.6\"></a></sup> </p>\n",
              " <p>While there's no universal system of metrics, text summarizers are typically evaluated based on TREC, DUC and <abbr data-title=\"» Message Understanding Conference\">MUC</abbr> systems.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 1\"></a></sup> DUC (2001-2007) became a summarization track in TAC (2008-).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#DUC-2014\" title=\"DUC 2014\"></a></sup> </p>\n",
              " <p>Datasets for supervised training of <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> algorithms are not common. For summarizing a single or a few documents, commonly used datasets are Gigaword,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail, TAC (2008-2011) and DUC (2003-2004).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> ELI5 and WikiSum can be used for longform question answering and <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> respectively.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, sec. 5.1\"></a></sup> <a class=\"article-link\" href=\"http://kavita-ganesan.com/opinosis-opinion-dataset\" rel=\"nofollow\">Opinosis</a> is a dataset of 51 article-summary pairs.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Released in 2018, <a class=\"article-link\" href=\"https://summari.es/\" rel=\"nofollow\">Cornell Newsroom</a> is the largest dataset for training and evaluating summarization systems. Spanning 1998-2017 and containing 1.3 million articles, it's been collected from newsrooms of 38 major publications. Summaries are obtained from search and social metadata.</p></article-answer></li>\n",
              " <li><article-question>What are some useful resources for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-14\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/><div class=\"uk-thumbnail-caption\">MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Pengfei Liu has curated a <a class=\"article-link\" href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">useful list</a> of datasets, research papers, and groups researching on text summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2020\" title=\"Liu 2020\"></a></sup> </p>\n",
              " <p>In Python, Gensim has a module for text summarization, which implements <em>TextRank</em> algorithm. An original implementation of the same algorithm is available as PyTextRank package. PyTeaser is a Python implementation of Scala's TextTeaser.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Back in 2016, Google released a baseline TensorFlow implementation for summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p></article-answer></li></ul><h2>References<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-citations\"><li id=\"Allahyari-et-al.-2017\"><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Barzilay-and-Lee-2004\"><a href=\"https://www.aclweb.org/anthology/N04-1015/\" rel=\"nofollow\">Barzilay, Regina, and Lillian Lee. 2004. \"Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization.\" Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004, pp. 113-120, May. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Brownlee-2017\"><a href=\"https://machinelearningmastery.com/gentle-introduction-text-summarization/\" rel=\"nofollow\">Brownlee, Jason. 2017. \"A Gentle Introduction to Text Summarization.\" Machine Learning Mastery, August 7. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Chauhan-2018\"><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"DUC-2014\"><a href=\"https://duc.nist.gov/\" rel=\"nofollow\">DUC. 2014. \"Document Understanding Conferences: Homepage.\" NIST, September 9. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Das-and-Martins-2007\"><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Edmundson-1969\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/edmonson69.pdf\" rel=\"nofollow\">Edmundson, H. P. 1969. \"New Methods in Automatic Extracting.\" Journal of the ACM, vol. 16, no. 2, pp. 264-285, April. doi:10.1145/321510.321519. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Erera-et-al.-2019\"><a href=\"https://www.aclweb.org/anthology/D19-3036/\" rel=\"nofollow\">Erera, Shai, Michal Shmueli-Scheuer, Guy Feigenblat, Ora Peled Nakash, Odellia Boni, Haggai Roitman, Doron Cohen, Bar Weiner, Yosi Mass, Or Rivlin, Guy Lev, Achiya Jerbi, Jonathan Herzig, Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin, Francesca Bonin, and David Konopnicki. 2019. \"A Summarization System for Scientific Documents.\" Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 211-216, November. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fan-et-al.-2019\"><a href=\"https://arxiv.org/abs/1910.08435\" rel=\"nofollow\">Fan, Angela, Claire Gardent, Chloe Braud, and Antoine Bordes. 2019. \"Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs.\" arXiv, v1, October 18. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fernandes-et-al.-2019\"><a href=\"https://arxiv.org/abs/1811.01824\" rel=\"nofollow\">Fernandes, Patrick, Miltiadis Allamanis, and Marc Brockschmidt. 2019. \"Structured Neural Summarization.\" arXiv, v2, February 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Goldstein-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0405/\" rel=\"nofollow\">Goldstein, Jade, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. \"Multi-Document Summarization By Sentence Extraction.\" NAACL-ANLP 2000 Workshop: Automatic Summarization. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Jurafsky-and-Martin-2009\"><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel, and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kumar-et-al.-2016\"><a href=\"https://thescipub.com/PDF/jcssp.2016.178.190.pdf\" rel=\"nofollow\">Kumar, Yogan Jaya, Ong Sing Goh, Halizah Basiron, Ngo Hea Choon, and Puspalata C Suppiah. 2016. \"A Review on Automatic Text Summarization Approaches.\" J. of Comp. Sci., Science Publications, April 29. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kupiec-et-al.-1995\"><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.7100&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">Kupiec, Julian, Jan Pedersen, and Francine Chen. 1995. \"A trainable document summarizer.\" SIGIR '95: Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 68-73, July. doi:10.1145/215206.215333. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Lebanoff-et-al.-2018\"><a href=\"https://arxiv.org/abs/1808.06218\" rel=\"nofollow\">Lebanoff, Logan, Kaiqiang Song, and Fei Liu. 2018. \"Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization.\" arXiv, v2, August 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-2017\"><a href=\"https://medium.com/@wenchen.li/text-summarization-applications-ed319f0bb13c\" rel=\"nofollow\">Li, Wenchen. 2017. \"Text summarization: applications.\" Medium, May 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-et-al.-2006\"><a href=\"https://www.aclweb.org/anthology/P06-1047/\" rel=\"nofollow\">Li, Wenjie, Mingli Wu, Qin Lu, Wei Xu, and Chunfa Yuan. 2006. \"Extractive Summarization using Inter- and Intra- Event Relevance.\" Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pp. 369-376, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2019\"><a href=\"https://arxiv.org/abs/1903.10318\" rel=\"nofollow\">Liu, Yang. 2019. \"Fine-tune BERT for Extractive Summarization.\" arXiv, v2, September 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2020\"><a href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">Liu, Pengfei. 2020. \"Modern History for Text Summarization.\" NLP Historiograpy. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-and-Pan-2016\"><a href=\"https://ai.googleblog.com/2016/08/text-summarization-with-tensorflow.html\" rel=\"nofollow\">Liu, Peter, and Xin Pan. 2016. \"Text summarization with TensorFlow.\" Google AI Blog, August 24. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-et-al.-2018\"><a href=\"https://arxiv.org/abs/1801.10198\" rel=\"nofollow\">Liu, Peter J., Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. 2018. \"Generating Wikipedia by Summarizing Long Sequences.\" arXiv, v1, January 30. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Luhn-1958\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf\" rel=\"nofollow\">Luhn, H. P. 1958. \"The automatic creation of literature abstracts.\" IBM Journal of Research and Development, pp. 159-165, April. doi:10.1147/rd.22.0159. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Marcu-1997\"><a href=\"https://www.cs.toronto.edu/pub/gh/Marcu-PhDthesis.pdf\" rel=\"nofollow\">Marcu, Daniel. 1997. \"The Rhetorical Parsing, Summarization, and Generation of Natural Language Texts.\" PhD Thesis, University of Toronto, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mathur-et-al.-2017\"><a href=\"https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/\" rel=\"nofollow\">Mathur, Pranay, Aman Gill, and Aayush Yadav. 2017. \"Text Summarization in Python: Extractive vs. Abstractive techniques revisited.\" Rare Technologies, April 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Meyer-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/P16-4017/\" rel=\"nofollow\">Meyer, Christian M., Darina Benikova, Margot Mieskes, and Iryna Gurevych. 2016. \"MDSWriter: Annotation Tool for Creating High-Quality Multi-Document Summarization Corpora.\" Proceedings of ACL-2016 System Demonstrations, pp. 97-102, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mihalcea-2004\"><a href=\"https://www.aclweb.org/anthology/P04-3020/\" rel=\"nofollow\">Mihalcea, Rada. 2004. \"Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization.\" Proceedings of the ACL Interactive Poster and Demonstration Sessions, pp. 170-173, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Moradi-and-Ghadiri-2019\"><a href=\"https://arxiv.org/abs/1908.02285\" rel=\"nofollow\">Moradi, Milad, and Nasser Ghadiri. 2019. \"Text Summarization in the Biomedical Domain.\" arXiv, v1, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Nallapati-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/K16-1028/\" rel=\"nofollow\">Nallapati, Ramesh, Bowen Zhou, Cicero dos Santos, Çağlar Gu̇lçehre, and Bing Xiang. 2016. \"Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.\" Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, ACL, pp. 280-290, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Opidi-2019\"><a href=\"https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/\" rel=\"nofollow\">Opidi, Alfrick. 2019. \"A Gentle Introduction to Text Summarization in Machine Learning.\" Blog, FloydHub, April 15. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pai-2019\"><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pawar-2018\"><a href=\"https://medium.com/@i_am_manish/ai-text-summarizer-2de0b07bc27\" rel=\"nofollow\">Pawar, Manish. 2018. \"Ai Text Summarizer.\" Medium, November 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Polsley-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/C16-2054/\" rel=\"nofollow\">Polsley, Seth, Pooja Jhunjhunwala, and Ruihong Huang. 2016. \"CaseSummarizer: A System for Automated Summarization of Legal Texts.\" Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pp. 258-262, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-2000\"><a href=\"https://www.aclweb.org/anthology/W00-1009/\" rel=\"nofollow\">Radev, Dragomir. 2000. \"A Common Theory of Information Fusion from Multiple Text Sources Step One: Cross-Document Structure.\" 1st SIGdial Workshop on Discourse and Dialogue, ACL, pp. 74-83, October. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0403/\" rel=\"nofollow\">Radev, Dragomir R., Hongyan Jing, and Malgorzata Budzikowska. 2000. \"Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies.\" NAACL-ANLP 2000 Workshop: Automatic Summarization, v2, April. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Ratia-2018\"><a href=\"https://blog.frase.io/20-applications-of-automatic-summarization-in-the-enterprise/\" rel=\"nofollow\">Ratia, Tomas. 2018. \"20 Applications of Automatic Summarization in the Enterprise.\" Blog, Frase, July 17. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Rush-et-al.-2015\"><a href=\"https://www.aclweb.org/anthology/D15-1044/\" rel=\"nofollow\">Rush, Alexander M., Sumit Chopra, and Jason Weston. 2015. \"A Neural Attention Model for Abstractive Sentence Summarization.\" Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 379-389, September. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"See-et-al.-2017\"><a href=\"https://arxiv.org/abs/1704.04368\" rel=\"nofollow\">See, Abigail, Peter J. Liu, and Christopher D. Manning. 2017. \"Get To The Point: Summarization with Pointer-Generator Networks.\" arXiv, v2, April 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wong-et-al.-2008\"><a href=\"https://www.aclweb.org/anthology/C08-1124/\" rel=\"nofollow\">Wong, Kam-Fai, Mingli Wu, and Wenjie Li. 2008. \"Extractive Summarization Using Supervised and Semi-Supervised Learning.\" Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pp. 985-992, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wu-2006\"><a href=\"https://www.aclweb.org/anthology/P06-3007/\" rel=\"nofollow\">Wu, Mingli. 2006. \"Investigations on Event-Based Summarization.\" Proceedings of the COLING/ACL 2006 Student Research Workshop, pp. 37-42, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"i2-Decisions-2019\"><a href=\"https://www.i2decisions.com/case-studies/text-summarization\" rel=\"nofollow\">i2 Decisions. 2019. \"Text Summarization.\" Case Studies, i2 Decisions, April 5. Updated 2019-05-21. Accessed 2020-02-20.</a></li></ol></div><div class=\"article-right uk-width-medium-2-5\"><h2 class=\"sec-milestones\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones\" id=\"cd-timeline\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Tags</h2>\n",
              " <i class=\"uk-icon-tags uk-icon-large pull-left\"></i>\n",
              " <div class=\"article-tags\">\n",
              " <a href=\"/site-map/browse-articles/algorithms\" rel=\"nofollow\">algorithms</a>\n",
              " <a href=\"/site-map/browse-articles/natural+language+processing\" rel=\"nofollow\">natural language processing</a>\n",
              " <a href=\"/site-map/browse-articles/text+analytics\" rel=\"nofollow\">text analytics</a>\n",
              " </div><h2>See Also</h2>\n",
              " <ul><li><a href=\"/natural-language-generation\">Natural Language Generation</a></li>\n",
              " <li><a href=\"/natural-language-understanding\">Natural Language Understanding</a></li>\n",
              " <li>Computational Discourse <a href=\"/site-map/add-article?title=Computational+Discourse\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/question-answering\">Question Answering</a></li>\n",
              " <li>Chatbot <a href=\"/site-map/add-article?title=Chatbot\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/speech-recognition\">Speech Recognition</a></li></ul><h2>Further Reading<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-further-reading\"><li><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/\" rel=\"nofollow\">Paulus, Romain, Caiming Xiong, and Richard Socher. 2020. \"Your TL;DR by an AI: A Deep Reinforced Model for Abstractive Summarization.\" Salesforce Einstein, Salesforce. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li></ol><h2>Article Stats</h2>\n",
              " <div class=\"uk-modal\" id=\"author-stats-modal\">\n",
              " <div class=\"author-stats-modal uk-modal-dialog\">\n",
              " <a class=\"uk-modal-close uk-close\"></a>\n",
              " <h2>Author-wise Stats for Article Edits</h2><a href=\"\"></a>\n",
              " <div class=\"uk-grid table-head\">\n",
              " <div class=\"uk-width-medium-1-3\">Author</div>\n",
              " <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid dashboard-table\">\n",
              " <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>\n",
              " <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid author-stats-table-footer\"><div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div></div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>\n",
              " Words<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Chats<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>\n",
              " Authors<br/>\n",
              " </div>\n",
              " </a>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>\n",
              " Edits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Likes<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>\n",
              " Hits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div><h2>Cite As</h2>\n",
              " <div class=\"article-cite-as\">Devopedia. 2020. \"Text Summarization.\" Version 2, February 21. Accessed 2020-05-17. https://devopedia.org/text-summarization</div><button class=\"uk-button uk-button-mini\" type=\"button\">Copy citation</button></div></div>\n",
              " </article>\n",
              " </main>\n",
              " </div>, <div id=\"system-message-container\">\n",
              " </div>, <div id=\"base-url\" style=\"display:none\"></div>, <div class=\"uk-modal\" id=\"diff-draft-modal\"></div>, <div class=\"pull-right\">\n",
              " <nav class=\"article-hover-links\" data-aid=\"261\" data-ispub=\"\">\n",
              " <span class=\"article-page-like\" data-vid=\"0\">\n",
              " <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Like this page\"></i><br/>\n",
              " </span>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-share\" id=\"offcanvas-share-link\"><i class=\"uk-icon-justify uk-icon-share-alt\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Share article\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-share\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <div class=\"a2a_kit a2a_kit_size_32 a2a_default_style\">\n",
              " <a class=\"a2a_button_facebook\"></a>\n",
              " <a class=\"a2a_button_twitter\"></a>\n",
              " <a class=\"a2a_button_linkedin\"></a>\n",
              " <a class=\"a2a_button_reddit\"></a>\n",
              " <a class=\"a2a_button_whatsapp\"></a>\n",
              " <a class=\"a2a_button_email\"></a>\n",
              " </div>\n",
              " <script>\n",
              "                         var a2a_config = a2a_config || {};\n",
              "                         a2a_config.onclick = 1;\n",
              "                     </script>\n",
              " <script async=\"\" src=\"https://static.addtoany.com/menu/page.js\"></script>\n",
              " </div>\n",
              " </div>\n",
              " <i class=\"uk-icon-justify article-showhide-links uk-icon-unlink\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Toggle hyperlinks\"></i><br/>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-compare\" id=\"offcanvas-compare-link\"><i class=\"uk-icon-justify uk-icon-files-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Compare versions\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-compare\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Article Versions</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-hover-versions\">\n",
              " <li class=\" \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">2</span> <span class=\"user-datetime\">2020-02-21 17:22:09</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1977\"><i class=\"icon-blank uk-icon-justify\"></i><a class=\"diff-versions uk-icon-justify uk-icon-exchange\" data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" href=\"#diff-modal\" title=\"Diff with\n",
              " previous\"><span class=\"hidden-ids\">1977,1975</span></a> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  Content done. Images added. Publishing.<br/></li><li class=\"last-one \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">1</span> <span class=\"user-datetime\">2020-02-20 06:53:06</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1975\"><i class=\"uk-icon-justify uk-icon-eye-slash\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Unpublished\n",
              " version\"></i> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  First version, no content yet.<br/></li> </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-versions\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older versions\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-modal\" id=\"diff-modal\"></div>\n",
              " <a data-uk-offcanvas=\"{mode:'slide'}\" href=\"#offcanvas-chatroom\" id=\"offcanvas-chatroom-link\"><i class=\"uk-icon-justify uk-icon-comments-o\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Discuss this page\"></i></a><br/>\n",
              " <div class=\"uk-offcanvas\" id=\"offcanvas-chatroom\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Chat Room</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-chat-msgs\">\n",
              " <li>\n",
              " <div id=\"chat-save-error\"></div>\n",
              " <div class=\"savenewmsg pull-right\" style=\"display:none\">Submitting ...</div>\n",
              " <div class=\"uk-alert uk-alert-warning\" id=\"chat-edit-desc\" style=\"display:none\">You are editing an existing chat message.</div>\n",
              " <form id=\"chat-form\">\n",
              " <input id=\"savedVersion\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"savedSection\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"chatid\" type=\"hidden\" value=\"0\"/>\n",
              " <select id=\"chat-article-version\" name=\"version\">\n",
              " <option selected=\"selected\" value=\"0\">All Versions</option><option class=\"user-datetime\" value=\"1977\">2020-02-21 17:22:09 by arvindpdmn</option><option class=\"user-datetime\" value=\"1975\">2020-02-20 06:53:06 by arvindpdmn</option> </select>\n",
              " <select id=\"chat-article-section\" name=\"section\">\n",
              " <option selected=\"selected\" value=\"All Sections\">All Sections</option><option value=\"Summary\">Summary</option><option value=\"Discussion\">Discussion</option><option value=\"Sample Code\">Sample Code</option><option value=\"References\">References</option><option value=\"Milestones\">Milestones</option><option value=\"Tags\">Tags</option><option value=\"See Also\">See Also</option><option value=\"Further Reading\">Further Reading</option> </select>\n",
              " </form>\n",
              " </li>\n",
              " </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-msgs\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older messages\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>\n",
              " </nav>\n",
              " </div>, <div class=\"uk-offcanvas\" id=\"offcanvas-share\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <div class=\"a2a_kit a2a_kit_size_32 a2a_default_style\">\n",
              " <a class=\"a2a_button_facebook\"></a>\n",
              " <a class=\"a2a_button_twitter\"></a>\n",
              " <a class=\"a2a_button_linkedin\"></a>\n",
              " <a class=\"a2a_button_reddit\"></a>\n",
              " <a class=\"a2a_button_whatsapp\"></a>\n",
              " <a class=\"a2a_button_email\"></a>\n",
              " </div>\n",
              " <script>\n",
              "                         var a2a_config = a2a_config || {};\n",
              "                         a2a_config.onclick = 1;\n",
              "                     </script>\n",
              " <script async=\"\" src=\"https://static.addtoany.com/menu/page.js\"></script>\n",
              " </div>\n",
              " </div>, <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <div class=\"a2a_kit a2a_kit_size_32 a2a_default_style\">\n",
              " <a class=\"a2a_button_facebook\"></a>\n",
              " <a class=\"a2a_button_twitter\"></a>\n",
              " <a class=\"a2a_button_linkedin\"></a>\n",
              " <a class=\"a2a_button_reddit\"></a>\n",
              " <a class=\"a2a_button_whatsapp\"></a>\n",
              " <a class=\"a2a_button_email\"></a>\n",
              " </div>\n",
              " <script>\n",
              "                         var a2a_config = a2a_config || {};\n",
              "                         a2a_config.onclick = 1;\n",
              "                     </script>\n",
              " <script async=\"\" src=\"https://static.addtoany.com/menu/page.js\"></script>\n",
              " </div>, <div class=\"a2a_kit a2a_kit_size_32 a2a_default_style\">\n",
              " <a class=\"a2a_button_facebook\"></a>\n",
              " <a class=\"a2a_button_twitter\"></a>\n",
              " <a class=\"a2a_button_linkedin\"></a>\n",
              " <a class=\"a2a_button_reddit\"></a>\n",
              " <a class=\"a2a_button_whatsapp\"></a>\n",
              " <a class=\"a2a_button_email\"></a>\n",
              " </div>, <div class=\"uk-offcanvas\" id=\"offcanvas-compare\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Article Versions</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-hover-versions\">\n",
              " <li class=\" \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">2</span> <span class=\"user-datetime\">2020-02-21 17:22:09</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1977\"><i class=\"icon-blank uk-icon-justify\"></i><a class=\"diff-versions uk-icon-justify uk-icon-exchange\" data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" href=\"#diff-modal\" title=\"Diff with\n",
              " previous\"><span class=\"hidden-ids\">1977,1975</span></a> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  Content done. Images added. Publishing.<br/></li><li class=\"last-one \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">1</span> <span class=\"user-datetime\">2020-02-20 06:53:06</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1975\"><i class=\"uk-icon-justify uk-icon-eye-slash\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Unpublished\n",
              " version\"></i> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  First version, no content yet.<br/></li> </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-versions\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older versions\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>, <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Article Versions</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-hover-versions\">\n",
              " <li class=\" \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">2</span> <span class=\"user-datetime\">2020-02-21 17:22:09</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1977\"><i class=\"icon-blank uk-icon-justify\"></i><a class=\"diff-versions uk-icon-justify uk-icon-exchange\" data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" href=\"#diff-modal\" title=\"Diff with\n",
              " previous\"><span class=\"hidden-ids\">1977,1975</span></a> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  Content done. Images added. Publishing.<br/></li><li class=\"last-one \"> <div class=\"item-head\"> <span class=\"uk-icon-button\">1</span> <span class=\"user-datetime\">2020-02-20 06:53:06</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1975\"><i class=\"uk-icon-justify uk-icon-eye-slash\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Unpublished\n",
              " version\"></i> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>  First version, no content yet.<br/></li> </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-versions\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older versions\"></i>\n",
              " </a>\n",
              " </div>, <div class=\"item-head\"> <span class=\"uk-icon-button\">2</span> <span class=\"user-datetime\">2020-02-21 17:22:09</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1977\"><i class=\"icon-blank uk-icon-justify\"></i><a class=\"diff-versions uk-icon-justify uk-icon-exchange\" data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" href=\"#diff-modal\" title=\"Diff with\n",
              " previous\"><span class=\"hidden-ids\">1977,1975</span></a> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>, <div class=\"pull-right\" data-id=\"261\" data-vid=\"1977\"><i class=\"icon-blank uk-icon-justify\"></i><a class=\"diff-versions uk-icon-justify uk-icon-exchange\" data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" href=\"#diff-modal\" title=\"Diff with\n",
              " previous\"><span class=\"hidden-ids\">1977,1975</span></a> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div>, <div class=\"item-head\"> <span class=\"uk-icon-button\">1</span> <span class=\"user-datetime\">2020-02-20 06:53:06</span><div class=\"pull-right\" data-id=\"261\" data-vid=\"1975\"><i class=\"uk-icon-justify uk-icon-eye-slash\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Unpublished\n",
              " version\"></i> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div><br/>  By <a href=\"/user/arvindpdmn\">arvindpdmn</a><br/> </div>, <div class=\"pull-right\" data-id=\"261\" data-vid=\"1975\"><i class=\"uk-icon-justify uk-icon-eye-slash\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Unpublished\n",
              " version\"></i> <span class=\"num-likes\"></span> <i class=\"uk-icon-justify uk-icon-thumbs-o-up article-unliked\" data-uk-tooltip=\"{cls:'ttip',pos:'top-left'}\" title=\"Like this\n",
              " version  \"></i></div>, <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>, <div class=\"uk-modal\" id=\"diff-modal\"></div>, <div class=\"uk-offcanvas\" id=\"offcanvas-chatroom\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Chat Room</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-chat-msgs\">\n",
              " <li>\n",
              " <div id=\"chat-save-error\"></div>\n",
              " <div class=\"savenewmsg pull-right\" style=\"display:none\">Submitting ...</div>\n",
              " <div class=\"uk-alert uk-alert-warning\" id=\"chat-edit-desc\" style=\"display:none\">You are editing an existing chat message.</div>\n",
              " <form id=\"chat-form\">\n",
              " <input id=\"savedVersion\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"savedSection\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"chatid\" type=\"hidden\" value=\"0\"/>\n",
              " <select id=\"chat-article-version\" name=\"version\">\n",
              " <option selected=\"selected\" value=\"0\">All Versions</option><option class=\"user-datetime\" value=\"1977\">2020-02-21 17:22:09 by arvindpdmn</option><option class=\"user-datetime\" value=\"1975\">2020-02-20 06:53:06 by arvindpdmn</option> </select>\n",
              " <select id=\"chat-article-section\" name=\"section\">\n",
              " <option selected=\"selected\" value=\"All Sections\">All Sections</option><option value=\"Summary\">Summary</option><option value=\"Discussion\">Discussion</option><option value=\"Sample Code\">Sample Code</option><option value=\"References\">References</option><option value=\"Milestones\">Milestones</option><option value=\"Tags\">Tags</option><option value=\"See Also\">See Also</option><option value=\"Further Reading\">Further Reading</option> </select>\n",
              " </form>\n",
              " </li>\n",
              " </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-msgs\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older messages\"></i>\n",
              " </a>\n",
              " </div>\n",
              " </div>, <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip article-hover-canvas\">\n",
              " <h2>Chat Room</h2>\n",
              " <ul class=\"uk-list uk-list-line\" id=\"article-chat-msgs\">\n",
              " <li>\n",
              " <div id=\"chat-save-error\"></div>\n",
              " <div class=\"savenewmsg pull-right\" style=\"display:none\">Submitting ...</div>\n",
              " <div class=\"uk-alert uk-alert-warning\" id=\"chat-edit-desc\" style=\"display:none\">You are editing an existing chat message.</div>\n",
              " <form id=\"chat-form\">\n",
              " <input id=\"savedVersion\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"savedSection\" type=\"hidden\" value=\"\"/>\n",
              " <input id=\"chatid\" type=\"hidden\" value=\"0\"/>\n",
              " <select id=\"chat-article-version\" name=\"version\">\n",
              " <option selected=\"selected\" value=\"0\">All Versions</option><option class=\"user-datetime\" value=\"1977\">2020-02-21 17:22:09 by arvindpdmn</option><option class=\"user-datetime\" value=\"1975\">2020-02-20 06:53:06 by arvindpdmn</option> </select>\n",
              " <select id=\"chat-article-section\" name=\"section\">\n",
              " <option selected=\"selected\" value=\"All Sections\">All Sections</option><option value=\"Summary\">Summary</option><option value=\"Discussion\">Discussion</option><option value=\"Sample Code\">Sample Code</option><option value=\"References\">References</option><option value=\"Milestones\">Milestones</option><option value=\"Tags\">Tags</option><option value=\"See Also\">See Also</option><option value=\"Further Reading\">Further Reading</option> </select>\n",
              " </form>\n",
              " </li>\n",
              " </ul>\n",
              " <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>\n",
              " <a id=\"load-older-msgs\" style=\"display:none\">\n",
              " <i class=\"pull-right uk-icon uk-icon-button uk-icon-chevron-down\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Load older messages\"></i>\n",
              " </a>\n",
              " </div>, <div id=\"chat-save-error\"></div>, <div class=\"savenewmsg pull-right\" style=\"display:none\">Submitting ...</div>, <div class=\"uk-alert uk-alert-warning\" id=\"chat-edit-desc\" style=\"display:none\">You are editing an existing chat message.</div>, <div class=\"loadmsg pull-right\" style=\"display:none\">Loading ...</div>, <div class=\"uk-modal\" id=\"image-slideshow\"> <div class=\"image-slideshow uk-modal-dialog\"><a class=\"uk-modal-close uk-close\"></a><a href=\"/\"></a> <i class=\"uk-icon uk-icon-chevron-left pull-left\" id=\"prev-img\"></i> <i class=\"uk-icon uk-icon-chevron-right pull-right\" id=\"next-img\"></i> <ul id=\"inner-slides\"><li id=\"slide-0\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/></div></li><li id=\"slide-1\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/></div></li><li id=\"slide-2\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/></div></li><li id=\"slide-3\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/></div></li><li id=\"slide-4\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Multi-document graph. Source: Radev 2000, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/></div></li><li id=\"slide-5\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/></div></li><li id=\"slide-6\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/></div></li><li id=\"slide-7\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/></div></li><li id=\"slide-8\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Architecture of BERTSUM. Source: Liu 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/></div></li><li id=\"slide-9\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/></div></li><li id=\"slide-10\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/></div></li><li id=\"slide-11\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/></div></li><li id=\"slide-12\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/></div></li><li id=\"slide-13\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/></div></li><li id=\"slide-14\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/></div></li> </ul> </div></div>, <div class=\"image-slideshow uk-modal-dialog\"><a class=\"uk-modal-close uk-close\"></a><a href=\"/\"></a> <i class=\"uk-icon uk-icon-chevron-left pull-left\" id=\"prev-img\"></i> <i class=\"uk-icon uk-icon-chevron-right pull-right\" id=\"next-img\"></i> <ul id=\"inner-slides\"><li id=\"slide-0\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/></div></li><li id=\"slide-1\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/></div></li><li id=\"slide-2\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/></div></li><li id=\"slide-3\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/></div></li><li id=\"slide-4\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Multi-document graph. Source: Radev 2000, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/></div></li><li id=\"slide-5\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/></div></li><li id=\"slide-6\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/></div></li><li id=\"slide-7\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/></div></li><li id=\"slide-8\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Architecture of BERTSUM. Source: Liu 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/></div></li><li id=\"slide-9\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/></div></li><li id=\"slide-10\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/></div></li><li id=\"slide-11\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/></div></li><li id=\"slide-12\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/></div></li><li id=\"slide-13\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/></div></li><li id=\"slide-14\"> <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup></div> <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/></div></li> </ul> </div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Multi-document graph. Source: Radev 2000, fig. 4.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Architecture of BERTSUM. Source: Liu 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/></div>, <div class=\"caption\"><i class=\"uk-icon-clone slideshow-clone-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i>MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup></div>, <div class=\"wrapper\"><span class=\"img-aligner\"></span><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/></div>, <div class=\"uk-grid article-top-authors\" data-uk-grid-margin=\"\"><div class=\"uk-width-medium-3-5\"><div class=\"uk-grid star-contribs\"><div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><br/><a href=\"/user/arvindpdmn\">arvindpdmn</a><br/>1638 DevCoins</div></div></div><div class=\"uk-width-medium-2-5\"><a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">1 author has contributed to this article</a><br/>Last updated by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-21 17:22:09</span><br/>Created by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-20 06:53:06</span></div></div>, <div class=\"uk-width-medium-3-5\"><div class=\"uk-grid star-contribs\"><div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><br/><a href=\"/user/arvindpdmn\">arvindpdmn</a><br/>1638 DevCoins</div></div></div>, <div class=\"uk-grid star-contribs\"><div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><br/><a href=\"/user/arvindpdmn\">arvindpdmn</a><br/>1638 DevCoins</div></div>, <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><br/><a href=\"/user/arvindpdmn\">arvindpdmn</a><br/>1638 DevCoins</div>, <div class=\"uk-width-medium-2-5\"><a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">1 author has contributed to this article</a><br/>Last updated by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-21 17:22:09</span><br/>Created by <a href=\"/user/arvindpdmn\">arvindpdmn</a> <br class=\"device-small\"/>on <span class=\"user-datetime dt-readable\">2020-02-20 06:53:06</span></div>, <div class=\"uk-grid\" data-uk-grid-margin=\"\"><div class=\"article-left uk-width-medium-3-5\"><h2 class=\"topper\">Summary</h2>\n",
              " <div id=\"summary-text-wrapper\"><div id=\"summary-text\"><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-0\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/><div class=\"uk-thumbnail-caption\">Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>On the web, everyone can be a publisher. We're already seeing vast amounts of information being published daily in the form of restaurant/movie/book reviews, blogs, status updates, and more. In addition, traditional print publications (newspapers, magazines, technical journals, whitepapers) are also available online. It's impossible for anyone to keep track of recent publications even if limited to one domain. This is where text summarization can help.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup>\n",
              " </p>\n",
              " <p>A summary, created automatically by algorithms, typically contains the most important information. The summary should be mindful of the reader and the communication goals. It may also help the reader decide if the original text is worth reading in full. The summary can also help improve document indexing for information retrieval. An automated summary is often less biased than a human-written summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> </p></div></div><h2 class=\"sec-milestones-small\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones-small\" id=\"cd-timeline-small\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Discussion</h2>\n",
              " <ul class=\"uk-list uk-list-space article-discussion-list\"><li><article-question>What are some real-world applications of text summarization?</article-question>\n",
              " <article-answer><p>Here are some everyday examples of text summarization: news headlines, outlines for students, movie previews, meeting minutes, biographies for resumes or obituaries, abridged versions of books,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> newsletter production, financial research, patent research, legal contract analysis, tweeting about new content, chatbots that answer questions, email summaries, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>When Google Search presents search results, some entries are accompanied by auto-generated summaries. Google may be leveraging a knowledge graph for this purpose. Google's approach to summarization is mainly entity centric. Summarization extends to timelines and events about entities.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-2017\" title=\"Li 2017\"></a></sup> </p>\n",
              " <p>Doctors write long medical notes containing nutritional information for pregnant mothers. When these were reduced to short crisp summaries, pregnant mothers found them a lot easier to understand.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#i2-Decisions-2019\" title=\"i2 Decisions 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Which are the main approaches to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-9\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/><div class=\"uk-thumbnail-caption\">Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>With <strong>extractive summarization</strong>, summary contains sentences picked and reproduced verbatim from the original text. With <strong>abstractive summarization</strong>, the algorithm interprets the text and generates a summary, possibly using new phrases and sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>Extractive summarization is data-driven, easier and often gives better results. Abstractive summarization is how humans tend to summarize text but it's hard for algorithms since it involves semantic representation, inference and natural language generation. Often abstractive summarization relies on text extracts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> </p>\n",
              " <p>For extraction, sentences are scored and those with highest scores are selected. Scoring criteria may include word frequencies, location heuristics, sentence similarity, rhetorical relations, and semantic roles.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995, sec. 2\"></a></sup> </p>\n",
              " <p>Typically an intermediate representation is used to select relevant summary content. With <strong>topic representation</strong>, the intent is to identify the main topics in the text. Topic words, word frequencies (including <abbr data-title=\"» Term Frequency Inverse Document Frequency\">TF-IDF</abbr>), clustering, <abbr data-title=\"» Latent Semantic Analysis\">LSA</abbr> and <abbr data-title=\"» Latent Dirichlet Allocation\">LDA</abbr> have been applied to summarization. With <strong>indicator representation</strong>, a feature set is used to rank and select sentences. Examples of this approach are graph-based methods and machine learning.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>What are the challenges and requirements of multi-document summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-10\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/><div class=\"uk-thumbnail-caption\">Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The pipeline for multi-document summarization (<abbr data-title=\"» Multi Document Summarization\">MDS</abbr>) has the same basic steps as for single-document summarization (<abbr data-title=\"» Single Document Summarization\">SDS</abbr>): content selection, information ordering, and sentence realization. However, <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> has some unique challenges:<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 1\"></a></sup> <ul class=\"list-in-ans\"><li><strong>Redundancy</strong>: A single document has far less redundancy than a topically-related group of documents. Summary shouldn't repeat similar sentences. <em>Maximal Marginal Relevance (<abbr data-title=\"» Maximal Marginal Relevance\">MMR</abbr>)</em> is a scoring system to penalize similar sentences.</li><li><strong>Temporal Ordering</strong>: A stream of news articles might be reporting the unfolding of an event. Summary should order them correctly and be sensitive to later developments overriding earlier ones.</li><li><strong>Cohesion and Coreference</strong>: Both are important for information ordering. Sometimes cohesion might demand a certain ordering but cause coreference problems, such as a person's shortened name appearing before the full name.</li><li><strong>Compression Ratio</strong>: Summarization becomes more difficult when more compression is demanded.</li></ul>\n",
              " <p><abbr data-title=\"» Multi Document Summarization\">MDS</abbr> may cluster similar documents and passages. Summary should include sufficient context and right level of detail. Factual inconsistencies across documents can be reported. Finally, users must be allowed to filter out irrelevant content, dig deeper into the the sources via attribution, or compare related passages across documents.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 3\"></a></sup> </p></p></article-answer></li>\n",
              " <li><article-question>How does text summarization vary across domains or contexts?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-11\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/><div class=\"uk-thumbnail-caption\">IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Summarization must tune its output to each domain or context. For example, summarization of a news article would involve different considerations from that of a corporate sales report.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>General text summarization techniques might not do well for specific domains. Summarizers therefore might wish to use domain-specific knowledge. For legal document summarization, <em>CaseSummarizer</em> is a tool.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Polsley-et-al.-2016\" title=\"Polsley et al. 2016\"></a></sup> In biomedical domain, summaries are created of literature, treatments, drug information, clinical notes, health records, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Moradi-and-Ghadiri-2019\" title=\"Moradi and Ghadiri 2019\"></a></sup> </p>\n",
              " <p>Summarizing scientific literature is a challenge due to length, complexity, and structure (tables and figures). <em>IBM Science Summarizer</em> is a tool that IBM created to summarize computer science publications. It extracts domain-specific entities of types task, dataset and metric.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019\"></a></sup> </p>\n",
              " <p>Often there are extra clues about what might be important in a document. Summarization can use these for content selection. For example, comments and discussions on a blog post point to interesting content segments. Likewise, citations in scientific papers are useful pointers. For web summarization, it's possible to look at other pages linking to a particular page and determine the most suitable sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 5\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How has machine learning been applied to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-12\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/><div class=\"uk-thumbnail-caption\">Some features used by an <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The common <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> approach is to view text summarization as a classification problem. Algorithm is trained in a supervised manner on original text, an extractive summary and a set of features. Algorithm learns to classify sentences as either summary sentences or non-summary sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p>\n",
              " <p>Classifiers could be based on naive-Bayes, decision trees, <abbr data-title=\"» Support Vector Machines\">SVM</abbr>, <abbr data-title=\"» Hidden Markov Model\">HMM</abbr>, and <abbr data-title=\"» Conditional Random Field\">CRF</abbr>. Often each sentence is classified independently of others. However, since <abbr data-title=\"» Hidden Markov Model\">HMM</abbr> and <abbr data-title=\"» Conditional Random Field\">CRF</abbr> capture dependencies, they outperform other techniques.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 2.2\"></a></sup> </p>\n",
              " <p>The problem with supervised algorithms is in creating labelled data for training. This problem is worse for <abbr data-title=\"» Multi Document Summarization\">MDS</abbr>.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> In a semi-supervised approach, a small amount of labelled data is used along with much larger amount of unlabelled data. The algorithm learns iteratively by classifying some unlabelled data in each iteration.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Could you describe neural network architectures for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-13\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/><div class=\"uk-thumbnail-caption\">Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The typical approach is to do <strong>sequence-to-sequence modelling</strong> since input is a sequence of words and the summary is also a sequence of words. In an encoder-decoder architecture, the encoder uses <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> to give an input representation. The decoder is also an <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> that generates the output sequence. An attention layer between the encoder and the decoder helps in determining the most relevant words for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pawar-2018\" title=\"Pawar 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pai-2019\" title=\"Pai 2019\"></a></sup> </p>\n",
              " <p>Seq2seq models, <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr>s and attention layers have made abstractive summarization possible, even if they're not yet state-of-the-art compared to extractive summarization methods. These models are trained <strong>end-to-end</strong> without bothering to model each step of a traditional summarization pipeline. They also don't need access to specialized vocabulary or do pre-processing.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> This end-to-end approach has been applied successfully to short output sequences, such as news headlines or short email responses.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>In a <strong>pointer-generator</strong> network, a generator provides new words whereas a pointer copies words from source text. Seq2seq models often produce repetitive sentences. A <strong>coverage model</strong> avoids repetitions.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017\"></a></sup> </p>\n",
              " <p>Fernandes et al. showed that sequence encoders with a graph component does better at capturing long-distance relationships.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fernandes-et-al.-2019\" title=\"Fernandes et al. 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How do I evaluate text summarization algorithms?</article-question>\n",
              " <article-answer><p>Human evaluation is the simplest. In 2004, <strong>Recall-Oriented Understudy for Gisting Evaluation (ROUGE)</strong> was created to automate evaluation by comparing against hand-crafted summaries. ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S, and ROUGE-SU are some metrics in this family.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 5.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p>\n",
              " <p>Different people produce different summaries of the same text. Meaning shared across different human summaries is called Summary Content Unit (<abbr data-title=\"» Summary Content Unit\">SCU</abbr>). With a focus on meaning, <strong>Pyramid Method</strong> evaluates a summary using <abbr data-title=\"» Summary Content Unit\">SCU</abbr>s.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.6\"></a></sup> </p>\n",
              " <p>While there's no universal system of metrics, text summarizers are typically evaluated based on TREC, DUC and <abbr data-title=\"» Message Understanding Conference\">MUC</abbr> systems.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 1\"></a></sup> DUC (2001-2007) became a summarization track in TAC (2008-).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#DUC-2014\" title=\"DUC 2014\"></a></sup> </p>\n",
              " <p>Datasets for supervised training of <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> algorithms are not common. For summarizing a single or a few documents, commonly used datasets are Gigaword,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail, TAC (2008-2011) and DUC (2003-2004).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> ELI5 and WikiSum can be used for longform question answering and <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> respectively.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, sec. 5.1\"></a></sup> <a class=\"article-link\" href=\"http://kavita-ganesan.com/opinosis-opinion-dataset\" rel=\"nofollow\">Opinosis</a> is a dataset of 51 article-summary pairs.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Released in 2018, <a class=\"article-link\" href=\"https://summari.es/\" rel=\"nofollow\">Cornell Newsroom</a> is the largest dataset for training and evaluating summarization systems. Spanning 1998-2017 and containing 1.3 million articles, it's been collected from newsrooms of 38 major publications. Summaries are obtained from search and social metadata.</p></article-answer></li>\n",
              " <li><article-question>What are some useful resources for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-14\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/><div class=\"uk-thumbnail-caption\">MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Pengfei Liu has curated a <a class=\"article-link\" href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">useful list</a> of datasets, research papers, and groups researching on text summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2020\" title=\"Liu 2020\"></a></sup> </p>\n",
              " <p>In Python, Gensim has a module for text summarization, which implements <em>TextRank</em> algorithm. An original implementation of the same algorithm is available as PyTextRank package. PyTeaser is a Python implementation of Scala's TextTeaser.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Back in 2016, Google released a baseline TensorFlow implementation for summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p></article-answer></li></ul><h2>References<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-citations\"><li id=\"Allahyari-et-al.-2017\"><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Barzilay-and-Lee-2004\"><a href=\"https://www.aclweb.org/anthology/N04-1015/\" rel=\"nofollow\">Barzilay, Regina, and Lillian Lee. 2004. \"Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization.\" Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004, pp. 113-120, May. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Brownlee-2017\"><a href=\"https://machinelearningmastery.com/gentle-introduction-text-summarization/\" rel=\"nofollow\">Brownlee, Jason. 2017. \"A Gentle Introduction to Text Summarization.\" Machine Learning Mastery, August 7. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Chauhan-2018\"><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"DUC-2014\"><a href=\"https://duc.nist.gov/\" rel=\"nofollow\">DUC. 2014. \"Document Understanding Conferences: Homepage.\" NIST, September 9. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Das-and-Martins-2007\"><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Edmundson-1969\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/edmonson69.pdf\" rel=\"nofollow\">Edmundson, H. P. 1969. \"New Methods in Automatic Extracting.\" Journal of the ACM, vol. 16, no. 2, pp. 264-285, April. doi:10.1145/321510.321519. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Erera-et-al.-2019\"><a href=\"https://www.aclweb.org/anthology/D19-3036/\" rel=\"nofollow\">Erera, Shai, Michal Shmueli-Scheuer, Guy Feigenblat, Ora Peled Nakash, Odellia Boni, Haggai Roitman, Doron Cohen, Bar Weiner, Yosi Mass, Or Rivlin, Guy Lev, Achiya Jerbi, Jonathan Herzig, Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin, Francesca Bonin, and David Konopnicki. 2019. \"A Summarization System for Scientific Documents.\" Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 211-216, November. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fan-et-al.-2019\"><a href=\"https://arxiv.org/abs/1910.08435\" rel=\"nofollow\">Fan, Angela, Claire Gardent, Chloe Braud, and Antoine Bordes. 2019. \"Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs.\" arXiv, v1, October 18. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fernandes-et-al.-2019\"><a href=\"https://arxiv.org/abs/1811.01824\" rel=\"nofollow\">Fernandes, Patrick, Miltiadis Allamanis, and Marc Brockschmidt. 2019. \"Structured Neural Summarization.\" arXiv, v2, February 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Goldstein-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0405/\" rel=\"nofollow\">Goldstein, Jade, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. \"Multi-Document Summarization By Sentence Extraction.\" NAACL-ANLP 2000 Workshop: Automatic Summarization. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Jurafsky-and-Martin-2009\"><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel, and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kumar-et-al.-2016\"><a href=\"https://thescipub.com/PDF/jcssp.2016.178.190.pdf\" rel=\"nofollow\">Kumar, Yogan Jaya, Ong Sing Goh, Halizah Basiron, Ngo Hea Choon, and Puspalata C Suppiah. 2016. \"A Review on Automatic Text Summarization Approaches.\" J. of Comp. Sci., Science Publications, April 29. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kupiec-et-al.-1995\"><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.7100&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">Kupiec, Julian, Jan Pedersen, and Francine Chen. 1995. \"A trainable document summarizer.\" SIGIR '95: Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 68-73, July. doi:10.1145/215206.215333. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Lebanoff-et-al.-2018\"><a href=\"https://arxiv.org/abs/1808.06218\" rel=\"nofollow\">Lebanoff, Logan, Kaiqiang Song, and Fei Liu. 2018. \"Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization.\" arXiv, v2, August 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-2017\"><a href=\"https://medium.com/@wenchen.li/text-summarization-applications-ed319f0bb13c\" rel=\"nofollow\">Li, Wenchen. 2017. \"Text summarization: applications.\" Medium, May 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-et-al.-2006\"><a href=\"https://www.aclweb.org/anthology/P06-1047/\" rel=\"nofollow\">Li, Wenjie, Mingli Wu, Qin Lu, Wei Xu, and Chunfa Yuan. 2006. \"Extractive Summarization using Inter- and Intra- Event Relevance.\" Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pp. 369-376, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2019\"><a href=\"https://arxiv.org/abs/1903.10318\" rel=\"nofollow\">Liu, Yang. 2019. \"Fine-tune BERT for Extractive Summarization.\" arXiv, v2, September 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2020\"><a href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">Liu, Pengfei. 2020. \"Modern History for Text Summarization.\" NLP Historiograpy. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-and-Pan-2016\"><a href=\"https://ai.googleblog.com/2016/08/text-summarization-with-tensorflow.html\" rel=\"nofollow\">Liu, Peter, and Xin Pan. 2016. \"Text summarization with TensorFlow.\" Google AI Blog, August 24. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-et-al.-2018\"><a href=\"https://arxiv.org/abs/1801.10198\" rel=\"nofollow\">Liu, Peter J., Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. 2018. \"Generating Wikipedia by Summarizing Long Sequences.\" arXiv, v1, January 30. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Luhn-1958\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf\" rel=\"nofollow\">Luhn, H. P. 1958. \"The automatic creation of literature abstracts.\" IBM Journal of Research and Development, pp. 159-165, April. doi:10.1147/rd.22.0159. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Marcu-1997\"><a href=\"https://www.cs.toronto.edu/pub/gh/Marcu-PhDthesis.pdf\" rel=\"nofollow\">Marcu, Daniel. 1997. \"The Rhetorical Parsing, Summarization, and Generation of Natural Language Texts.\" PhD Thesis, University of Toronto, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mathur-et-al.-2017\"><a href=\"https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/\" rel=\"nofollow\">Mathur, Pranay, Aman Gill, and Aayush Yadav. 2017. \"Text Summarization in Python: Extractive vs. Abstractive techniques revisited.\" Rare Technologies, April 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Meyer-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/P16-4017/\" rel=\"nofollow\">Meyer, Christian M., Darina Benikova, Margot Mieskes, and Iryna Gurevych. 2016. \"MDSWriter: Annotation Tool for Creating High-Quality Multi-Document Summarization Corpora.\" Proceedings of ACL-2016 System Demonstrations, pp. 97-102, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mihalcea-2004\"><a href=\"https://www.aclweb.org/anthology/P04-3020/\" rel=\"nofollow\">Mihalcea, Rada. 2004. \"Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization.\" Proceedings of the ACL Interactive Poster and Demonstration Sessions, pp. 170-173, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Moradi-and-Ghadiri-2019\"><a href=\"https://arxiv.org/abs/1908.02285\" rel=\"nofollow\">Moradi, Milad, and Nasser Ghadiri. 2019. \"Text Summarization in the Biomedical Domain.\" arXiv, v1, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Nallapati-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/K16-1028/\" rel=\"nofollow\">Nallapati, Ramesh, Bowen Zhou, Cicero dos Santos, Çağlar Gu̇lçehre, and Bing Xiang. 2016. \"Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.\" Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, ACL, pp. 280-290, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Opidi-2019\"><a href=\"https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/\" rel=\"nofollow\">Opidi, Alfrick. 2019. \"A Gentle Introduction to Text Summarization in Machine Learning.\" Blog, FloydHub, April 15. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pai-2019\"><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pawar-2018\"><a href=\"https://medium.com/@i_am_manish/ai-text-summarizer-2de0b07bc27\" rel=\"nofollow\">Pawar, Manish. 2018. \"Ai Text Summarizer.\" Medium, November 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Polsley-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/C16-2054/\" rel=\"nofollow\">Polsley, Seth, Pooja Jhunjhunwala, and Ruihong Huang. 2016. \"CaseSummarizer: A System for Automated Summarization of Legal Texts.\" Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pp. 258-262, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-2000\"><a href=\"https://www.aclweb.org/anthology/W00-1009/\" rel=\"nofollow\">Radev, Dragomir. 2000. \"A Common Theory of Information Fusion from Multiple Text Sources Step One: Cross-Document Structure.\" 1st SIGdial Workshop on Discourse and Dialogue, ACL, pp. 74-83, October. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0403/\" rel=\"nofollow\">Radev, Dragomir R., Hongyan Jing, and Malgorzata Budzikowska. 2000. \"Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies.\" NAACL-ANLP 2000 Workshop: Automatic Summarization, v2, April. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Ratia-2018\"><a href=\"https://blog.frase.io/20-applications-of-automatic-summarization-in-the-enterprise/\" rel=\"nofollow\">Ratia, Tomas. 2018. \"20 Applications of Automatic Summarization in the Enterprise.\" Blog, Frase, July 17. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Rush-et-al.-2015\"><a href=\"https://www.aclweb.org/anthology/D15-1044/\" rel=\"nofollow\">Rush, Alexander M., Sumit Chopra, and Jason Weston. 2015. \"A Neural Attention Model for Abstractive Sentence Summarization.\" Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 379-389, September. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"See-et-al.-2017\"><a href=\"https://arxiv.org/abs/1704.04368\" rel=\"nofollow\">See, Abigail, Peter J. Liu, and Christopher D. Manning. 2017. \"Get To The Point: Summarization with Pointer-Generator Networks.\" arXiv, v2, April 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wong-et-al.-2008\"><a href=\"https://www.aclweb.org/anthology/C08-1124/\" rel=\"nofollow\">Wong, Kam-Fai, Mingli Wu, and Wenjie Li. 2008. \"Extractive Summarization Using Supervised and Semi-Supervised Learning.\" Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pp. 985-992, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wu-2006\"><a href=\"https://www.aclweb.org/anthology/P06-3007/\" rel=\"nofollow\">Wu, Mingli. 2006. \"Investigations on Event-Based Summarization.\" Proceedings of the COLING/ACL 2006 Student Research Workshop, pp. 37-42, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"i2-Decisions-2019\"><a href=\"https://www.i2decisions.com/case-studies/text-summarization\" rel=\"nofollow\">i2 Decisions. 2019. \"Text Summarization.\" Case Studies, i2 Decisions, April 5. Updated 2019-05-21. Accessed 2020-02-20.</a></li></ol></div><div class=\"article-right uk-width-medium-2-5\"><h2 class=\"sec-milestones\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones\" id=\"cd-timeline\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Tags</h2>\n",
              " <i class=\"uk-icon-tags uk-icon-large pull-left\"></i>\n",
              " <div class=\"article-tags\">\n",
              " <a href=\"/site-map/browse-articles/algorithms\" rel=\"nofollow\">algorithms</a>\n",
              " <a href=\"/site-map/browse-articles/natural+language+processing\" rel=\"nofollow\">natural language processing</a>\n",
              " <a href=\"/site-map/browse-articles/text+analytics\" rel=\"nofollow\">text analytics</a>\n",
              " </div><h2>See Also</h2>\n",
              " <ul><li><a href=\"/natural-language-generation\">Natural Language Generation</a></li>\n",
              " <li><a href=\"/natural-language-understanding\">Natural Language Understanding</a></li>\n",
              " <li>Computational Discourse <a href=\"/site-map/add-article?title=Computational+Discourse\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/question-answering\">Question Answering</a></li>\n",
              " <li>Chatbot <a href=\"/site-map/add-article?title=Chatbot\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/speech-recognition\">Speech Recognition</a></li></ul><h2>Further Reading<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-further-reading\"><li><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/\" rel=\"nofollow\">Paulus, Romain, Caiming Xiong, and Richard Socher. 2020. \"Your TL;DR by an AI: A Deep Reinforced Model for Abstractive Summarization.\" Salesforce Einstein, Salesforce. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li></ol><h2>Article Stats</h2>\n",
              " <div class=\"uk-modal\" id=\"author-stats-modal\">\n",
              " <div class=\"author-stats-modal uk-modal-dialog\">\n",
              " <a class=\"uk-modal-close uk-close\"></a>\n",
              " <h2>Author-wise Stats for Article Edits</h2><a href=\"\"></a>\n",
              " <div class=\"uk-grid table-head\">\n",
              " <div class=\"uk-width-medium-1-3\">Author</div>\n",
              " <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid dashboard-table\">\n",
              " <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>\n",
              " <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid author-stats-table-footer\"><div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div></div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>\n",
              " Words<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Chats<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>\n",
              " Authors<br/>\n",
              " </div>\n",
              " </a>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>\n",
              " Edits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Likes<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>\n",
              " Hits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div><h2>Cite As</h2>\n",
              " <div class=\"article-cite-as\">Devopedia. 2020. \"Text Summarization.\" Version 2, February 21. Accessed 2020-05-17. https://devopedia.org/text-summarization</div><button class=\"uk-button uk-button-mini\" type=\"button\">Copy citation</button></div></div>, <div class=\"article-left uk-width-medium-3-5\"><h2 class=\"topper\">Summary</h2>\n",
              " <div id=\"summary-text-wrapper\"><div id=\"summary-text\"><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-0\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/><div class=\"uk-thumbnail-caption\">Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>On the web, everyone can be a publisher. We're already seeing vast amounts of information being published daily in the form of restaurant/movie/book reviews, blogs, status updates, and more. In addition, traditional print publications (newspapers, magazines, technical journals, whitepapers) are also available online. It's impossible for anyone to keep track of recent publications even if limited to one domain. This is where text summarization can help.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup>\n",
              " </p>\n",
              " <p>A summary, created automatically by algorithms, typically contains the most important information. The summary should be mindful of the reader and the communication goals. It may also help the reader decide if the original text is worth reading in full. The summary can also help improve document indexing for information retrieval. An automated summary is often less biased than a human-written summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> </p></div></div><h2 class=\"sec-milestones-small\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones-small\" id=\"cd-timeline-small\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Discussion</h2>\n",
              " <ul class=\"uk-list uk-list-space article-discussion-list\"><li><article-question>What are some real-world applications of text summarization?</article-question>\n",
              " <article-answer><p>Here are some everyday examples of text summarization: news headlines, outlines for students, movie previews, meeting minutes, biographies for resumes or obituaries, abridged versions of books,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> newsletter production, financial research, patent research, legal contract analysis, tweeting about new content, chatbots that answer questions, email summaries, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>When Google Search presents search results, some entries are accompanied by auto-generated summaries. Google may be leveraging a knowledge graph for this purpose. Google's approach to summarization is mainly entity centric. Summarization extends to timelines and events about entities.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-2017\" title=\"Li 2017\"></a></sup> </p>\n",
              " <p>Doctors write long medical notes containing nutritional information for pregnant mothers. When these were reduced to short crisp summaries, pregnant mothers found them a lot easier to understand.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#i2-Decisions-2019\" title=\"i2 Decisions 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Which are the main approaches to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\" data-fullsrc=\"/images/article/261/2509.1582303438.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-9\" src=\"/images/article/261/2509.1582303438.s.png\" title=\"Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.\"/><div class=\"uk-thumbnail-caption\">Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>With <strong>extractive summarization</strong>, summary contains sentences picked and reproduced verbatim from the original text. With <strong>abstractive summarization</strong>, the algorithm interprets the text and generates a summary, possibly using new phrases and sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>Extractive summarization is data-driven, easier and often gives better results. Abstractive summarization is how humans tend to summarize text but it's hard for algorithms since it involves semantic representation, inference and natural language generation. Often abstractive summarization relies on text extracts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 1\"></a></sup> </p>\n",
              " <p>For extraction, sentences are scored and those with highest scores are selected. Scoring criteria may include word frequencies, location heuristics, sentence similarity, rhetorical relations, and semantic roles.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995, sec. 2\"></a></sup> </p>\n",
              " <p>Typically an intermediate representation is used to select relevant summary content. With <strong>topic representation</strong>, the intent is to identify the main topics in the text. Topic words, word frequencies (including <abbr data-title=\"» Term Frequency Inverse Document Frequency\">TF-IDF</abbr>), clustering, <abbr data-title=\"» Latent Semantic Analysis\">LSA</abbr> and <abbr data-title=\"» Latent Dirichlet Allocation\">LDA</abbr> have been applied to summarization. With <strong>indicator representation</strong>, a feature set is used to rank and select sentences. Examples of this approach are graph-based methods and machine learning.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>What are the challenges and requirements of multi-document summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\" data-fullsrc=\"/images/article/261/7144.1582303465.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-10\" src=\"/images/article/261/7144.1582303465.s.jpg\" title=\"Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.\"/><div class=\"uk-thumbnail-caption\">Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The pipeline for multi-document summarization (<abbr data-title=\"» Multi Document Summarization\">MDS</abbr>) has the same basic steps as for single-document summarization (<abbr data-title=\"» Single Document Summarization\">SDS</abbr>): content selection, information ordering, and sentence realization. However, <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> has some unique challenges:<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 1\"></a></sup> <ul class=\"list-in-ans\"><li><strong>Redundancy</strong>: A single document has far less redundancy than a topically-related group of documents. Summary shouldn't repeat similar sentences. <em>Maximal Marginal Relevance (<abbr data-title=\"» Maximal Marginal Relevance\">MMR</abbr>)</em> is a scoring system to penalize similar sentences.</li><li><strong>Temporal Ordering</strong>: A stream of news articles might be reporting the unfolding of an event. Summary should order them correctly and be sensitive to later developments overriding earlier ones.</li><li><strong>Cohesion and Coreference</strong>: Both are important for information ordering. Sometimes cohesion might demand a certain ordering but cause coreference problems, such as a person's shortened name appearing before the full name.</li><li><strong>Compression Ratio</strong>: Summarization becomes more difficult when more compression is demanded.</li></ul>\n",
              " <p><abbr data-title=\"» Multi Document Summarization\">MDS</abbr> may cluster similar documents and passages. Summary should include sufficient context and right level of detail. Factual inconsistencies across documents can be reported. Finally, users must be allowed to filter out irrelevant content, dig deeper into the the sources via attribution, or compare related passages across documents.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Goldstein-et-al.-2000\" title=\"Goldstein et al. 2000, sec. 3\"></a></sup> </p></p></article-answer></li>\n",
              " <li><article-question>How does text summarization vary across domains or contexts?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\" data-fullsrc=\"/images/article/261/4271.1582303483.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-11\" src=\"/images/article/261/4271.1582303483.s.png\" title=\"IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.\"/><div class=\"uk-thumbnail-caption\">IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Summarization must tune its output to each domain or context. For example, summarization of a news article would involve different considerations from that of a corporate sales report.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Ratia-2018\" title=\"Ratia 2018\"></a></sup> </p>\n",
              " <p>General text summarization techniques might not do well for specific domains. Summarizers therefore might wish to use domain-specific knowledge. For legal document summarization, <em>CaseSummarizer</em> is a tool.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Polsley-et-al.-2016\" title=\"Polsley et al. 2016\"></a></sup> In biomedical domain, summaries are created of literature, treatments, drug information, clinical notes, health records, and more.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Moradi-and-Ghadiri-2019\" title=\"Moradi and Ghadiri 2019\"></a></sup> </p>\n",
              " <p>Summarizing scientific literature is a challenge due to length, complexity, and structure (tables and figures). <em>IBM Science Summarizer</em> is a tool that IBM created to summarize computer science publications. It extracts domain-specific entities of types task, dataset and metric.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019\"></a></sup> </p>\n",
              " <p>Often there are extra clues about what might be important in a document. Summarization can use these for content selection. For example, comments and discussions on a blog post point to interesting content segments. Likewise, citations in scientific papers are useful pointers. For web summarization, it's possible to look at other pages linking to a particular page and determine the most suitable sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 5\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How has machine learning been applied to text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\" data-fullsrc=\"/images/article/261/5912.1582303500.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-12\" src=\"/images/article/261/5912.1582303500.s.png\" title=\"Some features used by an ML classifier for text summarization. Source: Wong et al. 2008, tables 1-3.\"/><div class=\"uk-thumbnail-caption\">Some features used by an <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The common <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> approach is to view text summarization as a classification problem. Algorithm is trained in a supervised manner on original text, an extractive summary and a set of features. Algorithm learns to classify sentences as either summary sentences or non-summary sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p>\n",
              " <p>Classifiers could be based on naive-Bayes, decision trees, <abbr data-title=\"» Support Vector Machines\">SVM</abbr>, <abbr data-title=\"» Hidden Markov Model\">HMM</abbr>, and <abbr data-title=\"» Conditional Random Field\">CRF</abbr>. Often each sentence is classified independently of others. However, since <abbr data-title=\"» Hidden Markov Model\">HMM</abbr> and <abbr data-title=\"» Conditional Random Field\">CRF</abbr> capture dependencies, they outperform other techniques.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 2.2\"></a></sup> </p>\n",
              " <p>The problem with supervised algorithms is in creating labelled data for training. This problem is worse for <abbr data-title=\"» Multi Document Summarization\">MDS</abbr>.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> In a semi-supervised approach, a small amount of labelled data is used along with much larger amount of unlabelled data. The algorithm learns iteratively by classifying some unlabelled data in each iteration.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 6.2\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>Could you describe neural network architectures for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\" data-fullsrc=\"/images/article/261/4518.1582304150.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-13\" src=\"/images/article/261/4518.1582304150.s.png\" title=\"Pointer-generator network. Source: See et al. 2017, fig. 3.\"/><div class=\"uk-thumbnail-caption\">Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>The typical approach is to do <strong>sequence-to-sequence modelling</strong> since input is a sequence of words and the summary is also a sequence of words. In an encoder-decoder architecture, the encoder uses <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> to give an input representation. The decoder is also an <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr> that generates the output sequence. An attention layer between the encoder and the decoder helps in determining the most relevant words for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pawar-2018\" title=\"Pawar 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Pai-2019\" title=\"Pai 2019\"></a></sup> </p>\n",
              " <p>Seq2seq models, <abbr data-title=\"» Long Short Term Memory\">LSTM</abbr>s and attention layers have made abstractive summarization possible, even if they're not yet state-of-the-art compared to extractive summarization methods. These models are trained <strong>end-to-end</strong> without bothering to model each step of a traditional summarization pipeline. They also don't need access to specialized vocabulary or do pre-processing.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> This end-to-end approach has been applied successfully to short output sequences, such as news headlines or short email responses.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p>\n",
              " <p>In a <strong>pointer-generator</strong> network, a generator provides new words whereas a pointer copies words from source text. Seq2seq models often produce repetitive sentences. A <strong>coverage model</strong> avoids repetitions.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017\"></a></sup> </p>\n",
              " <p>Fernandes et al. showed that sequence encoders with a graph component does better at capturing long-distance relationships.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fernandes-et-al.-2019\" title=\"Fernandes et al. 2019\"></a></sup> </p></article-answer></li>\n",
              " <li><article-question>How do I evaluate text summarization algorithms?</article-question>\n",
              " <article-answer><p>Human evaluation is the simplest. In 2004, <strong>Recall-Oriented Understudy for Gisting Evaluation (ROUGE)</strong> was created to automate evaluation by comparing against hand-crafted summaries. ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S, and ROUGE-SU are some metrics in this family.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 5.2\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p>\n",
              " <p>Different people produce different summaries of the same text. Meaning shared across different human summaries is called Summary Content Unit (<abbr data-title=\"» Summary Content Unit\">SCU</abbr>). With a focus on meaning, <strong>Pyramid Method</strong> evaluates a summary using <abbr data-title=\"» Summary Content Unit\">SCU</abbr>s.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.6\"></a></sup> </p>\n",
              " <p>While there's no universal system of metrics, text summarizers are typically evaluated based on TREC, DUC and <abbr data-title=\"» Message Understanding Conference\">MUC</abbr> systems.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Das-and-Martins-2007\" title=\"Das and Martins 2007, sec. 1\"></a></sup> DUC (2001-2007) became a summarization track in TAC (2008-).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#DUC-2014\" title=\"DUC 2014\"></a></sup> </p>\n",
              " <p>Datasets for supervised training of <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> algorithms are not common. For summarizing a single or a few documents, commonly used datasets are Gigaword,<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail, TAC (2008-2011) and DUC (2003-2004).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Lebanoff-et-al.-2018\" title=\"Lebanoff et al. 2018\"></a></sup> ELI5 and WikiSum can be used for longform question answering and <abbr data-title=\"» Multi Document Summarization\">MDS</abbr> respectively.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, sec. 5.1\"></a></sup> <a class=\"article-link\" href=\"http://kavita-ganesan.com/opinosis-opinion-dataset\" rel=\"nofollow\">Opinosis</a> is a dataset of 51 article-summary pairs.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Released in 2018, <a class=\"article-link\" href=\"https://summari.es/\" rel=\"nofollow\">Cornell Newsroom</a> is the largest dataset for training and evaluating summarization systems. Spanning 1998-2017 and containing 1.3 million articles, it's been collected from newsrooms of 38 major publications. Summaries are obtained from search and social metadata.</p></article-answer></li>\n",
              " <li><article-question>What are some useful resources for text summarization?</article-question>\n",
              " <article-answer><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\" data-fullsrc=\"/images/article/261/2265.1582303704.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-14\" src=\"/images/article/261/2265.1582303704.s.jpg\" title=\"MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.\"/><div class=\"uk-thumbnail-caption\">MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>Pengfei Liu has curated a <a class=\"article-link\" href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">useful list</a> of datasets, research papers, and groups researching on text summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2020\" title=\"Liu 2020\"></a></sup> </p>\n",
              " <p>In Python, Gensim has a module for text summarization, which implements <em>TextRank</em> algorithm. An original implementation of the same algorithm is available as PyTextRank package. PyTeaser is a Python implementation of Scala's TextTeaser.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mathur-et-al.-2017\" title=\"Mathur et al. 2017\"></a></sup> </p>\n",
              " <p>Back in 2016, Google released a baseline TensorFlow implementation for summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-and-Pan-2016\" title=\"Liu and Pan 2016\"></a></sup> </p></article-answer></li></ul><h2>References<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-citations\"><li id=\"Allahyari-et-al.-2017\"><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Barzilay-and-Lee-2004\"><a href=\"https://www.aclweb.org/anthology/N04-1015/\" rel=\"nofollow\">Barzilay, Regina, and Lillian Lee. 2004. \"Catching the Drift: Probabilistic Content Models, with Applications to Generation and Summarization.\" Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL 2004, pp. 113-120, May. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Brownlee-2017\"><a href=\"https://machinelearningmastery.com/gentle-introduction-text-summarization/\" rel=\"nofollow\">Brownlee, Jason. 2017. \"A Gentle Introduction to Text Summarization.\" Machine Learning Mastery, August 7. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Chauhan-2018\"><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"DUC-2014\"><a href=\"https://duc.nist.gov/\" rel=\"nofollow\">DUC. 2014. \"Document Understanding Conferences: Homepage.\" NIST, September 9. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Das-and-Martins-2007\"><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Edmundson-1969\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/edmonson69.pdf\" rel=\"nofollow\">Edmundson, H. P. 1969. \"New Methods in Automatic Extracting.\" Journal of the ACM, vol. 16, no. 2, pp. 264-285, April. doi:10.1145/321510.321519. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Erera-et-al.-2019\"><a href=\"https://www.aclweb.org/anthology/D19-3036/\" rel=\"nofollow\">Erera, Shai, Michal Shmueli-Scheuer, Guy Feigenblat, Ora Peled Nakash, Odellia Boni, Haggai Roitman, Doron Cohen, Bar Weiner, Yosi Mass, Or Rivlin, Guy Lev, Achiya Jerbi, Jonathan Herzig, Yufang Hou, Charles Jochim, Martin Gleize, Francesca Bonin, Francesca Bonin, and David Konopnicki. 2019. \"A Summarization System for Scientific Documents.\" Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp. 211-216, November. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fan-et-al.-2019\"><a href=\"https://arxiv.org/abs/1910.08435\" rel=\"nofollow\">Fan, Angela, Claire Gardent, Chloe Braud, and Antoine Bordes. 2019. \"Using Local Knowledge Graph Construction to Scale Seq2Seq Models to Multi-Document Inputs.\" arXiv, v1, October 18. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Fernandes-et-al.-2019\"><a href=\"https://arxiv.org/abs/1811.01824\" rel=\"nofollow\">Fernandes, Patrick, Miltiadis Allamanis, and Marc Brockschmidt. 2019. \"Structured Neural Summarization.\" arXiv, v2, February 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Goldstein-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0405/\" rel=\"nofollow\">Goldstein, Jade, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. \"Multi-Document Summarization By Sentence Extraction.\" NAACL-ANLP 2000 Workshop: Automatic Summarization. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Jurafsky-and-Martin-2009\"><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel, and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kumar-et-al.-2016\"><a href=\"https://thescipub.com/PDF/jcssp.2016.178.190.pdf\" rel=\"nofollow\">Kumar, Yogan Jaya, Ong Sing Goh, Halizah Basiron, Ngo Hea Choon, and Puspalata C Suppiah. 2016. \"A Review on Automatic Text Summarization Approaches.\" J. of Comp. Sci., Science Publications, April 29. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Kupiec-et-al.-1995\"><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.452.7100&amp;rep=rep1&amp;type=pdf\" rel=\"nofollow\">Kupiec, Julian, Jan Pedersen, and Francine Chen. 1995. \"A trainable document summarizer.\" SIGIR '95: Proceedings of the 18th annual international ACM SIGIR conference on Research and development in information retrieval, pp. 68-73, July. doi:10.1145/215206.215333. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Lebanoff-et-al.-2018\"><a href=\"https://arxiv.org/abs/1808.06218\" rel=\"nofollow\">Lebanoff, Logan, Kaiqiang Song, and Fei Liu. 2018. \"Adapting the Neural Encoder-Decoder Framework from Single to Multi-Document Summarization.\" arXiv, v2, August 28. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-2017\"><a href=\"https://medium.com/@wenchen.li/text-summarization-applications-ed319f0bb13c\" rel=\"nofollow\">Li, Wenchen. 2017. \"Text summarization: applications.\" Medium, May 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Li-et-al.-2006\"><a href=\"https://www.aclweb.org/anthology/P06-1047/\" rel=\"nofollow\">Li, Wenjie, Mingli Wu, Qin Lu, Wei Xu, and Chunfa Yuan. 2006. \"Extractive Summarization using Inter- and Intra- Event Relevance.\" Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pp. 369-376, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2019\"><a href=\"https://arxiv.org/abs/1903.10318\" rel=\"nofollow\">Liu, Yang. 2019. \"Fine-tune BERT for Extractive Summarization.\" arXiv, v2, September 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-2020\"><a href=\"http://pfliu.com/Historiography/summarization/summ-eng.html\" rel=\"nofollow\">Liu, Pengfei. 2020. \"Modern History for Text Summarization.\" NLP Historiograpy. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-and-Pan-2016\"><a href=\"https://ai.googleblog.com/2016/08/text-summarization-with-tensorflow.html\" rel=\"nofollow\">Liu, Peter, and Xin Pan. 2016. \"Text summarization with TensorFlow.\" Google AI Blog, August 24. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Liu-et-al.-2018\"><a href=\"https://arxiv.org/abs/1801.10198\" rel=\"nofollow\">Liu, Peter J., Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi, Lukasz Kaiser, and Noam Shazeer. 2018. \"Generating Wikipedia by Summarizing Long Sequences.\" arXiv, v1, January 30. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Luhn-1958\"><a href=\"http://courses.ischool.berkeley.edu/i256/f06/papers/luhn58.pdf\" rel=\"nofollow\">Luhn, H. P. 1958. \"The automatic creation of literature abstracts.\" IBM Journal of Research and Development, pp. 159-165, April. doi:10.1147/rd.22.0159. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Marcu-1997\"><a href=\"https://www.cs.toronto.edu/pub/gh/Marcu-PhDthesis.pdf\" rel=\"nofollow\">Marcu, Daniel. 1997. \"The Rhetorical Parsing, Summarization, and Generation of Natural Language Texts.\" PhD Thesis, University of Toronto, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mathur-et-al.-2017\"><a href=\"https://rare-technologies.com/text-summarization-in-python-extractive-vs-abstractive-techniques-revisited/\" rel=\"nofollow\">Mathur, Pranay, Aman Gill, and Aayush Yadav. 2017. \"Text Summarization in Python: Extractive vs. Abstractive techniques revisited.\" Rare Technologies, April 5. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Meyer-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/P16-4017/\" rel=\"nofollow\">Meyer, Christian M., Darina Benikova, Margot Mieskes, and Iryna Gurevych. 2016. \"MDSWriter: Annotation Tool for Creating High-Quality Multi-Document Summarization Corpora.\" Proceedings of ACL-2016 System Demonstrations, pp. 97-102, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Mihalcea-2004\"><a href=\"https://www.aclweb.org/anthology/P04-3020/\" rel=\"nofollow\">Mihalcea, Rada. 2004. \"Graph-based Ranking Algorithms for Sentence Extraction, Applied to Text Summarization.\" Proceedings of the ACL Interactive Poster and Demonstration Sessions, pp. 170-173, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Moradi-and-Ghadiri-2019\"><a href=\"https://arxiv.org/abs/1908.02285\" rel=\"nofollow\">Moradi, Milad, and Nasser Ghadiri. 2019. \"Text Summarization in the Biomedical Domain.\" arXiv, v1, August 6. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Nallapati-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/K16-1028/\" rel=\"nofollow\">Nallapati, Ramesh, Bowen Zhou, Cicero dos Santos, Çağlar Gu̇lçehre, and Bing Xiang. 2016. \"Abstractive Text Summarization using Sequence-to-sequence RNNs and Beyond.\" Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, ACL, pp. 280-290, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Opidi-2019\"><a href=\"https://blog.floydhub.com/gentle-introduction-to-text-summarization-in-machine-learning/\" rel=\"nofollow\">Opidi, Alfrick. 2019. \"A Gentle Introduction to Text Summarization in Machine Learning.\" Blog, FloydHub, April 15. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pai-2019\"><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Pawar-2018\"><a href=\"https://medium.com/@i_am_manish/ai-text-summarizer-2de0b07bc27\" rel=\"nofollow\">Pawar, Manish. 2018. \"Ai Text Summarizer.\" Medium, November 20. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Polsley-et-al.-2016\"><a href=\"https://www.aclweb.org/anthology/C16-2054/\" rel=\"nofollow\">Polsley, Seth, Pooja Jhunjhunwala, and Ruihong Huang. 2016. \"CaseSummarizer: A System for Automated Summarization of Legal Texts.\" Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, pp. 258-262, December. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-2000\"><a href=\"https://www.aclweb.org/anthology/W00-1009/\" rel=\"nofollow\">Radev, Dragomir. 2000. \"A Common Theory of Information Fusion from Multiple Text Sources Step One: Cross-Document Structure.\" 1st SIGdial Workshop on Discourse and Dialogue, ACL, pp. 74-83, October. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Radev-et-al.-2000\"><a href=\"https://www.aclweb.org/anthology/W00-0403/\" rel=\"nofollow\">Radev, Dragomir R., Hongyan Jing, and Malgorzata Budzikowska. 2000. \"Centroid-based summarization of multiple documents: sentence extraction, utility-based evaluation, and user studies.\" NAACL-ANLP 2000 Workshop: Automatic Summarization, v2, April. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Ratia-2018\"><a href=\"https://blog.frase.io/20-applications-of-automatic-summarization-in-the-enterprise/\" rel=\"nofollow\">Ratia, Tomas. 2018. \"20 Applications of Automatic Summarization in the Enterprise.\" Blog, Frase, July 17. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Rush-et-al.-2015\"><a href=\"https://www.aclweb.org/anthology/D15-1044/\" rel=\"nofollow\">Rush, Alexander M., Sumit Chopra, and Jason Weston. 2015. \"A Neural Attention Model for Abstractive Sentence Summarization.\" Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pp. 379-389, September. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"See-et-al.-2017\"><a href=\"https://arxiv.org/abs/1704.04368\" rel=\"nofollow\">See, Abigail, Peter J. Liu, and Christopher D. Manning. 2017. \"Get To The Point: Summarization with Pointer-Generator Networks.\" arXiv, v2, April 25. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wong-et-al.-2008\"><a href=\"https://www.aclweb.org/anthology/C08-1124/\" rel=\"nofollow\">Wong, Kam-Fai, Mingli Wu, and Wenjie Li. 2008. \"Extractive Summarization Using Supervised and Semi-Supervised Learning.\" Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pp. 985-992, August. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"Wu-2006\"><a href=\"https://www.aclweb.org/anthology/P06-3007/\" rel=\"nofollow\">Wu, Mingli. 2006. \"Investigations on Event-Based Summarization.\" Proceedings of the COLING/ACL 2006 Student Research Workshop, pp. 37-42, July. Accessed 2020-02-20.</a></li>\n",
              " <li id=\"i2-Decisions-2019\"><a href=\"https://www.i2decisions.com/case-studies/text-summarization\" rel=\"nofollow\">i2 Decisions. 2019. \"Text Summarization.\" Case Studies, i2 Decisions, April 5. Updated 2019-05-21. Accessed 2020-02-20.</a></li></ol></div>, <div id=\"summary-text-wrapper\"><div id=\"summary-text\"><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-0\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/><div class=\"uk-thumbnail-caption\">Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>On the web, everyone can be a publisher. We're already seeing vast amounts of information being published daily in the form of restaurant/movie/book reviews, blogs, status updates, and more. In addition, traditional print publications (newspapers, magazines, technical journals, whitepapers) are also available online. It's impossible for anyone to keep track of recent publications even if limited to one domain. This is where text summarization can help.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup>\n",
              " </p>\n",
              " <p>A summary, created automatically by algorithms, typically contains the most important information. The summary should be mindful of the reader and the communication goals. It may also help the reader decide if the original text is worth reading in full. The summary can also help improve document indexing for information retrieval. An automated summary is often less biased than a human-written summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> </p></div></div>, <div id=\"summary-text\"><figure class=\"article-discussion uk-align-left uk-thumbnail\"><img alt=\"Types of text summarization. Source: Chauhan 2018.\" data-fullsrc=\"/images/article/261/5116.1582303416.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-0\" src=\"/images/article/261/5116.1582303416.s.png\" title=\"Types of text summarization. Source: Chauhan 2018.\"/><div class=\"uk-thumbnail-caption\">Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure>\n",
              " <p>On the web, everyone can be a publisher. We're already seeing vast amounts of information being published daily in the form of restaurant/movie/book reviews, blogs, status updates, and more. In addition, traditional print publications (newspapers, magazines, technical journals, whitepapers) are also available online. It's impossible for anyone to keep track of recent publications even if limited to one domain. This is where text summarization can help.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup>\n",
              " </p>\n",
              " <p>A summary, created automatically by algorithms, typically contains the most important information. The summary should be mindful of the reader and the communication goals. It may also help the reader decide if the original text is worth reading in full. The summary can also help improve document indexing for information retrieval. An automated summary is often less biased than a human-written summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Brownlee-2017\" title=\"Brownlee 2017\"></a></sup> </p></div>, <div class=\"uk-thumbnail-caption\">Types of text summarization. Source: Chauhan 2018.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Chauhan-2018\" title=\"Chauhan 2018\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>, <div class=\"\">Apr<br/>1958</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>, <div class=\"\">Apr<br/>1969</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>, <div class=\"year-only\">1995</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>, <div class=\"\">Dec<br/>1997</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>, <div class=\"\">Apr<br/>2000</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>, <div class=\"\">Oct<br/>2000</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>, <div class=\"\">May<br/>2004</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>, <div class=\"\">Jul<br/>2004</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>, <div class=\"year-only\">2006</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>, <div class=\"\">Sep<br/>2015</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>, <div class=\"\">Aug<br/>2016</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>, <div class=\"\">Jan<br/>2018</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>, <div class=\"\">Oct<br/>2019</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>, <div class=\"\">Sep<br/>2019</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"small-img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"uk-thumbnail-caption\">Illustrating extractive vs abstractive summarization. Source: Adapted from Opidi 2019.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Opidi-2019\" title=\"Opidi 2019\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"uk-thumbnail-caption\">Pipeline of multi-document summarization. Source: Jurafsky and Martin 2009, fig. 23.18.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.18\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"uk-thumbnail-caption\">IBM Science Summarizer for computer science domain. Source: Erera et al. 2019, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Erera-et-al.-2019\" title=\"Erera et al. 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"uk-thumbnail-caption\">Some features used by an <abbr data-title=\"» Machine Learning\n",
              " » Meta Language\">ML</abbr> classifier for text summarization. Source: Wong et al. 2008, tables 1-3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wong-et-al.-2008\" title=\"Wong et al. 2008, tables 1-3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"uk-thumbnail-caption\">Pointer-generator network. Source: See et al. 2017, fig. 3.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"uk-thumbnail-caption\">MDSWriter is a useful annotation tool for multi-document summarization. Source: Meyer et al. 2016, fig. 1.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Meyer-et-al.-2016\" title=\"Meyer et al. 2016, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"article-right uk-width-medium-2-5\"><h2 class=\"sec-milestones\">Milestones</h2>\n",
              " <section class=\"cd-container sec-milestones\" id=\"cd-timeline\"><div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>\n",
              " <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div></section><h2>Tags</h2>\n",
              " <i class=\"uk-icon-tags uk-icon-large pull-left\"></i>\n",
              " <div class=\"article-tags\">\n",
              " <a href=\"/site-map/browse-articles/algorithms\" rel=\"nofollow\">algorithms</a>\n",
              " <a href=\"/site-map/browse-articles/natural+language+processing\" rel=\"nofollow\">natural language processing</a>\n",
              " <a href=\"/site-map/browse-articles/text+analytics\" rel=\"nofollow\">text analytics</a>\n",
              " </div><h2>See Also</h2>\n",
              " <ul><li><a href=\"/natural-language-generation\">Natural Language Generation</a></li>\n",
              " <li><a href=\"/natural-language-understanding\">Natural Language Understanding</a></li>\n",
              " <li>Computational Discourse <a href=\"/site-map/add-article?title=Computational+Discourse\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/question-answering\">Question Answering</a></li>\n",
              " <li>Chatbot <a href=\"/site-map/add-article?title=Chatbot\" rel=\"nofollow\"><i class=\"uk-icon uk-icon-plus add-article-link\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Add new article\"></i></a></li>\n",
              " <li><a href=\"/speech-recognition\">Speech Recognition</a></li></ul><h2>Further Reading<i class=\"uk-icon-external-link external-link-icon pull-right\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"External links\"></i></h2>\n",
              " <ol class=\"article-further-reading\"><li><a href=\"https://github.com/rain1024/slp2-pdf/blob/master/chapter-wise-pdf/[23]%20Question%20Answering%20and%20Summarization.pdf\" rel=\"nofollow\">Jurafsky, Daniel and James H. Martin. 2009. \"Question Answering and Summarization.\" Chapter 23 in: Speech and Language Processing, Second Edition, Prentice-Hall, Inc. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://arxiv.org/pdf/1707.02268.pdf\" rel=\"nofollow\">Allahyari, Mehdi, Seyedamin Pouriyeh, Mehdi Assefi, Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutierrez, and Krys Kochut. 2017. \"Text Summarization Techniques: A Brief Survey.\" arXiv, v3, July 28. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.cs.cmu.edu/~nasmith/LS2/das-martins.07.pdf\" rel=\"nofollow\">Das, Dipanjan, and André F. T. Martins. 2007. \"A Survey on Automatic Text Summarization.\" Carnegie Mellon University, November 21. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\" rel=\"nofollow\">Pai, Aravind. 2019. \"Comprehensive Guide to Text Summarization using Deep Learning in Python.\" Blog, Analytics Vidhya, June 10. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://www.salesforce.com/products/einstein/ai-research/tl-dr-reinforced-model-abstractive-summarization/\" rel=\"nofollow\">Paulus, Romain, Caiming Xiong, and Richard Socher. 2020. \"Your TL;DR by an AI: A Deep Reinforced Model for Abstractive Summarization.\" Salesforce Einstein, Salesforce. Accessed 2020-02-20.</a></li>\n",
              " <li><a href=\"https://medium.com/jatana/unsupervised-text-summarization-using-sentence-embeddings-adb15ce83db1\" rel=\"nofollow\">Chauhan, Kushal. 2018. \"Unsupervised Text Summarization using Sentence Embeddings.\" Jatana, on Medium, August 6. Accessed 2020-02-20.</a></li></ol><h2>Article Stats</h2>\n",
              " <div class=\"uk-modal\" id=\"author-stats-modal\">\n",
              " <div class=\"author-stats-modal uk-modal-dialog\">\n",
              " <a class=\"uk-modal-close uk-close\"></a>\n",
              " <h2>Author-wise Stats for Article Edits</h2><a href=\"\"></a>\n",
              " <div class=\"uk-grid table-head\">\n",
              " <div class=\"uk-width-medium-1-3\">Author</div>\n",
              " <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid dashboard-table\">\n",
              " <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>\n",
              " <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid author-stats-table-footer\"><div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div></div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>\n",
              " Words<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Chats<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>\n",
              " Authors<br/>\n",
              " </div>\n",
              " </a>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>\n",
              " Edits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Likes<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>\n",
              " Hits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div><h2>Cite As</h2>\n",
              " <div class=\"article-cite-as\">Devopedia. 2020. \"Text Summarization.\" Version 2, February 21. Accessed 2020-05-17. https://devopedia.org/text-summarization</div><button class=\"uk-button uk-button-mini\" type=\"button\">Copy citation</button></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1958</div></div>, <div class=\"\">Apr<br/>1958</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\" data-fullsrc=\"/images/article/261/6980.1582303734.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-1\" src=\"/images/article/261/6980.1582303734.s.png\" title=\"Ignore too common words and least frequent words. Source: Luhn 1958, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Luhn makes use of <strong>word frequencies</strong> to determine sentences most significant for summarization. Frequently occurring words close to one another suggest significant sentences. Thresholds are set to ignore most frequent and least frequent words. For example, in biology, the word 'cell' is too common and can be ignored. Luhn's algorithm, extractive in nature, is simple in that it doesn't merge word variations (differ, different, differently).<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Luhn-1958\" title=\"Luhn 1958, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>1969</div></div>, <div class=\"\">Apr<br/>1969</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>In addition to word frequencies, Edmundson makes use of pragmatic or cue words, title and heading words, and structural indicators such as sentence location. He notes that these improve text extraction. Example cue words are 'significant', 'impossible' and 'hardly'. They're classified are positively relevant, negatively relevant and irrelevant. He hypothesizes that significant sentences or paragraphs occur very early and very late in the section or document. He also observes that future algorithms must consider language syntax and semantics. Statistical evidence alone is inadequate.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Edmundson-1969\" title=\"Edmundson 1969\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">1995</div></div>, <div class=\"year-only\">1995</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Kupiec et al. implements a <strong>supervised machine learning</strong> algorithm based on the <strong>naive-Bayes classifier</strong>. Algorithm is trained on hand-selected extracts. The features considered include sentence length cut-off, fixed-phrase, paragraph, thematic word, and uppercase word. For example, the model ignores short sentences. It picks out thematic words, proper names and acronyms. Words such as 'conclusions', 'summary' or 'discussion' are more likely to be in the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kupiec-et-al.-1995\" title=\"Kupiec et al. 1995\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Dec<br/>1997</div></div>, <div class=\"\">Dec<br/>1997</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\" data-fullsrc=\"/images/article/261/2554.1582303754.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-2\" src=\"/images/article/261/2554.1582303754.s.png\" title=\"Tree as an abstraction of discourse structure. Source: Marcu 1997, fig. 2.1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>For his PhD thesis on text summarization, Marcu takes inspiration from Rhetorical Structure Theory (<abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr>). He looks at the <strong>rhetorical relation</strong> between two non-overlapping text spans called nucleus and satellite. Examples of such relations are justification, evidence, restatement, and concession. Text is decomposed into smaller units connected by rhetorical relations.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997\"></a></sup> In the example, <em>Justification</em> is the relation between Mars weather and its distant orbit.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, fig. 23.15\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Marcu-1997\" title=\"Marcu 1997, fig. 2.1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Apr<br/>2000</div></div>, <div class=\"\">Apr<br/>2000</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\" data-fullsrc=\"/images/article/261/8806.1582303771.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-3\" src=\"/images/article/261/8806.1582303771.s.png\" title=\"An overview of clustering for text summarization. Source: Kumar et al. 2016, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Radev et al. propose <strong>centroid-based summarization</strong> for multi-document summarization. Similar documents and sentences are grouped into clusters. Each cluster may represent a different sub-topic. Cluster centroid is a pseudo document representative of the cluster. Summary would include sentences similar to the centroids.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-et-al.-2000\" title=\"Radev et al. 2000\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2000</div></div>, <div class=\"\">Oct<br/>2000</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Multi-document graph. Source: Radev 2000, fig. 4.\" data-fullsrc=\"/images/article/261/5755.1582303792.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-4\" src=\"/images/article/261/5755.1582303792.s.png\" title=\"Multi-document graph. Source: Radev 2000, fig. 4.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Since <abbr data-title=\"» Rhetorical Structure Theory\">RST</abbr> is limited to single documents, Radev introduces <strong>Cross-document Structure Theory (<abbr data-title=\"» Cross-document Structure Theory\">CST</abbr>)</strong> for multi-document summarization. He proposes multi-document graphs as a useful abstraction to represent relations at word, phrase, paragraph and document levels. He identifies 24 cross-document relations, such as Identity (same text), Subsumption (one sentence is contained in another), and Follow-up (additional information reflecting new developments). Summarization is done in four steps: clustering, document structure analysis, link analysis, and personalized graph-based summarization.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Radev-2000\" title=\"Radev 2000, fig. 4\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">May<br/>2004</div></div>, <div class=\"\">May<br/>2004</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Barzilay and Lee propose a domain-sensitive <strong>content model</strong>. They use <strong>Hidden Markov Model (<abbr data-title=\"» Hidden Markov Model\">HMM</abbr>)</strong> in which domain topics are the states and generates sentences relevant to that topic. State transitions model topic change. An n-gram model is used to generate sentences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Barzilay-and-Lee-2004\" title=\"Barzilay and Lee 2004\"></a></sup> This model jointly learns both content selection and information ordering.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Jurafsky-and-Martin-2009\" title=\"Jurafsky and Martin 2009, sec. 23.4.2\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jul<br/>2004</div></div>, <div class=\"\">Jul<br/>2004</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Inspired by Google's PageRank algorithm, Mihalcea proposes <em>TextRank</em>, a <strong>graph-based algorithm</strong>. Each sentence is a node in the graph. Edges correspond to sentence similarities using a metric such as cosine similarity.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Kumar-et-al.-2016\" title=\"Kumar et al. 2016\"></a></sup> A weighted graph is constructed from the text. A ranking algorithm (such as HITS, <abbr data-title=\"» Parts of Speech\">POS</abbr> or PageRank) is run on the graph. Graph nodes with the best scores are selected for the summary.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Mihalcea-2004\" title=\"Mihalcea 2004\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"year-only\">2006</div></div>, <div class=\"year-only\">2006</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Wu proposes <strong>event-based summarization</strong>. Event terms could be verbs (incorporate) or action nouns (incorporation). Event elements are typically named entities (Person, Organisation, Location, Time). Document is represented as an event map on which PageRank algorithm is employed.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Wu-2006\" title=\"Wu 2006\"></a></sup> The work of Li et al. is also event-based and it looks at intra-event and inter-event relevance.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Li-et-al.-2006\" title=\"Li et al. 2006\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2015</div></div>, <div class=\"\">Sep<br/>2015</div>, <div class=\"cd-timeline-content animated slideInRight\"><p>Rush et al. apply <strong>neural networks for abstractive summarization</strong>. Previous work on abstractive summarization relied on linguistic constraints or syntactic transformations. The proposed approach applies a neural language model along with an attention-based input encoder. They experiment with three different encoders: bag-of-words, convolutional (TDNN) and attention-based. The model using attention-based encoder performs best. Experiments are limited to headline generation based on only the first sentence. The model is trained on English Gigaword corpus.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Rush-et-al.-2015\" title=\"Rush et al. 2015\"></a></sup> This work is improved by many others in 2016.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Aug<br/>2016</div></div>, <div class=\"\">Aug<br/>2016</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\" data-fullsrc=\"/images/article/261/3283.1582303817.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-5\" src=\"/images/article/261/3283.1582303817.s.png\" title=\"Hierarchical encoder with hierarchical attention. Source: Nallapati et al. 2016, fig. 3.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Nallapati et al. use an <strong>attentional encoder-decoder <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr></strong> for abstractive summarization. Input embedding is feature-rich with word, <abbr data-title=\"» Parts of Speech\">POS</abbr>, <abbr data-title=\"» Named Entity Recognition\">NER</abbr>, TF, and <abbr data-title=\"» Inverse Document Frequency\">IDF</abbr>. A pointer-generator model handles rare or <abbr data-title=\"» Out of Vocabulary\">OOV</abbr> words. The attention mechanism is hierarchical at word and sentence levels. Since existing datasets are limited to single sentence summaries, they present a new dataset from <abbr data-title=\"» Convolutional Neural Network\">CNN</abbr>/DailyMail news stories with an average of 53 words and 3.72 sentences in the summaries.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016\"></a></sup> This work establishes a baseline for abstractive summarization of long texts.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#See-et-al.-2017\" title=\"See et al. 2017, sec. 3\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Nallapati-et-al.-2016\" title=\"Nallapati et al. 2016, fig. 3\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Jan<br/>2018</div></div>, <div class=\"\">Jan<br/>2018</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\" data-fullsrc=\"/images/article/261/8230.1582303833.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-6\" src=\"/images/article/261/8230.1582303833.s.png\" title=\"Original self-attention decoder (left) and its modified versions. Source: Liu et al. 2018, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>As an exercise in multi-document summarization, Liu et al. attempt to <strong>generate Wikipedia articles</strong>. In the extractive stage, they select the most important content tokens. For the abstractive stage, they use a scalable decoder-only transformer architecture in which input and output sequences are combined into a single sequence. To make it scale for longer sequences, they introduce memory-compressed attention and local attention. The final model has five layers alternating between memory-compressed and local attention.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018\"></a></sup> <sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Allahyari-et-al.-2017\" title=\"Allahyari et al. 2017, sec. 7\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-et-al.-2018\" title=\"Liu et al. 2018, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Oct<br/>2019</div></div>, <div class=\"\">Oct<br/>2019</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\" data-fullsrc=\"/images/article/261/1998.1582303922.jpg\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-7\" src=\"/images/article/261/1998.1582303922.s.jpg\" title=\"Use of a knowledge graph and attention to generate answer to a question. Source: Fan et al. 2019, fig. 5.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Fan et al. show that using <strong>knowledge graph representations</strong> of the text as input to a seq2seq model gives better performance. The graph is linearized before it's given to a transformer encoder. Graph construction involves merging nodes and resolving coreferences.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Fan-et-al.-2019\" title=\"Fan et al. 2019, fig. 5\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"cd-timeline-block\"><div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>\n",
              " <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div></div>, <div class=\"cd-timeline-date animated zoomIn\"><div class=\"\">Sep<br/>2019</div></div>, <div class=\"\">Sep<br/>2019</div>, <div class=\"cd-timeline-content animated slideInRight\"><figure class=\"uk-align-right uk-thumbnail\"><img alt=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\" data-fullsrc=\"/images/article/261/2731.1582303944.png\" data-uk-modal=\"{target:'#image-slideshow'}\" id=\"img-8\" src=\"/images/article/261/2731.1582303944.s.png\" title=\"Architecture of BERTSUM. Source: Liu 2019, fig. 1.\"/><div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div></figure><p>Liu proposes <em>BERTSUM</em>, a modification of <abbr data-title=\"» Bidirectional Encoder Representations from Transformers\">BERT</abbr> for summarization. The model encodes multiple sentences as a single input sequence. Interval segment embeddings are use to distinguish the sentences. For fine-tuning and capturing document-level features, he tries different summarization layers: simple classifier, <abbr data-title=\"» Recurrent Neural Network\">RNN</abbr>, inter-sentence transformer. He finds that two-layer inter-sentence transformer performs best.<sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019\"></a></sup> </p></div>, <div class=\"milestone-img-caption\"><sup class=\"inline-citation\"><a class=\"uk-icon-justify uk-icon-asterisk\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#Liu-2019\" title=\"Liu 2019, fig. 1\"></a></sup> <i class=\"uk-icon-search-plus article-img-caption-icon\" data-uk-modal=\"{target:'#image-slideshow'}\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"Zoom in\"></i><i class=\"uk-icon-clone article-img-caption-icon\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"View in new tab\"></i></div>, <div class=\"article-tags\">\n",
              " <a href=\"/site-map/browse-articles/algorithms\" rel=\"nofollow\">algorithms</a>\n",
              " <a href=\"/site-map/browse-articles/natural+language+processing\" rel=\"nofollow\">natural language processing</a>\n",
              " <a href=\"/site-map/browse-articles/text+analytics\" rel=\"nofollow\">text analytics</a>\n",
              " </div>, <div class=\"uk-modal\" id=\"author-stats-modal\">\n",
              " <div class=\"author-stats-modal uk-modal-dialog\">\n",
              " <a class=\"uk-modal-close uk-close\"></a>\n",
              " <h2>Author-wise Stats for Article Edits</h2><a href=\"\"></a>\n",
              " <div class=\"uk-grid table-head\">\n",
              " <div class=\"uk-width-medium-1-3\">Author</div>\n",
              " <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid dashboard-table\">\n",
              " <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>\n",
              " <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid author-stats-table-footer\"><div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div></div>\n",
              " </div>\n",
              " </div>, <div class=\"author-stats-modal uk-modal-dialog\">\n",
              " <a class=\"uk-modal-close uk-close\"></a>\n",
              " <h2>Author-wise Stats for Article Edits</h2><a href=\"\"></a>\n",
              " <div class=\"uk-grid table-head\">\n",
              " <div class=\"uk-width-medium-1-3\">Author</div>\n",
              " <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid dashboard-table\">\n",
              " <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>\n",
              " <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-grid author-stats-table-footer\"><div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div></div>\n",
              " </div>, <div class=\"uk-grid table-head\">\n",
              " <div class=\"uk-width-medium-1-3\">Author</div>\n",
              " <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>, <div class=\"uk-width-medium-1-3\">Author</div>, <div class=\"uk-width-medium-2-3 col-number\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>\n",
              " </div>, <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>\n",
              " </div>, <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> <span class=\"col-status\">No. of Edits</span>\n",
              " </div>, <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-comments-o uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> <span class=\"col-status\">No. of Chats</span>\n",
              " </div>, <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-medium\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> <span class=\"col-status\">DevCoins</span>\n",
              " </div>, <div class=\"uk-grid dashboard-table\">\n",
              " <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>\n",
              " <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>\n",
              " </div>, <div class=\"uk-width-medium-1-3\"><img alt=\"Avatar of user arvindpdmn\" data-uk-tooltip=\"{cls:'ttip'}\" src=\"/images/avatar/44.869607870.1497946746.jpg\" title=\"arvindpdmn\"/><a href=\"/user/arvindpdmn\">arvindpdmn</a></div>, <div class=\"uk-width-medium-2-3\">\n",
              " <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>\n",
              " </div>, <div class=\"uk-grid uk-grid-collapse\">\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>\n",
              " <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>\n",
              " </div>, <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Edits\"></i> 2\n",
              "       </div>, <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-copy uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# Chats\"></i> 0\n",
              "       </div>, <div class=\"uk-width-1-3 col-number\">\n",
              " <i class=\"uk-icon uk-icon-database uk-icon-small field-head\" data-uk-tooltip=\"{cls:'ttip'}\" title=\"# DevCoins\"></i> 1638\n",
              "       </div>, <div class=\"uk-grid author-stats-table-footer\"><div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div></div>, <div class=\"uk-width-medium-1-1 uk-text-right\">\n",
              " DevCoins due to articles, chats, their likes and article hits are included.\n",
              " </div>, <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>\n",
              " Words<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Chats<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>, <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>\n",
              " Words<br/>\n",
              " </div>\n",
              " </div>, <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>\n",
              " Words<br/>\n",
              " </div>, <div class=\"stats-number number-upcounter\">\n",
              " 2477\n",
              "     </div>, <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Chats<br/>\n",
              " </div>\n",
              " </div>, <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Chats<br/>\n",
              " </div>, <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>, <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>\n",
              " Authors<br/>\n",
              " </div>\n",
              " </a>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>\n",
              " Edits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>, <div class=\"uk-width-1-2\">\n",
              " <a data-uk-modal=\"\" data-uk-tooltip=\"{cls:'ttip'}\" href=\"#author-stats-modal\" title=\"Stats by Author\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>\n",
              " Authors<br/>\n",
              " </div>\n",
              " </a>\n",
              " </div>, <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>\n",
              " Authors<br/>\n",
              " </div>, <div class=\"stats-number number-upcounter\">\n",
              " 1\n",
              "     </div>, <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>\n",
              " Edits<br/>\n",
              " </div>\n",
              " </div>, <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>\n",
              " Edits<br/>\n",
              " </div>, <div class=\"stats-number number-upcounter\">\n",
              " 2\n",
              "     </div>, <div class=\"uk-grid\" data-uk-grid-margin=\"\">\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Likes<br/>\n",
              " </div>\n",
              " </div>\n",
              " <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>\n",
              " Hits<br/>\n",
              " </div>\n",
              " </div>\n",
              " </div>, <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Likes<br/>\n",
              " </div>\n",
              " </div>, <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>\n",
              " Likes<br/>\n",
              " </div>, <div class=\"stats-number number-upcounter\">\n",
              " 0\n",
              "     </div>, <div class=\"uk-width-1-2\">\n",
              " <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>\n",
              " Hits<br/>\n",
              " </div>\n",
              " </div>, <div class=\"article-stats-card\">\n",
              " <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>\n",
              " Hits<br/>\n",
              " </div>, <div class=\"stats-number number-upcounter\">\n",
              " 963\n",
              "     </div>, <div class=\"article-cite-as\">Devopedia. 2020. \"Text Summarization.\" Version 2, February 21. Accessed 2020-05-17. https://devopedia.org/text-summarization</div>, <div class=\"uk-container uk-container-center\">\n",
              " <div class=\"uk-flex uk-flex-middle uk-flex-space-between uk-text-center-small\">\n",
              " <div class=\"tm-footer-left\">\n",
              " <div class=\"uk-panel\"><div class=\"uk-grid uk-subnav\"><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about\">About</a></li><li><a href=\"/site-info/terms-of-use\">Terms of Use</a></li><li><a href=\"/site-info/terms-of-use#privacy-policy\">Privacy Policy</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/foundation\">Foundation</a></li><li><a href=\"/site-info/foundation#trustees\">Trustees</a></li><li><a href=\"/site-info/foundation#donations\">Donations</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about#mission\">Mission</a></li><li><a href=\"/site-info/about#values\">Values</a></li><li><a href=\"/site-info/about#licensing\">Licensing</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-map/events\">Events</a></li><li><a href=\"https://github.com/DevopediaOrg/webapp/issues\" rel=\"noopener\" target=\"_blank\">Report Issues</a></li><li><a href=\"https://github.com/DevopediaOrg\" rel=\"noopener\" target=\"_blank\">Open Source Code</a></li></ul></div></div></div> </div>\n",
              " <a class=\"tm-totop-scroller\" data-uk-smooth-scroll=\"\" href=\"#\"></a>\n",
              " <div class=\"tm-footer-right\">\n",
              " <div class=\"uk-panel\">\n",
              " <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" rel=\"noopener\" target=\"_blank\"><img alt=\"CC BY-SA 4.0\" src=\"/images/cc-by-sa-logo.png\" style=\"height:25px\" title=\"CC BY-SA 4.0\"/></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-facebook uk-icon-small\" href=\"https://www.facebook.com/Devopedia/\" rel=\"noopener\" target=\"_blank\" title=\"Facebook\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-twitter uk-icon-small\" href=\"https://twitter.com/Devopedia\" rel=\"noopener\" target=\"_blank\" title=\"Twitter\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-reddit uk-icon-small\" href=\"https://www.reddit.com/r/Devopedia/\" rel=\"noopener\" target=\"_blank\" title=\"Reddit\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-envelope uk-icon-small\" href=\"mailto:webadmin@devopedia.org\" rel=\"noopener\" target=\"_blank\" title=\"Email\"></a></div> </div>\n",
              " </div>\n",
              " </div>, <div class=\"uk-flex uk-flex-middle uk-flex-space-between uk-text-center-small\">\n",
              " <div class=\"tm-footer-left\">\n",
              " <div class=\"uk-panel\"><div class=\"uk-grid uk-subnav\"><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about\">About</a></li><li><a href=\"/site-info/terms-of-use\">Terms of Use</a></li><li><a href=\"/site-info/terms-of-use#privacy-policy\">Privacy Policy</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/foundation\">Foundation</a></li><li><a href=\"/site-info/foundation#trustees\">Trustees</a></li><li><a href=\"/site-info/foundation#donations\">Donations</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about#mission\">Mission</a></li><li><a href=\"/site-info/about#values\">Values</a></li><li><a href=\"/site-info/about#licensing\">Licensing</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-map/events\">Events</a></li><li><a href=\"https://github.com/DevopediaOrg/webapp/issues\" rel=\"noopener\" target=\"_blank\">Report Issues</a></li><li><a href=\"https://github.com/DevopediaOrg\" rel=\"noopener\" target=\"_blank\">Open Source Code</a></li></ul></div></div></div> </div>\n",
              " <a class=\"tm-totop-scroller\" data-uk-smooth-scroll=\"\" href=\"#\"></a>\n",
              " <div class=\"tm-footer-right\">\n",
              " <div class=\"uk-panel\">\n",
              " <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" rel=\"noopener\" target=\"_blank\"><img alt=\"CC BY-SA 4.0\" src=\"/images/cc-by-sa-logo.png\" style=\"height:25px\" title=\"CC BY-SA 4.0\"/></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-facebook uk-icon-small\" href=\"https://www.facebook.com/Devopedia/\" rel=\"noopener\" target=\"_blank\" title=\"Facebook\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-twitter uk-icon-small\" href=\"https://twitter.com/Devopedia\" rel=\"noopener\" target=\"_blank\" title=\"Twitter\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-reddit uk-icon-small\" href=\"https://www.reddit.com/r/Devopedia/\" rel=\"noopener\" target=\"_blank\" title=\"Reddit\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-envelope uk-icon-small\" href=\"mailto:webadmin@devopedia.org\" rel=\"noopener\" target=\"_blank\" title=\"Email\"></a></div> </div>\n",
              " </div>, <div class=\"tm-footer-left\">\n",
              " <div class=\"uk-panel\"><div class=\"uk-grid uk-subnav\"><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about\">About</a></li><li><a href=\"/site-info/terms-of-use\">Terms of Use</a></li><li><a href=\"/site-info/terms-of-use#privacy-policy\">Privacy Policy</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/foundation\">Foundation</a></li><li><a href=\"/site-info/foundation#trustees\">Trustees</a></li><li><a href=\"/site-info/foundation#donations\">Donations</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about#mission\">Mission</a></li><li><a href=\"/site-info/about#values\">Values</a></li><li><a href=\"/site-info/about#licensing\">Licensing</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-map/events\">Events</a></li><li><a href=\"https://github.com/DevopediaOrg/webapp/issues\" rel=\"noopener\" target=\"_blank\">Report Issues</a></li><li><a href=\"https://github.com/DevopediaOrg\" rel=\"noopener\" target=\"_blank\">Open Source Code</a></li></ul></div></div></div> </div>, <div class=\"uk-panel\"><div class=\"uk-grid uk-subnav\"><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about\">About</a></li><li><a href=\"/site-info/terms-of-use\">Terms of Use</a></li><li><a href=\"/site-info/terms-of-use#privacy-policy\">Privacy Policy</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/foundation\">Foundation</a></li><li><a href=\"/site-info/foundation#trustees\">Trustees</a></li><li><a href=\"/site-info/foundation#donations\">Donations</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about#mission\">Mission</a></li><li><a href=\"/site-info/about#values\">Values</a></li><li><a href=\"/site-info/about#licensing\">Licensing</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-map/events\">Events</a></li><li><a href=\"https://github.com/DevopediaOrg/webapp/issues\" rel=\"noopener\" target=\"_blank\">Report Issues</a></li><li><a href=\"https://github.com/DevopediaOrg\" rel=\"noopener\" target=\"_blank\">Open Source Code</a></li></ul></div></div></div>, <div class=\"uk-grid uk-subnav\"><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about\">About</a></li><li><a href=\"/site-info/terms-of-use\">Terms of Use</a></li><li><a href=\"/site-info/terms-of-use#privacy-policy\">Privacy Policy</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/foundation\">Foundation</a></li><li><a href=\"/site-info/foundation#trustees\">Trustees</a></li><li><a href=\"/site-info/foundation#donations\">Donations</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about#mission\">Mission</a></li><li><a href=\"/site-info/about#values\">Values</a></li><li><a href=\"/site-info/about#licensing\">Licensing</a></li></ul></div><div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-map/events\">Events</a></li><li><a href=\"https://github.com/DevopediaOrg/webapp/issues\" rel=\"noopener\" target=\"_blank\">Report Issues</a></li><li><a href=\"https://github.com/DevopediaOrg\" rel=\"noopener\" target=\"_blank\">Open Source Code</a></li></ul></div></div>, <div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about\">About</a></li><li><a href=\"/site-info/terms-of-use\">Terms of Use</a></li><li><a href=\"/site-info/terms-of-use#privacy-policy\">Privacy Policy</a></li></ul></div>, <div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/foundation\">Foundation</a></li><li><a href=\"/site-info/foundation#trustees\">Trustees</a></li><li><a href=\"/site-info/foundation#donations\">Donations</a></li></ul></div>, <div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-info/about#mission\">Mission</a></li><li><a href=\"/site-info/about#values\">Values</a></li><li><a href=\"/site-info/about#licensing\">Licensing</a></li></ul></div>, <div class=\"uk-width-small-1-2 uk-width-medium-1-4\"><ul><li><a href=\"/site-map/events\">Events</a></li><li><a href=\"https://github.com/DevopediaOrg/webapp/issues\" rel=\"noopener\" target=\"_blank\">Report Issues</a></li><li><a href=\"https://github.com/DevopediaOrg\" rel=\"noopener\" target=\"_blank\">Open Source Code</a></li></ul></div>, <div class=\"tm-footer-right\">\n",
              " <div class=\"uk-panel\">\n",
              " <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" rel=\"noopener\" target=\"_blank\"><img alt=\"CC BY-SA 4.0\" src=\"/images/cc-by-sa-logo.png\" style=\"height:25px\" title=\"CC BY-SA 4.0\"/></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-facebook uk-icon-small\" href=\"https://www.facebook.com/Devopedia/\" rel=\"noopener\" target=\"_blank\" title=\"Facebook\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-twitter uk-icon-small\" href=\"https://twitter.com/Devopedia\" rel=\"noopener\" target=\"_blank\" title=\"Twitter\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-reddit uk-icon-small\" href=\"https://www.reddit.com/r/Devopedia/\" rel=\"noopener\" target=\"_blank\" title=\"Reddit\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-envelope uk-icon-small\" href=\"mailto:webadmin@devopedia.org\" rel=\"noopener\" target=\"_blank\" title=\"Email\"></a></div> </div>, <div class=\"uk-panel\">\n",
              " <a href=\"https://creativecommons.org/licenses/by-sa/4.0/\" rel=\"noopener\" target=\"_blank\"><img alt=\"CC BY-SA 4.0\" src=\"/images/cc-by-sa-logo.png\" style=\"height:25px\" title=\"CC BY-SA 4.0\"/></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-facebook uk-icon-small\" href=\"https://www.facebook.com/Devopedia/\" rel=\"noopener\" target=\"_blank\" title=\"Facebook\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-twitter uk-icon-small\" href=\"https://twitter.com/Devopedia\" rel=\"noopener\" target=\"_blank\" title=\"Twitter\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-reddit uk-icon-small\" href=\"https://www.reddit.com/r/Devopedia/\" rel=\"noopener\" target=\"_blank\" title=\"Reddit\"></a>\n",
              " <a class=\"uk-margin-right uk-icon-hover uk-icon-envelope uk-icon-small\" href=\"mailto:webadmin@devopedia.org\" rel=\"noopener\" target=\"_blank\" title=\"Email\"></a></div>, <div class=\"uk-offcanvas\" id=\"offcanvas\">\n",
              " <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip\"><div class=\"uk-panel main-search-box\">\n",
              " <form action=\"/\" class=\"uk-search\" id=\"search-100-5ec127cf3d771\" method=\"post\">\n",
              " <input class=\"uk-search-field\" name=\"searchword\" placeholder=\"search...\" type=\"text\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"search\"/>\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_search\"/>\n",
              " <input name=\"Itemid\" type=\"hidden\" value=\"104\"/>\n",
              " </form>\n",
              " </div>\n",
              " <ul class=\"uk-nav uk-nav-offcanvas\"><li class=\"uk-parent uk-nav-header\">Site Map\n",
              " <ul class=\"uk-nav-sub\"><li><a href=\"/site-map/dashboard\" rel=\"nofollow\">Dashboard</a></li><li><a href=\"/site-map/browse-articles\" rel=\"nofollow\">Browse Articles</a></li><li><a class=\"menu-line-above\" href=\"/site-map/events\">Events</a></li><li><a class=\"menu-line-above\" href=\"/site-map/about-devopedia\">About Devopedia</a></li><li><a href=\"/site-map/author-guidelines\">Author Guidelines</a></li><li><a href=\"/site-map/site-stats\">Site Stats</a></li><li><a href=\"/site-map/faq-help\" rel=\"nofollow\">FAQ &amp; Help</a></li></ul></li></ul>\n",
              " <div class=\"uk-panel social-login\"><h3 class=\"uk-panel-title\">Login</h3><div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"offcanvas-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"offcanvas-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"offcanvas-form-login-username\">\n",
              " <label for=\"offcanvas-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"offcanvas-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"offcanvas-form-login-password\">\n",
              " <label for=\"offcanvas-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"offcanvas-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"offcanvas-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"offcanvas-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"offcanvas-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\">\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\">\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\">\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></input></input></input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>\n",
              " </div></div>\n",
              " </div>, <div class=\"uk-offcanvas-bar uk-offcanvas-bar-flip\"><div class=\"uk-panel main-search-box\">\n",
              " <form action=\"/\" class=\"uk-search\" id=\"search-100-5ec127cf3d771\" method=\"post\">\n",
              " <input class=\"uk-search-field\" name=\"searchword\" placeholder=\"search...\" type=\"text\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"search\"/>\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_search\"/>\n",
              " <input name=\"Itemid\" type=\"hidden\" value=\"104\"/>\n",
              " </form>\n",
              " </div>\n",
              " <ul class=\"uk-nav uk-nav-offcanvas\"><li class=\"uk-parent uk-nav-header\">Site Map\n",
              " <ul class=\"uk-nav-sub\"><li><a href=\"/site-map/dashboard\" rel=\"nofollow\">Dashboard</a></li><li><a href=\"/site-map/browse-articles\" rel=\"nofollow\">Browse Articles</a></li><li><a class=\"menu-line-above\" href=\"/site-map/events\">Events</a></li><li><a class=\"menu-line-above\" href=\"/site-map/about-devopedia\">About Devopedia</a></li><li><a href=\"/site-map/author-guidelines\">Author Guidelines</a></li><li><a href=\"/site-map/site-stats\">Site Stats</a></li><li><a href=\"/site-map/faq-help\" rel=\"nofollow\">FAQ &amp; Help</a></li></ul></li></ul>\n",
              " <div class=\"uk-panel social-login\"><h3 class=\"uk-panel-title\">Login</h3><div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"offcanvas-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"offcanvas-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"offcanvas-form-login-username\">\n",
              " <label for=\"offcanvas-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"offcanvas-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"offcanvas-form-login-password\">\n",
              " <label for=\"offcanvas-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"offcanvas-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"offcanvas-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"offcanvas-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"offcanvas-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\">\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\">\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\">\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></input></input></input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>\n",
              " </div></div>, <div class=\"uk-panel main-search-box\">\n",
              " <form action=\"/\" class=\"uk-search\" id=\"search-100-5ec127cf3d771\" method=\"post\">\n",
              " <input class=\"uk-search-field\" name=\"searchword\" placeholder=\"search...\" type=\"text\"/>\n",
              " <input name=\"task\" type=\"hidden\" value=\"search\"/>\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_search\"/>\n",
              " <input name=\"Itemid\" type=\"hidden\" value=\"104\"/>\n",
              " </form>\n",
              " </div>, <div class=\"uk-panel social-login\"><h3 class=\"uk-panel-title\">Login</h3><div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"offcanvas-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"offcanvas-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"offcanvas-form-login-username\">\n",
              " <label for=\"offcanvas-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"offcanvas-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"offcanvas-form-login-password\">\n",
              " <label for=\"offcanvas-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"offcanvas-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"offcanvas-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"offcanvas-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"offcanvas-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\">\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\">\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\">\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></input></input></input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>\n",
              " </div>, <div class=\"jlslogin\">\n",
              " <div class=\"slogin-buttons slogin-compact\" id=\"offcanvas-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <form action=\"/\" id=\"offcanvas-login-form\" method=\"post\">\n",
              " <fieldset class=\"userdata\">\n",
              " <p id=\"offcanvas-form-login-username\">\n",
              " <label for=\"offcanvas-modlgn-username\">Username</label>\n",
              " <input class=\"inputbox\" id=\"offcanvas-modlgn-username\" name=\"username\" size=\"18\" type=\"text\">\n",
              " </input></p>\n",
              " <p id=\"offcanvas-form-login-password\">\n",
              " <label for=\"offcanvas-modlgn-passwd\">Password</label>\n",
              " <input class=\"inputbox\" id=\"offcanvas-modlgn-passwd\" name=\"password\" size=\"18\" type=\"password\">\n",
              " </input></p>\n",
              " <p id=\"offcanvas-form-login-remember\" style=\"display:none\">\n",
              " <label for=\"offcanvas-modlgn-remember\">\n",
              " <input checked=\"\" class=\"inputbox\" id=\"offcanvas-modlgn-remember\" name=\"remember\" type=\"checkbox\" value=\"yes\">\n",
              " \t\t\t\t  \tRemember Me\t\t\t\t </input></label>\n",
              " </p>\n",
              " <div class=\"slogin-clear\"></div>\n",
              " <input class=\"button\" name=\"Submit\" type=\"submit\" value=\"Log in\">\n",
              " <input name=\"option\" type=\"hidden\" value=\"com_users\">\n",
              " <input name=\"task\" type=\"hidden\" value=\"user.login\">\n",
              " <input name=\"return\" type=\"hidden\" value=\"aHR0cHM6Ly9kZXZvcGVkaWEub3JnL3RleHQtc3VtbWFyaXphdGlvbg==\">\n",
              " <input name=\"5112020352767346717cb2c3b1ff5840\" type=\"hidden\" value=\"1\"/> </input></input></input></input></fieldset>\n",
              " <ul class=\"ul-jlslogin\">\n",
              " <li>\n",
              " <a href=\"/component/users/?view=reset\" rel=\"nofollow\">\n",
              "                     Forgot your password?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=remind\" rel=\"nofollow\">\n",
              "                     Forgot your username?</a>\n",
              " </li>\n",
              " <li>\n",
              " <a href=\"/component/users/?view=registration\" rel=\"nofollow\">\n",
              "                         Create an account</a>\n",
              " </li>\n",
              " </ul>\n",
              " </form>\n",
              " </div>, <div class=\"slogin-buttons slogin-compact\" id=\"offcanvas-slogin-buttons\">\n",
              " <a href=\"/component/slogin/provider/facebook/auth\" rel=\"nofollow\" title=\"Facebook\"><span class=\"facebookslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/google/auth\" rel=\"nofollow\" title=\"Google\"><span class=\"googleslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/linkedin/auth\" rel=\"nofollow\" title=\"LinkedIn\"><span class=\"linkedinslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/github/auth\" rel=\"nofollow\" title=\"GitHub\"><span class=\"githubslogin\"> </span></a>\n",
              " <a href=\"/component/slogin/provider/bitbucket/auth\" rel=\"nofollow\" title=\"BitBucket\"><span class=\"bitbucketslogin\"> </span></a>\n",
              " </div>, <div class=\"slogin-clear\"></div>, <div class=\"slogin-clear\"></div>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj2IFyJLdjb1",
        "colab_type": "code",
        "outputId": "c62eb2dd-7c90-4d59-fad9-c4eb9d131d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import urllib3\n",
        "http = urllib3.PoolManager()\n",
        "rr = http.request('GET', 'https://www.gutenberg.org/files/766/766-0.txt')\n",
        "rr.data[:1000]\n",
        "open(\"David_Copperfield_new.txt\", 'wb').write(rr.data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2033139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnBBMZsjhXUE",
        "colab_type": "code",
        "outputId": "d6f6aa7a-4575-4eaa-ea90-c0189c07ec8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import spacy\n",
        "from spacy.tokens.doc import Doc\n",
        "from spacy.vocab import Vocab\n",
        "doc = Doc(Vocab(), words=[u'Hi', u'there'])\n",
        "print(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi there \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p4lhg7_iPR2",
        "colab_type": "code",
        "outputId": "149c2077-dd7c-48e3-a200-b4643942a781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "doc = nlp('I want a green apple')\n",
        "[w for w in doc[4].lefts]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[a, green]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx83v7PGi4j2",
        "colab_type": "code",
        "outputId": "7ec7ee5d-9db6-4814-d4ac-65456f5d55dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "doc = nlp(u'A severe storm hit the beach. It started to rain.')\n",
        "for sent in doc.sents:\n",
        "  print(len(sent))\n",
        "  [print(sent[i]) for i in range(len(sent))]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "A\n",
            "severe\n",
            "storm\n",
            "hit\n",
            "the\n",
            "beach\n",
            ".\n",
            "5\n",
            "It\n",
            "started\n",
            "to\n",
            "rain\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJk0g_hkmtss",
        "colab_type": "code",
        "outputId": "6bdba032-c4e6-4380-9f66-2a395324f007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "doc = nlp(u'A severe storm hit the beach. It started to rain.')\n",
        "for token in doc:\n",
        " if token.pos_=='NOUN':\n",
        "     chunk = ''\n",
        "     for w in token.children:\n",
        "      if w.pos_ == 'DET' or w.pos_ == 'ADJ':\n",
        "         chunk = chunk + w.text + ' '\n",
        "     chunk = chunk + token.text\n",
        "     print(chunk)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A severe storm\n",
            "the beach\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqSqbfhanveF",
        "colab_type": "code",
        "outputId": "d0cd604b-bd55-4e28-b605-0be16d20a457",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "doc = nlp('I want a green apple')\n",
        "print(doc[2:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a green apple\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PpH29nToC4y",
        "colab_type": "code",
        "outputId": "33fdb6f5-c5de-4c72-dcb6-8d70a17ce31a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "doc = nlp(u'The Golden Gate Bridge is an iconic landmark in San Francisco.')\n",
        "print([doc[i] for i in range(len(doc))])\n",
        "for token in doc:\n",
        "      print(token.text, token.lemma_, token.pos_, token.dep_)\n",
        "#With the span.merge() method, we can change this default behavior:\n",
        "span = doc[1:4]\n",
        "lem_id = doc.vocab.strings[span.text]\n",
        "span.merge(lemma = lem_id)\n",
        "#To be precise, we pass on the lemma’s id obtained through the doc.vocab.string attribute.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[The, Golden, Gate, Bridge, is, an, iconic, landmark, in, San, Francisco, .]\n",
            "The the DET det\n",
            "Golden Golden PROPN compound\n",
            "Gate Gate PROPN compound\n",
            "Bridge Bridge PROPN nsubj\n",
            "is be AUX ROOT\n",
            "an an DET det\n",
            "iconic iconic ADJ amod\n",
            "landmark landmark NOUN attr\n",
            "in in ADP prep\n",
            "San San PROPN compound\n",
            "Francisco Francisco PROPN pobj\n",
            ". . PUNCT punct\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Golden Gate Bridge"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grp2OVIOp8EK",
        "colab_type": "code",
        "outputId": "08784a73-7a78-49d4-f6cf-9693bc892abc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "   import spacy\n",
        "   nlp = spacy.load('en')\n",
        "   #first sample text\n",
        "   doc1 = nlp(u'Google Search, often referred to as simply Google, is the most used search engine nowadays. It handles a huge number of searches each day.')\n",
        "   #second sample text\n",
        "   doc2 = nlp(u'Microsoft Windows is a family of proprietary operating systems \\\n",
        "   developed and sold by Microsoft. The company also produces a wide range of other software for desktops and servers.')\n",
        "   #third sample text\n",
        "   doc3 = nlp(u\"Titicaca is a large, deep, mountain lake in the Andes. It is known as the highest navigable lake in the world.\")\n",
        "   docs = [doc1,doc2,doc3]\n",
        "   spans = {}\n",
        "   for j,doc in enumerate(docs):\n",
        "     named_entity_span = [doc[i].text for i in range(len(doc)) if\n",
        "      doc[i].ent_type != 0]\n",
        "     print(named_entity_span)\n",
        "     named_entity_span = ' '.join(named_entity_span)\n",
        "     named_entity_span = nlp(named_entity_span)\n",
        "     spans.update({j:named_entity_span})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Google', 'Search', 'Google', 'each', 'day']\n",
            "['Microsoft', 'Windows', 'Microsoft']\n",
            "['Andes']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-Ah94kbqlCc",
        "colab_type": "text"
      },
      "source": [
        "We group the Docs with the sample texts into a list to make it possible to iterate over them in a loop ➊. We define a Python dictionary to store the keywords for each text ➋. In a loop iterating over the Docs ➌, we extract these keywords in a separate list for each text, selecting only the words marked as named entities ➍. Then we print out the list to see what it contains ➎. Next, we convert this list into a plain string ➏ to which we then apply the pipeline, converting it to a Doc object ➐. We then append the Doc to the spans dictionary defined earlier ➑. Now we can see the words in each text whose vectors we’ll compare.\n",
        "\n",
        "Next, we call similarity() on these spans and print the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTCWnAxQqs04",
        "colab_type": "code",
        "outputId": "aeb50e43-ceb0-4d5e-f2b9-adefe045853a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('doc1 is similar to doc2:',spans[0].similarity(spans[1]))\n",
        "print('doc1 is similar to doc3:',spans[0].similarity(spans[2]))\n",
        "print('doc2 is similar to doc3:',spans[1].similarity(spans[2]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "doc1 is similar to doc2: 0.5977375871782556\n",
            "doc1 is similar to doc3: 0.33277840983778667\n",
            "doc2 is similar to doc3: 0.496476790289189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGmHLhhRq8_P",
        "colab_type": "text"
      },
      "source": [
        "In particularly large texts, you might pick out the named entities found in it, because they most likely best describe the text’s category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lUsQa-1rbZs",
        "colab_type": "code",
        "outputId": "c98e6aba-b422-420b-de79-50f9856f816e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install stanza\n",
        "import stanza\n",
        "# download English model\n",
        "stanza.download('en')\n",
        "# initialize English neural pipeline\n",
        "nlp = stanza.Pipeline('en')\n",
        "# run annotation over a sentence\n",
        "doc = nlp('The Golden Gate Bridge is an iconic landmark in SFO')\n",
        "print(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/9c/60689521a971a57dd02d2925105efedefa9dccd76c9a0b92566683d43e89/stanza-1.0.1-py3-none-any.whl (193kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 81kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.5.0+cu101)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (46.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Installing collected packages: stanza\n",
            "Successfully installed stanza-1.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 9.09MB/s]                    \n",
            "2020-05-17 08:17:17 INFO: Downloading default packages for language: en (English)...\n",
            "Downloading http://nlp.stanford.edu/software/stanza/1.0.0/en/default.zip: 100%|██████████| 402M/402M [00:58<00:00, 6.94MB/s]\n",
            "2020-05-17 08:18:23 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-05-17 08:18:23 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| pos       | ewt       |\n",
            "| lemma     | ewt       |\n",
            "| depparse  | ewt       |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2020-05-17 08:18:23 INFO: Use device: cpu\n",
            "2020-05-17 08:18:23 INFO: Loading: tokenize\n",
            "2020-05-17 08:18:23 INFO: Loading: pos\n",
            "2020-05-17 08:18:25 INFO: Loading: lemma\n",
            "2020-05-17 08:18:25 INFO: Loading: depparse\n",
            "2020-05-17 08:18:27 INFO: Loading: ner\n",
            "2020-05-17 08:18:29 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[\n",
            "  [\n",
            "    {\n",
            "      \"id\": \"1\",\n",
            "      \"text\": \"The\",\n",
            "      \"lemma\": \"the\",\n",
            "      \"upos\": \"DET\",\n",
            "      \"xpos\": \"DT\",\n",
            "      \"feats\": \"Definite=Def|PronType=Art\",\n",
            "      \"head\": 4,\n",
            "      \"deprel\": \"det\",\n",
            "      \"misc\": \"start_char=0|end_char=3\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"2\",\n",
            "      \"text\": \"Golden\",\n",
            "      \"lemma\": \"golden\",\n",
            "      \"upos\": \"PROPN\",\n",
            "      \"xpos\": \"NNP\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=4|end_char=10\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"3\",\n",
            "      \"text\": \"Gate\",\n",
            "      \"lemma\": \"Gate\",\n",
            "      \"upos\": \"PROPN\",\n",
            "      \"xpos\": \"NNP\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 4,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=11|end_char=15\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"4\",\n",
            "      \"text\": \"Bridge\",\n",
            "      \"lemma\": \"Bridge\",\n",
            "      \"upos\": \"PROPN\",\n",
            "      \"xpos\": \"NNP\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"nsubj\",\n",
            "      \"misc\": \"start_char=16|end_char=22\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"5\",\n",
            "      \"text\": \"is\",\n",
            "      \"lemma\": \"be\",\n",
            "      \"upos\": \"AUX\",\n",
            "      \"xpos\": \"VBZ\",\n",
            "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"cop\",\n",
            "      \"misc\": \"start_char=23|end_char=25\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"6\",\n",
            "      \"text\": \"an\",\n",
            "      \"lemma\": \"a\",\n",
            "      \"upos\": \"DET\",\n",
            "      \"xpos\": \"DT\",\n",
            "      \"feats\": \"Definite=Ind|PronType=Art\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"det\",\n",
            "      \"misc\": \"start_char=26|end_char=28\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"7\",\n",
            "      \"text\": \"iconic\",\n",
            "      \"lemma\": \"iconic\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJ\",\n",
            "      \"feats\": \"Degree=Pos\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"amod\",\n",
            "      \"misc\": \"start_char=29|end_char=35\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"8\",\n",
            "      \"text\": \"landmark\",\n",
            "      \"lemma\": \"landmark\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 0,\n",
            "      \"deprel\": \"root\",\n",
            "      \"misc\": \"start_char=36|end_char=44\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"9\",\n",
            "      \"text\": \"in\",\n",
            "      \"lemma\": \"in\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=45|end_char=47\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"10\",\n",
            "      \"text\": \"SFO\",\n",
            "      \"lemma\": \"SFO\",\n",
            "      \"upos\": \"PROPN\",\n",
            "      \"xpos\": \"NNP\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"nmod\",\n",
            "      \"misc\": \"start_char=48|end_char=51\"\n",
            "    }\n",
            "  ]\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7v0lTSvth-7",
        "colab_type": "code",
        "outputId": "5bf8e142-90d5-4fcc-f028-717bfeefb4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "print(doc.entities)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{\n",
            "  \"text\": \"The Golden Gate Bridge\",\n",
            "  \"type\": \"FAC\",\n",
            "  \"start_char\": 0,\n",
            "  \"end_char\": 22\n",
            "}, {\n",
            "  \"text\": \"SFO\",\n",
            "  \"type\": \"GPE\",\n",
            "  \"start_char\": 48,\n",
            "  \"end_char\": 51\n",
            "}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrACXfuUuJkd",
        "colab_type": "code",
        "outputId": "243aa9e1-0630-4c2f-8f7b-4b551f81d9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entity: The Golden Gate Bridge\ttype: FAC\n",
            "entity: SFO\ttype: GPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8OSeEkuuRm3",
        "colab_type": "code",
        "outputId": "5f186d92-ecfd-45df-87ed-b4bc9ccdae2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "print(*[f'token: {token.text}\\tner: {token.ner}' for sent in doc.sentences for token in sent.tokens], sep='\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "token: The\tner: B-FAC\n",
            "token: Golden\tner: I-FAC\n",
            "token: Gate\tner: I-FAC\n",
            "token: Bridge\tner: E-FAC\n",
            "token: is\tner: O\n",
            "token: an\tner: O\n",
            "token: iconic\tner: O\n",
            "token: landmark\tner: O\n",
            "token: in\tner: O\n",
            "token: SFO\tner: S-GPE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9wnVcmhuinI",
        "colab_type": "code",
        "outputId": "98507fe0-9cf4-45fc-8352-fdac2a03c2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "import CoreNLP\n",
        "from stanza.server import CoreNLPClient\n",
        "\n",
        "# example text\n",
        "print('---')\n",
        "print('input text')\n",
        "print('')\n",
        "\n",
        "text = \"Chris Manning is a nice person. Chris wrote a simple sentence. He also gives oranges to people.\"\n",
        "\n",
        "print(text)\n",
        "\n",
        "# set up the client\n",
        "print('---')\n",
        "print('starting up Java Stanford CoreNLP Server...')\n",
        "\n",
        "# set up the client\n",
        "with CoreNLPClient(annotators=['tokenize','ssplit','pos','lemma','ner', 'parse', 'depparse','coref'], timeout=30000, memory='16G') as client:\n",
        "    # submit the request to the server\n",
        "    ann = client.annotate(text)\n",
        "\n",
        "    # get the first sentence\n",
        "    sentence = ann.sentence[0]\n",
        "\n",
        "    # get the constituency parse of the first sentence\n",
        "    print('---')\n",
        "    print('constituency parse of first sentence')\n",
        "    constituency_parse = sentence.parseTree\n",
        "    print(constituency_parse)\n",
        "\n",
        "    # get the first subtree of the constituency parse\n",
        "    print('---')\n",
        "    print('first subtree of constituency parse')\n",
        "    print(constituency_parse.child[0])\n",
        "\n",
        "    # get the value of the first subtree\n",
        "    print('---')\n",
        "    print('value of first subtree of constituency parse')\n",
        "    print(constituency_parse.child[0].value)\n",
        "\n",
        "    # get the dependency parse of the first sentence\n",
        "    print('---')\n",
        "    print('dependency parse of first sentence')\n",
        "    dependency_parse = sentence.basicDependencies\n",
        "    print(dependency_parse)\n",
        "\n",
        "    # get the first token of the first sentence\n",
        "    print('---')\n",
        "    print('first token of first sentence')\n",
        "    token = sentence.token[0]\n",
        "    print(token)\n",
        "\n",
        "    # get the part-of-speech tag\n",
        "    print('---')\n",
        "    print('part of speech tag of token')\n",
        "    token.pos\n",
        "    print(token.pos)\n",
        "\n",
        "    # get the named entity tag\n",
        "    print('---')\n",
        "    print('named entity tag of token')\n",
        "    print(token.ner)\n",
        "\n",
        "    # get an entity mention from the first sentence\n",
        "    print('---')\n",
        "    print('first entity mention in sentence')\n",
        "    print(sentence.mentions[0])\n",
        "\n",
        "    # access the coref chain\n",
        "    print('---')\n",
        "    print('coref chains for the example')\n",
        "    print(ann.corefChain)\n",
        "\n",
        "    # Use tokensregex patterns to find who wrote a sentence.\n",
        "    pattern = '([ner: PERSON]+) /wrote/ /an?/ []{0,3} /sentence|article/'\n",
        "    matches = client.tokensregex(text, pattern)\n",
        "    # sentences contains a list with matches for each sentence.\n",
        "    assert len(matches[\"sentences\"]) == 3\n",
        "    # length tells you whether or not there are any matches in this\n",
        "    assert matches[\"sentences\"][1][\"length\"] == 1\n",
        "    # You can access matches like most regex groups.\n",
        "    matches[\"sentences\"][1][\"0\"][\"text\"] == \"Chris wrote a simple sentence\"\n",
        "    matches[\"sentences\"][1][\"0\"][\"1\"][\"text\"] == \"Chris\"\n",
        "\n",
        "    # Use semgrex patterns to directly find who wrote what.\n",
        "    pattern = '{word:wrote} >nsubj {}=subject >dobj {}=object'\n",
        "    matches = client.semgrex(text, pattern)\n",
        "    # sentences contains a list with matches for each sentence.\n",
        "    assert len(matches[\"sentences\"]) == 3\n",
        "    # length tells you whether or not there are any matches in this\n",
        "    assert matches[\"sentences\"][1][\"length\"] == 1\n",
        "    # You can access matches like most regex groups.\n",
        "    matches[\"sentences\"][1][\"0\"][\"text\"] == \"wrote\"\n",
        "    matches[\"sentences\"][1][\"0\"][\"$subject\"][\"text\"] == \"Chris\"\n",
        "    matches[\"sentences\"][1][\"0\"][\"$object\"][\"text\"] == \"sentence\"\n",
        "\n",
        "    # Tregex example\n",
        "    pattern = 'NP'\n",
        "    matches = client.tregex(text, pattern)\n",
        "    for match in matches:\n",
        "        print(matches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-a38324d96092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mCoreNLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoreNLPClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# example text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'CoreNLP'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywNxw0j6vrkn",
        "colab_type": "code",
        "outputId": "afda8202-2462-4228-ece8-091988719508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "source": [
        "import os\n",
        "os.environ[\"$CORENLP_HOME\"] = r'StanfordCoreNLP-3.9.1.1'\n",
        "!pip install StanfordCoreNLP\n",
        "from stanfordcorenlp import StanfordCoreNLP\n",
        "from stanza.server import CoreNLPClient\n",
        "# start a CoreNLP client\n",
        "with CoreNLPClient(annotators=['tokenize', 'ssplit', 'ner', 'coref']) as client:\n",
        "# run annotation over input\n",
        "  ann = client.annotate('Emily said that she liked the movie.')\n",
        "# access all entities\n",
        "  for sent in ann.sentence:\n",
        "    print(sent.mentions)\n",
        "# access coreference annotations\n",
        "    print(ann.corefChain)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting StanfordCoreNLP\n",
            "  Downloading https://files.pythonhosted.org/packages/35/cb/0a271890bbe3a77fc1aca2bc3a58b14e11799ea77cb5f7d6fb0a8b4c46fa/stanfordcorenlp-3.9.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from StanfordCoreNLP) (2.23.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from StanfordCoreNLP) (5.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->StanfordCoreNLP) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->StanfordCoreNLP) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->StanfordCoreNLP) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->StanfordCoreNLP) (3.0.4)\n",
            "Installing collected packages: StanfordCoreNLP\n",
            "Successfully installed StanfordCoreNLP-3.9.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-e834111f8418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstanza\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoreNLPClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# start a CoreNLP client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mCoreNLPClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ssplit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coref'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# run annotation over input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mann\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Emily said that she liked the movie.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stanza/server/client.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, start_server, endpoint, timeout, threads, annotators, properties, output_format, stdout, stderr, memory, be_quiet, max_char_length, preload, classpath, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mclasspath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CORENLP_HOME\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mclasspath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                     \u001b[0;34m\"Please define $CORENLP_HOME to be location of your CoreNLP distribution or pass in a classpath parameter\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                 \u001b[0mclasspath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasspath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/*\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mstart_cmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"java -Xmx{memory} -cp '{classpath}'  edu.stanford.nlp.pipeline.StanfordCoreNLPServer \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Please define $CORENLP_HOME to be location of your CoreNLP distribution or pass in a classpath parameter"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eN2m1dz6ykwd",
        "colab_type": "code",
        "outputId": "df4c7d8b-2a4e-4a15-f996-ef0744638674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "from stanfordcorenlp import StanfordCoreNLP\n",
        "import logging\n",
        "import json\n",
        "\n",
        "class StanfordNLP:\n",
        "    def __init__(self, host='http://localhost', port=9000):\n",
        "        print('before timeout')\n",
        "        self.nlp = StanfordCoreNLP(host, port=port,)\n",
        "                                   #timeout=300)  , quiet=False, logging_level=logging.DEBUG)\n",
        "        print('after timeout')\n",
        "        self.props = {\n",
        "            'annotators': 'tokenize,ssplit,pos,lemma,ner,parse,depparse,dcoref,relation',\n",
        "            'pipelineLanguage': 'en',\n",
        "            'outputFormat': 'json'\n",
        "        }\n",
        "\n",
        "    def word_tokenize(self, sentence):\n",
        "        return self.nlp.word_tokenize(sentence)\n",
        "\n",
        "    def pos(self, sentence):\n",
        "        return self.nlp.pos_tag(sentence)\n",
        "\n",
        "    def ner(self, sentence):\n",
        "        return self.nlp.ner(sentence)\n",
        "\n",
        "    def parse(self, sentence):\n",
        "        return self.nlp.parse(sentence)\n",
        "\n",
        "    def dependency_parse(self, sentence):\n",
        "        return self.nlp.dependency_parse(sentence)\n",
        "\n",
        "    def annotate(self, sentence):\n",
        "        return json.loads(self.nlp.annotate(sentence, properties=self.props))\n",
        "\n",
        "    @staticmethod\n",
        "    def tokens_to_dict(_tokens):\n",
        "        tokens = defaultdict(dict)\n",
        "        for token in _tokens:\n",
        "            tokens[int(token['index'])] = {\n",
        "                'word': token['word'],\n",
        "                'lemma': token['lemma'],\n",
        "                'pos': token['pos'],\n",
        "                'ner': token['ner']\n",
        "            }\n",
        "        return tokens\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sNLP = StanfordNLP()\n",
        "    text = 'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\n",
        "    print (\"Annotate:\", sNLP.annotate(text))\n",
        "   # print \"POS:\", sNLP.pos(text)\n",
        "    #print \"Tokens:\", sNLP.word_tokenize(text)\n",
        "    #print \"NER:\", sNLP.ner(text)\n",
        "    #print \"Parse:\", sNLP.parse(text)\n",
        "    #print \"Dep Parse:\", sNLP.dependency_parse(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before timeout\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-39919a2697ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0msNLP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'A blog post using Stanford CoreNLP Server. Visit www.khalidalnajjar.com for more details.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Annotate:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msNLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-107-39919a2697ad>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, port)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'http://localhost'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before timeout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStanfordCoreNLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                                    \u001b[0;31m#timeout=300)  , quiet=False, logging_level=logging.DEBUG)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after timeout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stanfordcorenlp/corenlp.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_host, port, memory, lang, timeout, quiet, logging_level)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_ex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Waiting until the server is available.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The server is available.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkyn4D4OPEkz",
        "colab_type": "code",
        "outputId": "6e1888a1-e27e-4e86-e0a9-ac4e21f38660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import requests\n",
        "r = requests.post('https://devopedia.org/text-summarization')\n",
        "print(r.status_code)\n",
        "print(r.text[:1000])\n",
        "\n",
        "!pip install stanza\n",
        "import stanza\n",
        "# download English model\n",
        "stanza.download('en')\n",
        "# initialize English neural pipeline\n",
        "nlp = stanza.Pipeline('en')\n",
        "# run annotation over a sentence\n",
        "doc = nlp(r.text[:1000])\n",
        "print(doc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "<!DOCTYPE HTML>\r\n",
            "<html lang=\"en-gb\" dir=\"ltr\"  data-config='{\"twitter\":0,\"plusone\":0,\"facebook\":0,\"style\":\"rainbow\"}'>\r\n",
            "\r\n",
            "<head>\r\n",
            "<meta charset=\"utf-8\">\r\n",
            "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\r\n",
            "<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\r\n",
            "<base href=\"https://devopedia.org/text-summarization\" />\n",
            "\t<meta name=\"rights\" content=\"CC BY-SA 4.0 for content. MIT License for code.\" />\n",
            "\t<meta name=\"author\" content=\"arvindpdmn\" />\n",
            "\t<meta name=\"twitter:card\" content=\"summary_large_image\" />\n",
            "\t<meta name=\"twitter:description\" content=\"On the web, everyone can be a publisher. We're already seeing vast amounts of information being published daily in the form of restaurant/movie/book reviews, blogs, status updates, and more. In addition, traditional print publications (newspapers, magazines, technical journals, whitepapers) are also available online. It's impossible for anyone to keep track of recent publications even if limited to one domain. This is where text s\n",
            "Requirement already satisfied: stanza in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.5.0+cu101)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (46.3.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.12.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.9)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 9.57MB/s]                    \n",
            "2020-05-17 11:01:59 INFO: Downloading default packages for language: en (English)...\n",
            "2020-05-17 11:02:00 INFO: File exists: /root/stanza_resources/en/default.zip.\n",
            "2020-05-17 11:02:05 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-05-17 11:02:05 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| pos       | ewt       |\n",
            "| lemma     | ewt       |\n",
            "| depparse  | ewt       |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2020-05-17 11:02:05 INFO: Use device: cpu\n",
            "2020-05-17 11:02:05 INFO: Loading: tokenize\n",
            "2020-05-17 11:02:05 INFO: Loading: pos\n",
            "2020-05-17 11:02:06 INFO: Loading: lemma\n",
            "2020-05-17 11:02:06 INFO: Loading: depparse\n",
            "2020-05-17 11:02:07 INFO: Loading: ner\n",
            "2020-05-17 11:02:08 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[\n",
            "  [\n",
            "    {\n",
            "      \"id\": \"1\",\n",
            "      \"text\": \"<!\",\n",
            "      \"lemma\": \"<!\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=0|end_char=2\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"2\",\n",
            "      \"text\": \"DOCTYPE\",\n",
            "      \"lemma\": \"doctype\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=2|end_char=9\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"3\",\n",
            "      \"text\": \"HTML\",\n",
            "      \"lemma\": \"html\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 0,\n",
            "      \"deprel\": \"root\",\n",
            "      \"misc\": \"start_char=10|end_char=14\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"4\",\n",
            "      \"text\": \">\",\n",
            "      \"lemma\": \">\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=14|end_char=15\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"5\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 7,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=17|end_char=18\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"6\",\n",
            "      \"text\": \"html\",\n",
            "      \"lemma\": \"html\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 7,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=18|end_char=22\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"7\",\n",
            "      \"text\": \"lang\",\n",
            "      \"lemma\": \"lang\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"list\",\n",
            "      \"misc\": \"start_char=23|end_char=27\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"8\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=27|end_char=28\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"9\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=28|end_char=29\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"10\",\n",
            "      \"text\": \"en\",\n",
            "      \"lemma\": \"en\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 12,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=29|end_char=31\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"11\",\n",
            "      \"text\": \"-\",\n",
            "      \"lemma\": \"-\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"HYPH\",\n",
            "      \"head\": 12,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=31|end_char=32\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"12\",\n",
            "      \"text\": \"gb\",\n",
            "      \"lemma\": \"gb\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"list\",\n",
            "      \"misc\": \"start_char=32|end_char=34\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"13\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 12,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=34|end_char=35\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"14\",\n",
            "      \"text\": \"dir=\",\n",
            "      \"lemma\": \"dir=\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 16,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=36|end_char=40\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"15\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 16,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=40|end_char=41\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"16\",\n",
            "      \"text\": \"ltr\",\n",
            "      \"lemma\": \"ltr\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"list\",\n",
            "      \"misc\": \"start_char=41|end_char=44\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"17\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=44|end_char=45\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"18\",\n",
            "      \"text\": \"data\",\n",
            "      \"lemma\": \"data\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 19,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=47|end_char=51\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"19\",\n",
            "      \"text\": \"-config\",\n",
            "      \"lemma\": \"-config\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"list\",\n",
            "      \"misc\": \"start_char=51|end_char=58\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"20\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=58|end_char=59\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"21\",\n",
            "      \"text\": \"'{\",\n",
            "      \"lemma\": \"'{\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=59|end_char=61\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"22\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=61|end_char=62\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"23\",\n",
            "      \"text\": \"twitter\",\n",
            "      \"lemma\": \"twitter\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 19,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=62|end_char=69\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"24\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=69|end_char=70\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"25\",\n",
            "      \"text\": \":\",\n",
            "      \"lemma\": \":\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \":\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=70|end_char=71\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"26\",\n",
            "      \"text\": \"0\",\n",
            "      \"lemma\": \"0\",\n",
            "      \"upos\": \"NUM\",\n",
            "      \"xpos\": \"CD\",\n",
            "      \"feats\": \"NumType=Card\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=71|end_char=72\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"27\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=72|end_char=73\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"28\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=73|end_char=74\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"29\",\n",
            "      \"text\": \"plusone\",\n",
            "      \"lemma\": \"plusone\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=74|end_char=81\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"30\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=81|end_char=82\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"31\",\n",
            "      \"text\": \":\",\n",
            "      \"lemma\": \":\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \":\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=82|end_char=83\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"32\",\n",
            "      \"text\": \"0\",\n",
            "      \"lemma\": \"0\",\n",
            "      \"upos\": \"NUM\",\n",
            "      \"xpos\": \"CD\",\n",
            "      \"feats\": \"NumType=Card\",\n",
            "      \"head\": 35,\n",
            "      \"deprel\": \"nummod\",\n",
            "      \"misc\": \"start_char=83|end_char=84\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"33\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 35,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=84|end_char=85\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"34\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 35,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=85|end_char=86\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"35\",\n",
            "      \"text\": \"facebook\",\n",
            "      \"lemma\": \"facebook\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=86|end_char=94\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"36\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 35,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=94|end_char=95\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"37\",\n",
            "      \"text\": \":\",\n",
            "      \"lemma\": \":\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \":\",\n",
            "      \"head\": 35,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=95|end_char=96\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"38\",\n",
            "      \"text\": \"0\",\n",
            "      \"lemma\": \"0\",\n",
            "      \"upos\": \"NUM\",\n",
            "      \"xpos\": \"CD\",\n",
            "      \"feats\": \"NumType=Card\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"nummod\",\n",
            "      \"misc\": \"start_char=96|end_char=97\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"39\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=97|end_char=98\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"40\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=98|end_char=99\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"41\",\n",
            "      \"text\": \"style\",\n",
            "      \"lemma\": \"style\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 35,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=99|end_char=104\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"42\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=104|end_char=105\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"43\",\n",
            "      \"text\": \":\",\n",
            "      \"lemma\": \":\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \":\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=105|end_char=106\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"44\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 45,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=106|end_char=107\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"45\",\n",
            "      \"text\": \"rainbow\",\n",
            "      \"lemma\": \"rainbow\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=107|end_char=114\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"46\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 45,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=114|end_char=115\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"47\",\n",
            "      \"text\": \"}\",\n",
            "      \"lemma\": \"}\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 45,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=115|end_char=116\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"48\",\n",
            "      \"text\": \"'>\",\n",
            "      \"lemma\": \"'>\",\n",
            "      \"upos\": \"SYM\",\n",
            "      \"xpos\": \"NFP\",\n",
            "      \"head\": 45,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=116|end_char=118\"\n",
            "    }\n",
            "  ],\n",
            "  [\n",
            "    {\n",
            "      \"id\": \"1\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=122|end_char=123\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"2\",\n",
            "      \"text\": \"head\",\n",
            "      \"lemma\": \"head\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 0,\n",
            "      \"deprel\": \"root\",\n",
            "      \"misc\": \"start_char=123|end_char=127\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"3\",\n",
            "      \"text\": \">\",\n",
            "      \"lemma\": \">\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=127|end_char=128\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"4\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 6,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=130|end_char=131\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"5\",\n",
            "      \"text\": \"meta\",\n",
            "      \"lemma\": \"meta\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 6,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=131|end_char=135\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"6\",\n",
            "      \"text\": \"charset\",\n",
            "      \"lemma\": \"charset\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=136|end_char=143\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"7\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=143|end_char=144\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"8\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=144|end_char=145\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"9\",\n",
            "      \"text\": \"u\",\n",
            "      \"lemma\": \"u\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=145|end_char=146\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"10\",\n",
            "      \"text\": \"tf\",\n",
            "      \"lemma\": \"tf\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=146|end_char=148\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"11\",\n",
            "      \"text\": \"-\",\n",
            "      \"lemma\": \"-\",\n",
            "      \"upos\": \"SYM\",\n",
            "      \"xpos\": \"SYM\",\n",
            "      \"head\": 12,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=148|end_char=149\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"12\",\n",
            "      \"text\": \"8\",\n",
            "      \"lemma\": \"8\",\n",
            "      \"upos\": \"NUM\",\n",
            "      \"xpos\": \"CD\",\n",
            "      \"feats\": \"NumType=Card\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"nmod\",\n",
            "      \"misc\": \"start_char=149|end_char=150\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"13\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=150|end_char=151\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"14\",\n",
            "      \"text\": \">\",\n",
            "      \"lemma\": \">\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=151|end_char=152\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"15\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 18,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=154|end_char=155\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"16\",\n",
            "      \"text\": \"meta\",\n",
            "      \"lemma\": \"meta\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 18,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=155|end_char=159\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"17\",\n",
            "      \"text\": \"http-equiv=\",\n",
            "      \"lemma\": \"http-equiv=\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"list\",\n",
            "      \"misc\": \"start_char=160|end_char=171\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"18\",\n",
            "      \"text\": \"\\\"X\",\n",
            "      \"lemma\": \"\\\"x\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"list\",\n",
            "      \"misc\": \"start_char=171|end_char=173\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"19\",\n",
            "      \"text\": \"-\",\n",
            "      \"lemma\": \"-\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=173|end_char=174\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"20\",\n",
            "      \"text\": \"UA-\",\n",
            "      \"lemma\": \"ua-\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=174|end_char=177\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"21\",\n",
            "      \"text\": \"Compatible\",\n",
            "      \"lemma\": \"compatible\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJ\",\n",
            "      \"feats\": \"Degree=Pos\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"amod\",\n",
            "      \"misc\": \"start_char=177|end_char=187\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"22\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=187|end_char=188\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"23\",\n",
            "      \"text\": \"content\",\n",
            "      \"lemma\": \"content\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"parataxis\",\n",
            "      \"misc\": \"start_char=189|end_char=196\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"24\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=196|end_char=197\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"25\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 26,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=197|end_char=198\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"26\",\n",
            "      \"text\": \"IE\",\n",
            "      \"lemma\": \"ie\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"parataxis\",\n",
            "      \"misc\": \"start_char=198|end_char=200\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"27\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=200|end_char=201\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"28\",\n",
            "      \"text\": \"edge\",\n",
            "      \"lemma\": \"edge\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 26,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=201|end_char=205\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"29\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 28,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=205|end_char=206\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"30\",\n",
            "      \"text\": \">\",\n",
            "      \"lemma\": \">\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 26,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=206|end_char=207\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"31\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 33,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=209|end_char=210\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"32\",\n",
            "      \"text\": \"meta\",\n",
            "      \"lemma\": \"meta\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 33,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=210|end_char=214\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"33\",\n",
            "      \"text\": \"name\",\n",
            "      \"lemma\": \"name\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"parataxis\",\n",
            "      \"misc\": \"start_char=215|end_char=219\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"34\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 33,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=219|end_char=220\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"35\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 38,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=220|end_char=221\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"36\",\n",
            "      \"text\": \"viewport\",\n",
            "      \"lemma\": \"viewport\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 38,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=221|end_char=229\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"37\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 38,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=229|end_char=230\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"38\",\n",
            "      \"text\": \"content\",\n",
            "      \"lemma\": \"content\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 33,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=231|end_char=238\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"39\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 33,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=238|end_char=239\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"40\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=239|end_char=240\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"41\",\n",
            "      \"text\": \"width\",\n",
            "      \"lemma\": \"width\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"parataxis\",\n",
            "      \"misc\": \"start_char=240|end_char=245\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"42\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=245|end_char=246\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"43\",\n",
            "      \"text\": \"device-width\",\n",
            "      \"lemma\": \"device-width\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=246|end_char=258\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"44\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 47,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=258|end_char=259\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"45\",\n",
            "      \"text\": \"initial\",\n",
            "      \"lemma\": \"initial\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJ\",\n",
            "      \"feats\": \"Degree=Pos\",\n",
            "      \"head\": 47,\n",
            "      \"deprel\": \"amod\",\n",
            "      \"misc\": \"start_char=260|end_char=267\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"46\",\n",
            "      \"text\": \"-\",\n",
            "      \"lemma\": \"-\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"HYPH\",\n",
            "      \"head\": 47,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=267|end_char=268\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"47\",\n",
            "      \"text\": \"scale\",\n",
            "      \"lemma\": \"scale\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=268|end_char=273\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"48\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=273|end_char=274\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"49\",\n",
            "      \"text\": \"1\",\n",
            "      \"lemma\": \"1\",\n",
            "      \"upos\": \"NUM\",\n",
            "      \"xpos\": \"CD\",\n",
            "      \"feats\": \"NumType=Card\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=274|end_char=275\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"50\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 49,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=275|end_char=276\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"51\",\n",
            "      \"text\": \">\",\n",
            "      \"lemma\": \">\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 49,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=276|end_char=277\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"52\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=279|end_char=280\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"53\",\n",
            "      \"text\": \"base\",\n",
            "      \"lemma\": \"base\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 41,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=280|end_char=284\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"54\",\n",
            "      \"text\": \"href\",\n",
            "      \"lemma\": \"href\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=285|end_char=289\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"55\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=289|end_char=290\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"56\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 57,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=290|end_char=291\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"57\",\n",
            "      \"text\": \"https://devopedia.org/text-summarization\",\n",
            "      \"lemma\": \"https://devopedia.org/text-summarization\",\n",
            "      \"upos\": \"X\",\n",
            "      \"xpos\": \"ADD\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=291|end_char=331\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"58\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 57,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=331|end_char=332\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"59\",\n",
            "      \"text\": \"/>\",\n",
            "      \"lemma\": \"/>\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 57,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=333|end_char=335\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"60\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 62,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=337|end_char=338\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"61\",\n",
            "      \"text\": \"meta\",\n",
            "      \"lemma\": \"meta\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 62,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=338|end_char=342\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"62\",\n",
            "      \"text\": \"name\",\n",
            "      \"lemma\": \"name\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 57,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=343|end_char=347\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"63\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 62,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=347|end_char=348\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"64\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 67,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=348|end_char=349\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"65\",\n",
            "      \"text\": \"rights\",\n",
            "      \"lemma\": \"rights\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 67,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=349|end_char=355\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"66\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 67,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=355|end_char=356\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"67\",\n",
            "      \"text\": \"content\",\n",
            "      \"lemma\": \"content\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 62,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=357|end_char=364\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"68\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 62,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=364|end_char=365\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"69\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 70,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=365|end_char=366\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"70\",\n",
            "      \"text\": \"CC\",\n",
            "      \"lemma\": \"cc\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 67,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=366|end_char=368\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"71\",\n",
            "      \"text\": \"BY\",\n",
            "      \"lemma\": \"by\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 73,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=369|end_char=371\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"72\",\n",
            "      \"text\": \"-\",\n",
            "      \"lemma\": \"-\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"HYPH\",\n",
            "      \"head\": 73,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=371|end_char=372\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"73\",\n",
            "      \"text\": \"SA\",\n",
            "      \"lemma\": \"sa\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 70,\n",
            "      \"deprel\": \"nmod\",\n",
            "      \"misc\": \"start_char=372|end_char=374\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"74\",\n",
            "      \"text\": \"4.0\",\n",
            "      \"lemma\": \"4.0\",\n",
            "      \"upos\": \"NUM\",\n",
            "      \"xpos\": \"CD\",\n",
            "      \"feats\": \"NumType=Card\",\n",
            "      \"head\": 73,\n",
            "      \"deprel\": \"nummod\",\n",
            "      \"misc\": \"start_char=375|end_char=378\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"75\",\n",
            "      \"text\": \"for\",\n",
            "      \"lemma\": \"for\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 76,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=379|end_char=382\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"76\",\n",
            "      \"text\": \"content\",\n",
            "      \"lemma\": \"content\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 70,\n",
            "      \"deprel\": \"nmod\",\n",
            "      \"misc\": \"start_char=383|end_char=390\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"77\",\n",
            "      \"text\": \".\",\n",
            "      \"lemma\": \".\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \".\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=390|end_char=391\"\n",
            "    }\n",
            "  ],\n",
            "  [\n",
            "    {\n",
            "      \"id\": \"1\",\n",
            "      \"text\": \"MIT\",\n",
            "      \"lemma\": \"MIT\",\n",
            "      \"upos\": \"PROPN\",\n",
            "      \"xpos\": \"NNP\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 0,\n",
            "      \"deprel\": \"root\",\n",
            "      \"misc\": \"start_char=392|end_char=395\"\n",
            "    }\n",
            "  ],\n",
            "  [\n",
            "    {\n",
            "      \"id\": \"1\",\n",
            "      \"text\": \"License\",\n",
            "      \"lemma\": \"license\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 0,\n",
            "      \"deprel\": \"root\",\n",
            "      \"misc\": \"start_char=396|end_char=403\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"2\",\n",
            "      \"text\": \"for\",\n",
            "      \"lemma\": \"for\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=404|end_char=407\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"3\",\n",
            "      \"text\": \"code\",\n",
            "      \"lemma\": \"code\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"nmod\",\n",
            "      \"misc\": \"start_char=408|end_char=412\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"4\",\n",
            "      \"text\": \".\",\n",
            "      \"lemma\": \".\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \".\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=412|end_char=413\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"5\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=413|end_char=414\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"6\",\n",
            "      \"text\": \"/>\",\n",
            "      \"lemma\": \"/>\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=415|end_char=417\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"7\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 9,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=419|end_char=420\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"8\",\n",
            "      \"text\": \"meta\",\n",
            "      \"lemma\": \"meta\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 9,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=420|end_char=424\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"9\",\n",
            "      \"text\": \"name\",\n",
            "      \"lemma\": \"name\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"parataxis\",\n",
            "      \"misc\": \"start_char=425|end_char=429\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"10\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 9,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=429|end_char=430\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"11\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 14,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=430|end_char=431\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"12\",\n",
            "      \"text\": \"author\",\n",
            "      \"lemma\": \"author\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 14,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=431|end_char=437\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"13\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 14,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=437|end_char=438\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"14\",\n",
            "      \"text\": \"content\",\n",
            "      \"lemma\": \"content\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 9,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=439|end_char=446\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"15\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=446|end_char=447\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"16\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 17,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=447|end_char=448\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"17\",\n",
            "      \"text\": \"arvindpdmn\",\n",
            "      \"lemma\": \"arvindpdmn\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=448|end_char=458\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"18\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 17,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=458|end_char=459\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"19\",\n",
            "      \"text\": \"/>\",\n",
            "      \"lemma\": \"/>\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 17,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=460|end_char=462\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"20\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 22,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=464|end_char=465\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"21\",\n",
            "      \"text\": \"meta\",\n",
            "      \"lemma\": \"meta\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 22,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=465|end_char=469\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"22\",\n",
            "      \"text\": \"name\",\n",
            "      \"lemma\": \"name\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"parataxis\",\n",
            "      \"misc\": \"start_char=470|end_char=474\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"23\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 22,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=474|end_char=475\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"24\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 22,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=475|end_char=476\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"25\",\n",
            "      \"text\": \"twitter\",\n",
            "      \"lemma\": \"twitter\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"parataxis\",\n",
            "      \"misc\": \"start_char=476|end_char=483\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"26\",\n",
            "      \"text\": \":\",\n",
            "      \"lemma\": \":\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \":\",\n",
            "      \"head\": 22,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=483|end_char=484\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"27\",\n",
            "      \"text\": \"card\",\n",
            "      \"lemma\": \"card\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=484|end_char=488\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"28\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=488|end_char=489\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"29\",\n",
            "      \"text\": \"content\",\n",
            "      \"lemma\": \"content\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 25,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=490|end_char=497\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"30\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=497|end_char=498\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"31\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 32,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=498|end_char=499\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"32\",\n",
            "      \"text\": \"summary_large_image\",\n",
            "      \"lemma\": \"summary_large_image\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=499|end_char=518\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"33\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 32,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=518|end_char=519\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"34\",\n",
            "      \"text\": \"/>\",\n",
            "      \"lemma\": \"/>\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 32,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=520|end_char=522\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"35\",\n",
            "      \"text\": \"<\",\n",
            "      \"lemma\": \"<\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 37,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=524|end_char=525\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"36\",\n",
            "      \"text\": \"meta\",\n",
            "      \"lemma\": \"meta\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 37,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=525|end_char=529\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"37\",\n",
            "      \"text\": \"name\",\n",
            "      \"lemma\": \"name\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 32,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=530|end_char=534\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"38\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 37,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=534|end_char=535\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"39\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"``\",\n",
            "      \"head\": 42,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=535|end_char=536\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"40\",\n",
            "      \"text\": \"twitter:description\",\n",
            "      \"lemma\": \"twitter:description\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 42,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=536|end_char=555\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"41\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 42,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=555|end_char=556\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"42\",\n",
            "      \"text\": \"content\",\n",
            "      \"lemma\": \"content\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 37,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=557|end_char=564\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"43\",\n",
            "      \"text\": \"=\",\n",
            "      \"lemma\": \"=\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 37,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=564|end_char=565\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"44\",\n",
            "      \"text\": \"\\\"\",\n",
            "      \"lemma\": \"\\\"\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"''\",\n",
            "      \"head\": 42,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=565|end_char=566\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"45\",\n",
            "      \"text\": \"On\",\n",
            "      \"lemma\": \"on\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 47,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=566|end_char=568\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"46\",\n",
            "      \"text\": \"the\",\n",
            "      \"lemma\": \"the\",\n",
            "      \"upos\": \"DET\",\n",
            "      \"xpos\": \"DT\",\n",
            "      \"feats\": \"Definite=Def|PronType=Art\",\n",
            "      \"head\": 47,\n",
            "      \"deprel\": \"det\",\n",
            "      \"misc\": \"start_char=569|end_char=572\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"47\",\n",
            "      \"text\": \"web\",\n",
            "      \"lemma\": \"web\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"obl\",\n",
            "      \"misc\": \"start_char=573|end_char=576\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"48\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=576|end_char=577\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"49\",\n",
            "      \"text\": \"everyone\",\n",
            "      \"lemma\": \"everyone\",\n",
            "      \"upos\": \"PRON\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"nsubj\",\n",
            "      \"misc\": \"start_char=578|end_char=586\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"50\",\n",
            "      \"text\": \"can\",\n",
            "      \"lemma\": \"can\",\n",
            "      \"upos\": \"AUX\",\n",
            "      \"xpos\": \"MD\",\n",
            "      \"feats\": \"VerbForm=Fin\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"aux\",\n",
            "      \"misc\": \"start_char=587|end_char=590\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"51\",\n",
            "      \"text\": \"be\",\n",
            "      \"lemma\": \"be\",\n",
            "      \"upos\": \"AUX\",\n",
            "      \"xpos\": \"VB\",\n",
            "      \"feats\": \"VerbForm=Inf\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"cop\",\n",
            "      \"misc\": \"start_char=591|end_char=593\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"52\",\n",
            "      \"text\": \"a\",\n",
            "      \"lemma\": \"a\",\n",
            "      \"upos\": \"DET\",\n",
            "      \"xpos\": \"DT\",\n",
            "      \"feats\": \"Definite=Ind|PronType=Art\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"det\",\n",
            "      \"misc\": \"start_char=594|end_char=595\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"53\",\n",
            "      \"text\": \"publisher\",\n",
            "      \"lemma\": \"publisher\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 1,\n",
            "      \"deprel\": \"parataxis\",\n",
            "      \"misc\": \"start_char=596|end_char=605\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"54\",\n",
            "      \"text\": \".\",\n",
            "      \"lemma\": \".\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \".\",\n",
            "      \"head\": 53,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=605|end_char=606\"\n",
            "    }\n",
            "  ],\n",
            "  [\n",
            "    {\n",
            "      \"id\": \"1\",\n",
            "      \"text\": \"We\",\n",
            "      \"lemma\": \"we\",\n",
            "      \"upos\": \"PRON\",\n",
            "      \"xpos\": \"PRP\",\n",
            "      \"feats\": \"Case=Nom|Number=Plur|Person=1|PronType=Prs\",\n",
            "      \"head\": 4,\n",
            "      \"deprel\": \"nsubj\",\n",
            "      \"misc\": \"start_char=607|end_char=609\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"2\",\n",
            "      \"text\": \"'re\",\n",
            "      \"lemma\": \"be\",\n",
            "      \"upos\": \"AUX\",\n",
            "      \"xpos\": \"VBP\",\n",
            "      \"feats\": \"Mood=Ind|Tense=Pres|VerbForm=Fin\",\n",
            "      \"head\": 4,\n",
            "      \"deprel\": \"aux\",\n",
            "      \"misc\": \"start_char=609|end_char=612\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"3\",\n",
            "      \"text\": \"already\",\n",
            "      \"lemma\": \"already\",\n",
            "      \"upos\": \"ADV\",\n",
            "      \"xpos\": \"RB\",\n",
            "      \"head\": 4,\n",
            "      \"deprel\": \"advmod\",\n",
            "      \"misc\": \"start_char=613|end_char=620\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"4\",\n",
            "      \"text\": \"seeing\",\n",
            "      \"lemma\": \"see\",\n",
            "      \"upos\": \"VERB\",\n",
            "      \"xpos\": \"VBG\",\n",
            "      \"feats\": \"Tense=Pres|VerbForm=Part\",\n",
            "      \"head\": 0,\n",
            "      \"deprel\": \"root\",\n",
            "      \"misc\": \"start_char=621|end_char=627\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"5\",\n",
            "      \"text\": \"vast\",\n",
            "      \"lemma\": \"vast\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJ\",\n",
            "      \"feats\": \"Degree=Pos\",\n",
            "      \"head\": 6,\n",
            "      \"deprel\": \"amod\",\n",
            "      \"misc\": \"start_char=628|end_char=632\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"6\",\n",
            "      \"text\": \"amounts\",\n",
            "      \"lemma\": \"amount\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 4,\n",
            "      \"deprel\": \"obj\",\n",
            "      \"misc\": \"start_char=633|end_char=640\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"7\",\n",
            "      \"text\": \"of\",\n",
            "      \"lemma\": \"of\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=641|end_char=643\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"8\",\n",
            "      \"text\": \"information\",\n",
            "      \"lemma\": \"information\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 6,\n",
            "      \"deprel\": \"nmod\",\n",
            "      \"misc\": \"start_char=644|end_char=655\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"9\",\n",
            "      \"text\": \"being\",\n",
            "      \"lemma\": \"be\",\n",
            "      \"upos\": \"AUX\",\n",
            "      \"xpos\": \"VBG\",\n",
            "      \"feats\": \"VerbForm=Ger\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"aux:pass\",\n",
            "      \"misc\": \"start_char=656|end_char=661\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"10\",\n",
            "      \"text\": \"published\",\n",
            "      \"lemma\": \"publish\",\n",
            "      \"upos\": \"VERB\",\n",
            "      \"xpos\": \"VBN\",\n",
            "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"acl\",\n",
            "      \"misc\": \"start_char=662|end_char=671\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"11\",\n",
            "      \"text\": \"daily\",\n",
            "      \"lemma\": \"daily\",\n",
            "      \"upos\": \"ADV\",\n",
            "      \"xpos\": \"RB\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"advmod\",\n",
            "      \"misc\": \"start_char=672|end_char=677\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"12\",\n",
            "      \"text\": \"in\",\n",
            "      \"lemma\": \"in\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 14,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=678|end_char=680\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"13\",\n",
            "      \"text\": \"the\",\n",
            "      \"lemma\": \"the\",\n",
            "      \"upos\": \"DET\",\n",
            "      \"xpos\": \"DT\",\n",
            "      \"feats\": \"Definite=Def|PronType=Art\",\n",
            "      \"head\": 14,\n",
            "      \"deprel\": \"det\",\n",
            "      \"misc\": \"start_char=681|end_char=684\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"14\",\n",
            "      \"text\": \"form\",\n",
            "      \"lemma\": \"form\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"obl\",\n",
            "      \"misc\": \"start_char=685|end_char=689\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"15\",\n",
            "      \"text\": \"of\",\n",
            "      \"lemma\": \"of\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 16,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=690|end_char=692\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"16\",\n",
            "      \"text\": \"restaurant\",\n",
            "      \"lemma\": \"restaurant\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 14,\n",
            "      \"deprel\": \"nmod\",\n",
            "      \"misc\": \"start_char=693|end_char=703\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"17\",\n",
            "      \"text\": \"/\",\n",
            "      \"lemma\": \"/\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 18,\n",
            "      \"deprel\": \"cc\",\n",
            "      \"misc\": \"start_char=703|end_char=704\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"18\",\n",
            "      \"text\": \"movie\",\n",
            "      \"lemma\": \"movie\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 16,\n",
            "      \"deprel\": \"conj\",\n",
            "      \"misc\": \"start_char=704|end_char=709\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"19\",\n",
            "      \"text\": \"/\",\n",
            "      \"lemma\": \"/\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 20,\n",
            "      \"deprel\": \"cc\",\n",
            "      \"misc\": \"start_char=709|end_char=710\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"20\",\n",
            "      \"text\": \"book\",\n",
            "      \"lemma\": \"book\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 21,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=710|end_char=714\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"21\",\n",
            "      \"text\": \"reviews\",\n",
            "      \"lemma\": \"review\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 16,\n",
            "      \"deprel\": \"conj\",\n",
            "      \"misc\": \"start_char=715|end_char=722\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"22\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 23,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=722|end_char=723\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"23\",\n",
            "      \"text\": \"blogs\",\n",
            "      \"lemma\": \"blog\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 16,\n",
            "      \"deprel\": \"conj\",\n",
            "      \"misc\": \"start_char=724|end_char=729\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"24\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 26,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=729|end_char=730\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"25\",\n",
            "      \"text\": \"status\",\n",
            "      \"lemma\": \"status\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 26,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=731|end_char=737\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"26\",\n",
            "      \"text\": \"updates\",\n",
            "      \"lemma\": \"update\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 16,\n",
            "      \"deprel\": \"conj\",\n",
            "      \"misc\": \"start_char=738|end_char=745\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"27\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=745|end_char=746\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"28\",\n",
            "      \"text\": \"and\",\n",
            "      \"lemma\": \"and\",\n",
            "      \"upos\": \"CCONJ\",\n",
            "      \"xpos\": \"CC\",\n",
            "      \"head\": 29,\n",
            "      \"deprel\": \"cc\",\n",
            "      \"misc\": \"start_char=747|end_char=750\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"29\",\n",
            "      \"text\": \"more\",\n",
            "      \"lemma\": \"more\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJR\",\n",
            "      \"feats\": \"Degree=Cmp\",\n",
            "      \"head\": 16,\n",
            "      \"deprel\": \"conj\",\n",
            "      \"misc\": \"start_char=751|end_char=755\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"30\",\n",
            "      \"text\": \".\",\n",
            "      \"lemma\": \".\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \".\",\n",
            "      \"head\": 4,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=755|end_char=756\"\n",
            "    }\n",
            "  ],\n",
            "  [\n",
            "    {\n",
            "      \"id\": \"1\",\n",
            "      \"text\": \"In\",\n",
            "      \"lemma\": \"in\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 2,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=757|end_char=759\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"2\",\n",
            "      \"text\": \"addition\",\n",
            "      \"lemma\": \"addition\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 19,\n",
            "      \"deprel\": \"obl\",\n",
            "      \"misc\": \"start_char=760|end_char=768\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"3\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 19,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=768|end_char=769\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"4\",\n",
            "      \"text\": \"traditional\",\n",
            "      \"lemma\": \"traditional\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJ\",\n",
            "      \"feats\": \"Degree=Pos\",\n",
            "      \"head\": 6,\n",
            "      \"deprel\": \"amod\",\n",
            "      \"misc\": \"start_char=770|end_char=781\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"5\",\n",
            "      \"text\": \"print\",\n",
            "      \"lemma\": \"print\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 6,\n",
            "      \"deprel\": \"compound\",\n",
            "      \"misc\": \"start_char=782|end_char=787\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"6\",\n",
            "      \"text\": \"publications\",\n",
            "      \"lemma\": \"publication\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 19,\n",
            "      \"deprel\": \"nsubj\",\n",
            "      \"misc\": \"start_char=788|end_char=800\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"7\",\n",
            "      \"text\": \"(\",\n",
            "      \"lemma\": \"(\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-LRB-\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=801|end_char=802\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"8\",\n",
            "      \"text\": \"newspapers\",\n",
            "      \"lemma\": \"newspaper\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 6,\n",
            "      \"deprel\": \"appos\",\n",
            "      \"misc\": \"start_char=802|end_char=812\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"9\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 10,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=812|end_char=813\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"10\",\n",
            "      \"text\": \"magazines\",\n",
            "      \"lemma\": \"magazine\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"conj\",\n",
            "      \"misc\": \"start_char=814|end_char=823\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"11\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 13,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=823|end_char=824\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"12\",\n",
            "      \"text\": \"technical\",\n",
            "      \"lemma\": \"technical\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJ\",\n",
            "      \"feats\": \"Degree=Pos\",\n",
            "      \"head\": 13,\n",
            "      \"deprel\": \"amod\",\n",
            "      \"misc\": \"start_char=825|end_char=834\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"13\",\n",
            "      \"text\": \"journals\",\n",
            "      \"lemma\": \"journal\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"conj\",\n",
            "      \"misc\": \"start_char=835|end_char=843\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"14\",\n",
            "      \"text\": \",\",\n",
            "      \"lemma\": \",\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \",\",\n",
            "      \"head\": 15,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=843|end_char=844\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"15\",\n",
            "      \"text\": \"whitepapers\",\n",
            "      \"lemma\": \"whitepaper\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"conj\",\n",
            "      \"misc\": \"start_char=845|end_char=856\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"16\",\n",
            "      \"text\": \")\",\n",
            "      \"lemma\": \")\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \"-RRB-\",\n",
            "      \"head\": 15,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=856|end_char=857\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"17\",\n",
            "      \"text\": \"are\",\n",
            "      \"lemma\": \"be\",\n",
            "      \"upos\": \"AUX\",\n",
            "      \"xpos\": \"VBP\",\n",
            "      \"feats\": \"Mood=Ind|Tense=Pres|VerbForm=Fin\",\n",
            "      \"head\": 19,\n",
            "      \"deprel\": \"cop\",\n",
            "      \"misc\": \"start_char=858|end_char=861\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"18\",\n",
            "      \"text\": \"also\",\n",
            "      \"lemma\": \"also\",\n",
            "      \"upos\": \"ADV\",\n",
            "      \"xpos\": \"RB\",\n",
            "      \"head\": 19,\n",
            "      \"deprel\": \"advmod\",\n",
            "      \"misc\": \"start_char=862|end_char=866\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"19\",\n",
            "      \"text\": \"available\",\n",
            "      \"lemma\": \"available\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJ\",\n",
            "      \"feats\": \"Degree=Pos\",\n",
            "      \"head\": 0,\n",
            "      \"deprel\": \"root\",\n",
            "      \"misc\": \"start_char=867|end_char=876\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"20\",\n",
            "      \"text\": \"online\",\n",
            "      \"lemma\": \"online\",\n",
            "      \"upos\": \"ADV\",\n",
            "      \"xpos\": \"RB\",\n",
            "      \"head\": 19,\n",
            "      \"deprel\": \"advmod\",\n",
            "      \"misc\": \"start_char=877|end_char=883\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"21\",\n",
            "      \"text\": \".\",\n",
            "      \"lemma\": \".\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \".\",\n",
            "      \"head\": 19,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=883|end_char=884\"\n",
            "    }\n",
            "  ],\n",
            "  [\n",
            "    {\n",
            "      \"id\": \"1\",\n",
            "      \"text\": \"It\",\n",
            "      \"lemma\": \"it\",\n",
            "      \"upos\": \"PRON\",\n",
            "      \"xpos\": \"PRP\",\n",
            "      \"feats\": \"Case=Nom|Gender=Neut|Number=Sing|Person=3|PronType=Prs\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"expl\",\n",
            "      \"misc\": \"start_char=885|end_char=887\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"2\",\n",
            "      \"text\": \"'s\",\n",
            "      \"lemma\": \"be\",\n",
            "      \"upos\": \"AUX\",\n",
            "      \"xpos\": \"VBZ\",\n",
            "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"cop\",\n",
            "      \"misc\": \"start_char=887|end_char=889\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"3\",\n",
            "      \"text\": \"impossible\",\n",
            "      \"lemma\": \"impossible\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJ\",\n",
            "      \"feats\": \"Degree=Pos\",\n",
            "      \"head\": 0,\n",
            "      \"deprel\": \"root\",\n",
            "      \"misc\": \"start_char=890|end_char=900\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"4\",\n",
            "      \"text\": \"for\",\n",
            "      \"lemma\": \"for\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 5,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=901|end_char=904\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"5\",\n",
            "      \"text\": \"anyone\",\n",
            "      \"lemma\": \"anyone\",\n",
            "      \"upos\": \"PRON\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"obl\",\n",
            "      \"misc\": \"start_char=905|end_char=911\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"6\",\n",
            "      \"text\": \"to\",\n",
            "      \"lemma\": \"to\",\n",
            "      \"upos\": \"PART\",\n",
            "      \"xpos\": \"TO\",\n",
            "      \"head\": 7,\n",
            "      \"deprel\": \"mark\",\n",
            "      \"misc\": \"start_char=912|end_char=914\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"7\",\n",
            "      \"text\": \"keep\",\n",
            "      \"lemma\": \"keep\",\n",
            "      \"upos\": \"VERB\",\n",
            "      \"xpos\": \"VB\",\n",
            "      \"feats\": \"VerbForm=Inf\",\n",
            "      \"head\": 5,\n",
            "      \"deprel\": \"acl\",\n",
            "      \"misc\": \"start_char=915|end_char=919\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"8\",\n",
            "      \"text\": \"track\",\n",
            "      \"lemma\": \"track\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 7,\n",
            "      \"deprel\": \"obj\",\n",
            "      \"misc\": \"start_char=920|end_char=925\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"9\",\n",
            "      \"text\": \"of\",\n",
            "      \"lemma\": \"of\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 11,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=926|end_char=928\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"10\",\n",
            "      \"text\": \"recent\",\n",
            "      \"lemma\": \"recent\",\n",
            "      \"upos\": \"ADJ\",\n",
            "      \"xpos\": \"JJ\",\n",
            "      \"feats\": \"Degree=Pos\",\n",
            "      \"head\": 11,\n",
            "      \"deprel\": \"amod\",\n",
            "      \"misc\": \"start_char=929|end_char=935\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"11\",\n",
            "      \"text\": \"publications\",\n",
            "      \"lemma\": \"publication\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NNS\",\n",
            "      \"feats\": \"Number=Plur\",\n",
            "      \"head\": 8,\n",
            "      \"deprel\": \"nmod\",\n",
            "      \"misc\": \"start_char=936|end_char=948\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"12\",\n",
            "      \"text\": \"even\",\n",
            "      \"lemma\": \"even\",\n",
            "      \"upos\": \"ADV\",\n",
            "      \"xpos\": \"RB\",\n",
            "      \"head\": 14,\n",
            "      \"deprel\": \"advmod\",\n",
            "      \"misc\": \"start_char=949|end_char=953\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"13\",\n",
            "      \"text\": \"if\",\n",
            "      \"lemma\": \"if\",\n",
            "      \"upos\": \"SCONJ\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 14,\n",
            "      \"deprel\": \"mark\",\n",
            "      \"misc\": \"start_char=954|end_char=956\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"14\",\n",
            "      \"text\": \"limited\",\n",
            "      \"lemma\": \"limit\",\n",
            "      \"upos\": \"VERB\",\n",
            "      \"xpos\": \"VBN\",\n",
            "      \"feats\": \"Tense=Past|VerbForm=Part\",\n",
            "      \"head\": 7,\n",
            "      \"deprel\": \"advcl\",\n",
            "      \"misc\": \"start_char=957|end_char=964\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"15\",\n",
            "      \"text\": \"to\",\n",
            "      \"lemma\": \"to\",\n",
            "      \"upos\": \"ADP\",\n",
            "      \"xpos\": \"IN\",\n",
            "      \"head\": 17,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=965|end_char=967\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"16\",\n",
            "      \"text\": \"one\",\n",
            "      \"lemma\": \"one\",\n",
            "      \"upos\": \"NUM\",\n",
            "      \"xpos\": \"CD\",\n",
            "      \"feats\": \"NumType=Card\",\n",
            "      \"head\": 17,\n",
            "      \"deprel\": \"nummod\",\n",
            "      \"misc\": \"start_char=968|end_char=971\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"17\",\n",
            "      \"text\": \"domain\",\n",
            "      \"lemma\": \"domain\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 14,\n",
            "      \"deprel\": \"obl\",\n",
            "      \"misc\": \"start_char=972|end_char=978\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"18\",\n",
            "      \"text\": \".\",\n",
            "      \"lemma\": \".\",\n",
            "      \"upos\": \"PUNCT\",\n",
            "      \"xpos\": \".\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"punct\",\n",
            "      \"misc\": \"start_char=978|end_char=979\"\n",
            "    }\n",
            "  ],\n",
            "  [\n",
            "    {\n",
            "      \"id\": \"1\",\n",
            "      \"text\": \"This\",\n",
            "      \"lemma\": \"this\",\n",
            "      \"upos\": \"PRON\",\n",
            "      \"xpos\": \"DT\",\n",
            "      \"feats\": \"Number=Sing|PronType=Dem\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"nsubj\",\n",
            "      \"misc\": \"start_char=980|end_char=984\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"2\",\n",
            "      \"text\": \"is\",\n",
            "      \"lemma\": \"be\",\n",
            "      \"upos\": \"AUX\",\n",
            "      \"xpos\": \"VBZ\",\n",
            "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"cop\",\n",
            "      \"misc\": \"start_char=985|end_char=987\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"3\",\n",
            "      \"text\": \"where\",\n",
            "      \"lemma\": \"where\",\n",
            "      \"upos\": \"ADV\",\n",
            "      \"xpos\": \"WRB\",\n",
            "      \"feats\": \"PronType=Int\",\n",
            "      \"head\": 0,\n",
            "      \"deprel\": \"root\",\n",
            "      \"misc\": \"start_char=988|end_char=993\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"4\",\n",
            "      \"text\": \"text\",\n",
            "      \"lemma\": \"text\",\n",
            "      \"upos\": \"NOUN\",\n",
            "      \"xpos\": \"NN\",\n",
            "      \"feats\": \"Number=Sing\",\n",
            "      \"head\": 3,\n",
            "      \"deprel\": \"nsubj\",\n",
            "      \"misc\": \"start_char=994|end_char=998\"\n",
            "    },\n",
            "    {\n",
            "      \"id\": \"5\",\n",
            "      \"text\": \"s\",\n",
            "      \"lemma\": \"'s\",\n",
            "      \"upos\": \"PART\",\n",
            "      \"xpos\": \"POS\",\n",
            "      \"head\": 4,\n",
            "      \"deprel\": \"case\",\n",
            "      \"misc\": \"start_char=999|end_char=1000\"\n",
            "    }\n",
            "  ]\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdIjAfw1TFo4",
        "colab_type": "code",
        "outputId": "aca54016-271e-40b2-a043-b94369b8a65c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "import requests\n",
        "r = requests.post('https://devopedia.org/text-summarization')\n",
        "print(r.status_code)\n",
        "dates11=[]\n",
        "\n",
        "#!pip install stanza\n",
        "import stanza\n",
        "# download English model\n",
        "stanza.download('en')\n",
        "# initialize English neural pipeline\n",
        "nlp = stanza.Pipeline('en', processors='tokenize, ner')\n",
        "# run annotation over html from web page\n",
        "j=1000\n",
        "while(j<=len(r.text)):\n",
        "     doc = nlp(r.text[j-1000:j])\n",
        "     for entity in doc.entities:\n",
        "       if (entity.type == 'ORG'):\n",
        "         #print(entity.type, entity.text)\n",
        "         dates11.append(entity.text)\n",
        "     j=j+1000\n",
        "print(dates11)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 9.45MB/s]                    \n",
            "2020-05-17 12:55:15 INFO: Downloading default packages for language: en (English)...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-17 12:55:16 INFO: File exists: /root/stanza_resources/en/default.zip.\n",
            "2020-05-17 12:55:22 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-05-17 12:55:22 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2020-05-17 12:55:22 INFO: Use device: cpu\n",
            "2020-05-17 12:55:22 INFO: Loading: tokenize\n",
            "2020-05-17 12:55:22 INFO: Loading: ner\n",
            "2020-05-17 12:55:22 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['MIT', 'non-Retina iPhone', 'Jurafsky', 'Jurafsky', 'IBM Science Summarizer', 'Erera', 'IBM Science Summarizer', 'IBM', 'ML', 'MDSWriter', 'Luhn', 'Edmundson', 'Radev', 'Barzilay', 'Google', 'PageRank', 'Mihalcea', 'Organisation', 'Location', 'Time', 'PageRank', 'Nallapati', 'IDF', 'Convolutional Neural Network', 'CNN', 'Google Search', 'Google', 'Google', 'Jurafsky', 'Jurafsky', 'IBM Science Summarizer', 'Erera', 'IBM Science Summarizer', 'IBM', 'ROUGE-N', 'ROUGE-L', 'ROUGE-W', 'ROUGE-SU', 'Summary Content Unit', 'TREC', 'DUC', 'TAC', 'Convolutional Neural Network', 'CNN', 'DailyMail', 'TAC', 'DUC', 'ELI5', 'WikiSum', 'Cornell Newsroom', 'MDSWriter', 'Python', 'Gensim', 'PyTeaser', 'Scala', 'Google', 'the North American Chapter of the Association for Computational Linguistics', 'Machine Learning Mastery', 'NIST', 'Das-and-Martins-2007', 'Carnegie Mellon University', 'Edmundson', 'ACM', 'Miltiadis Allamanis', 'Goldstein-et-al.-', 'Jurafsky', 'Language Processing', 'Second Edition', 'Prentice-Hall, Inc.', 'Halizah Basiron', 'Ngo Hea Choon', 'Science Publications', 'ACM SIGIR', 'the Association for Computational Linguistics', 'Google AI', 'IBM Journal of Research and Development', 'PhD Thesis', 'University of Toronto', 'Rare Technologies', 'Meyer-et-', 'Christian M.', 'ACL-2016 System Demonstrations', 'Cicero dos Santos', 'SIGNLL Conference on Computational Natural Language Learning', 'NAACL-ANLP', 'Empirical Methods in Natural Language Processing', 'Pointer-Generator Networks', 'Wong-et-', 'Student Research Workshop', 'Luhn', 'Edmundson', 'Kupiec et al.', 'Radev', 'Barzilay', 'Google', 'PageRank', 'Mihalcea', 'Organisation', 'Location', 'Time', 'PageRank', 'IDF', 'CNN', 'Language Processing', 'Second Edition', 'Prentice-Hall, Inc.', 'Das, Dipanjan', 'Carnegie Mellon University', 'Salesforce Einstein', 'Salesforce']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEqdqprgkAc_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "r = requests.post('https://devopedia.org/text-summarization')\n",
        "print(r.status_code)\n",
        "#print(r.text[:1000])\n",
        "open(\"sample_doc11.html\", 'w').write(r.text)\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "divstr= soup.find_all('div')\n",
        "\n",
        "#!pip install stanza\n",
        "import stanza\n",
        "# download English model\n",
        "stanza.download('en')\n",
        "# initialize English neural pipeline\n",
        "nlp = stanza.Pipeline('en', processors='tokenize, ner')\n",
        "# run annotation over a sentence\n",
        "j=100000\n",
        "while(j<=150000):\n",
        "#while(j<=len(r.text)):\n",
        "     doc = nlp(divstr[j-1000:j])\n",
        "     for entity in doc.entities:\n",
        "       if (entity.type == 'DATE'):\n",
        "         print(entity.type, entity.text)\n",
        "     j=j+1000\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjnZRJxxvH6W",
        "colab_type": "code",
        "outputId": "652d6c03-fcd7-4cc2-eb83-6c4894ed6aee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "import requests\n",
        "r = requests.post('https://en.wikipedia.org/wiki/Ramayana')\n",
        "print(r.status_code)\n",
        "\n",
        "#!pip install stanza\n",
        "import stanza\n",
        "# download English model\n",
        "stanza.download('en')\n",
        "# initialize English neural pipeline\n",
        "nlp = stanza.Pipeline('en', processors='tokenize, ner')\n",
        "# run annotation over html from web page\n",
        "j=1000\n",
        "PERSON_coll=[]\n",
        "ORG_coll=[]\n",
        "while(j<=len(r.text)):\n",
        "     doc = nlp(r.text[(j-1000):j])\n",
        "     for entity in doc.entities:\n",
        "       if (entity.type == 'PERSON'):\n",
        "         PERSON_coll.append(entity.text)\n",
        "       if (entity.type == 'ORG'):\n",
        "         ORG_coll.append(entity.text)\n",
        "     j=j+1000\n",
        "print(PERSON_coll)\n",
        "print(ORG_coll)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 9.52MB/s]                    \n",
            "2020-05-17 13:11:13 INFO: Downloading default packages for language: en (English)...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-17 13:11:13 INFO: File exists: /root/stanza_resources/en/default.zip.\n",
            "2020-05-17 13:11:19 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-05-17 13:11:19 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2020-05-17 13:11:19 INFO: Use device: cpu\n",
            "2020-05-17 13:11:19 INFO: Loading: tokenize\n",
            "2020-05-17 13:11:19 INFO: Loading: ner\n",
            "2020-05-17 13:11:20 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Rama', 'Valmiki', 'Rama', 'Lakshmana', 'Kali', 'Kali', 'Kali', 'Krishna', 'Lakshmi', 'Parvati', 'Radha', 'Rama', 'Rama', 'Maya', 'Aparigraha', 'Raja', 'Ashrama', 'Durga Puja', 'Raksha Bandhan', 'Adi Shankara', 'Akka Mahadevi</', 'Allama Prabhu<', 'Gangesha Upadhyaya', 'Haridasa Thakur', 'Raghavendra', 'Vachaspati Mishra', 'Mahesh Yogi', 'Ramakrishna', 'Ramana Ma', 'Ramachandra', 'Agama', 'Vishnu Purana', 'Bhaga', 'Vāmana Purana', 'Garuda Purana', 'Padma Purana', 'Shiva Purana', 'Linga Purana', 'Kūrma Purana', 'Pramana Sutras', 'Shiva Samhita', 'Rama', 'Rama', 'King', 'Sita', 'Sita', 'Sita', 'Lakshmana', 'Ravana', 'Ravana', 'Lanka', 'Ram', 'Ayodhya', 'Ayodhya', 'Ayodhy', 'Aranya', 'Kand', 'Kishkindha', 'Sundara', 'Rama', 'Rama', 'Ravana', 'Ravana', 'Sri Lanka', 'Rama', 'Philip', 'Kishkindha', 'Rama', 'Rama', 'Aayana', 'Rama', 'Treta Yuga', 'Valmiki Muni', 'Valmiki', 'Ram', 'Robert P. Goldman', 'Robert P. Goldman', 'Romesh_Chunder_Dutt', 'Romesh Chunder Dutt', 'Romesh Chunder Dutt', 'Bala Kand', 'Uttara Kand', 'Kamban', 'Budda Reddy', 'Saptakanda', 'Shri Ram Panchali', 'Rama', 'Treta Yuga', 'Rama', 'Rama', 'Treta Yuga', 'Ikshvaku', 'Rama', 'Sita', 'Janaka', 'Rama', 'Kanda', 'Bala Kanda', 'Rama', 'Bala Kand', 'Hermann Jacobi', 'Bala kanda', 'Rama', 'Sita', 'Ayodhy', 'Rama', 'Bharata', 'Lakshmana', 'Lakshmana', 'Shatrughna', 'Rama', 'Kaikeyi', 'Dasaratha', 'Dasaratha', 'Dasharatha', 'Bharata', 'Rama', 'Dasharatha', 'Rama', 'Rama', 'Vishnu', 'Dasharatha', 'Ayodhya', 'Dasharatha', 'Kaikeyi', 'Rama', 'Rama', 'Ravana', 'Sita', 'Vaidehi', 'Janaka', 'Rama', 'Rama', 'Mithila', 'Mithila', 'the Shiv Dhanush', 'Janaka', 'Sita', 'Sita', 'Lakshmi', 'Vishnu', 'Sita', 'Lanka', 'Ravana', 'Lanka', 'Lanka', 'Rama', 'Ravana', 'Bhar', 'Dasharatha', 'Queen Kaikeyi', 'Kaikeyi', 'Rama', 'Dasharatha', 'Rama', 'Rama', 'Bharata', 'Ram', 'Rama', 'Bharata', 'Rama', 'Saumitra', 'Rama', 'King Dasharatha', 'Queen Sumitra', 'Shatrughna', 'Lakshmana', 'Vishnu', 'Sita', 'Rama', 'Sita', 'Maricha', 'Rama', 'Sita', 'Ravana', 'Sita', 'Shatrughna', 'Shatrughna', 'Dasharatha', 'Queen Sumitra', 'Rama', 'Lakshmana', 'Rama Setu', 'Rama', 'Kesari', 'Sita', 'Rama', 'Sita', 'Ravana', 'Rama', 'Vali', 'Sugriva', 'Kishkindha', 'Rama', 'Sugriva', 'Sita', 'Sugriva', 'Kishkindha', 'Vali', 'Ram', 'Kishkindha', 'Sugriva', 'Rama', 'Sita', 'Ravana', 'Ravana', 'Ravana', 'Vali', 'Tara', 'Tara', 'Rama', 'Rama', 'Rama', 'Lakshmana', 'Sugriva', 'Sugriva', 'Rama', 'Sugriva', 'Rama', 'Riksharaj', 'Rikshas', 'Jambavantha', 'Rama', 'Sita', 'Ravana', 'Hanuman', 'Sita', 'Sita', 'Ravana', 'Jatayu', 'Ravana', 'Jatayu', 'Ravana', 'Rama', 'Lakshmana', 'Jatayu', 'Sita', 'Ravana', 'Aruna', 'Ravana', 'Sita', 'Rama', 'Ravana', 'Lanka', 'Lanka', 'Ram', 'Ravana', 'Lanka', 'Vishnu', 'Rama', 'Brahma', 'Ravana', 'Rama', 'Lakshmana', 'Lakshmana', 'Ravana', 'Ravana', 'Vanara', 'Rama', 'Ravana', 'Rama', 'Lakshmana', 'Shurpanakha', 'Sita', 'Rama', 'Ravana', 'Sita', 'Tataka', 'Dasharatha', 'Rama', 'Rama', 'Lakshmana', 'Subahu', 'Maricha', 'Subahu', 'Rama', 'Lanka', 'Rama', 'Tara', 'Indra', 'Vali', 'Vali', 'Vali', 'Rama', 'Rama', 'Rama', 'Rama', 'Rama', 'Rama', 'Rama', 'Rama', 'Vali', 'Sugriva', 'Rama', 'Rishi', 'Rishi', 'Tapasya', 'Rishis', 'Bharadwaja', 'Viswashrava', 'Ilavida', 'Ilavida', 'Viswashrava', 'Kubera', 'Kubera', 'Ravana', 'Viswashrava', 'Kaikesi', 'Ravana', 'Kubera', 'Kubera', 'Kubera', 'Ilavida', 'Viswashrava', 'Kubera', 'Raka', 'Kaikesi', 'Viswashrava', 'Pushpotata', 'Ravana', 'Malini', 'Vibhishana', 'Raka', 'Kanda', 'Bala Kanda', 'Dasharatha', 'Siradhvaja', 'Kushadhvaja Janakas', 'Sita', 'Lakshmana', 'Urmila', 'Bharata', 'Mandavi', 'Shatrughna', 'Rama', 'Dasharatha', 'Kaushalya', 'Kaikeyi', 'Sumitra', 'Rama', 'Bharata', 'Lakshmana', 'Shatrughna', 'Sumitra', 'Vishnu', 'Vishnu', 'Ravana', 'Ravana', 'Vash', 'Rama', 'Vishwamitra', 'Rama', 'Lakshmana', 'Rama', 'Lakshmana', 'Mithila', 'King', 'King', 'Sita', 'Sita', 'King', 'Sita', 'Sage Vishwamitra', 'Rama', 'Lakshmana', 'Rama', 'Dasharatha', 'Janaka', 'Rama', 'Sita', 'Bharata', 'Mithila', 'Mithila', 'Ayodhya', 'Rama', 'Sita', 'Dasharatha', 'Rama', 'Kaikeyi', 'Manthara', 'Dasharatha', 'Kaikeyi', 'Rama', 'Bharata', 'Kaikeyi', 'Rama', 'Sita', 'Lakshmana', 'Sita', 'Ram', 'Dasharatha', 'Bharata', 'Bharata', 'Rama', 'Rama', 'Rama', 'Rama', 'Kanda', 'Ravana', 'Jatayu', 'Sita', 'Raja Ravi Varma', 'Raja Ravi Varma', 'Rama', 'Sita', 'Lakshmana', 'Ravana', 'Sita', 'Lakshmana', 'Khara', 'Khara', 'Dushan', 'Rama', 'Khara', 'Ravana', 'Rama', 'Sita', 'Maricha', 'Maricha', 'Sita', 'Sita', 'Rama', 'Rama', 'Sita', 'Sita', 'Lakshmana', 'Sita', 'Rama', 'Lakshmana', 'Lakshmana', 'Rama', 'Ram', 'Sita', 'Rama', 'Lakshman', 'Ravana', 'Sita', 'Sita', 'Ravana', 'Sita', 'Sita', 'Ravana', 'Sita', 'Rama', 'Rama', 'Lakshmana', 'Sita', 'Jatayu', 'Kabandha', 'Kishkindha_Kanda', 'Kishkindha', 'Rama', 'Vali', 'Rama', 'Lakshmana', 'Hanuman', 'Rama', 'Kishkindha', 'Rama', 'Sugriva', 'Vali', 'Rama', 'Sita', 'Sugriva', 'Tara', 'Tara', 'Vali', 'Lakshmana', 'Sugriva', 'Sugriva', 'Jatayu', 'Sita', 'Kanda', 'Sundara Kanda', 'Sund', 'Ravana', 'Sita', 'Sundara Kand', 'Sita', 'Hanuman', 'Mainakudu', 'Hanuman', 'Sita', 'Lankini', 'Lanka', 'Hanuman', 'Lankini', 'Lanka', 'Lankini', 'Hanuman', 'Ravana', 'Sita', 'Ravana', 'Ravana', 'Hanuman', 'Sita', 'Ram', 'Sita', 'Ram', 'Ramyana', 'Hanuman', 'Rama', 'Rama', 'Ravana', 'Sita', 'Ravana', 'Hanuman', 'Sita', 'Ram', 'Rama', 'Hanuman', 'Ravana', 'Ravana', 'Ravana', 'Sita', 'Ravana', 'Rama', 'Ravana', 'Ravana', 'Lanka', 'Ram', 'Sita', 'Trisiras', 'Hanuman', 'Rama', 'Rama', 'Ravana', 'Hanuman', 'Sita', 'Rama', 'Lakshmana', 'Ravana', 'Vibhishana', 'Nala', 'Ram', 'Ravana', 'Indrajit', 'Lakshmana', 'Hanuman', 'Hanuman', 'Lakshmana', 'Rama', 'Ravana', 'Rama', 'Vibhishana', 'Lanka', 'Sita', 'Rama', 'Sita', 'Sita', 'Valmiki', 'Sita', 'Agni', 'Sita', 'Maya Sita', 'Maya Sita', 'Rama', 'Uttara Kanda', 'Uttara Kanda', 'Kakbhusundi', 'Garud', 'Tulsidas', 'Garud', 'Ram', 'Ayodhya', 'Ayodhya', 'Rama', 'Rama', 'Sita', 'Lakshmana', 'Hanuman', 'Rama', 'Hanuman', 'Rama', 'Sita', 'Rama', \"Ram-Rajya'\", 'Valmiki', 'Rama', 'Sita', 'Sita', 'Ram', 'Rama', 'Lakshmana', 'the Queen of Ayodhya', 'Sita', 'the Queen of Ayodhya', 'Lakshmana', 'Sita', 'Sita', 'Valmiki', 'Luv', 'Kush', 'Rama', 'Rama', 'Rama', 'Kusha', 'Lakshmana', 'Lakshmana', 'Lakshmana', 'Bharat', 'Shatrughan', 'Hanuman', 'Rama', 'Valmiki', 'Sita', 'Sita', 'Hanuman', 'Valmiki', 'Sita', 'Sita', 'Rama', 'Luv', 'Kush', 'Nagarsen', 'Sita', 'Sita', 'Sita', 'Bhoomidevi', 'Sita', 'Rama', 'River', 'Sarayu', 'Rama', 'Ravana', 'Rama', 'Kambar', 'Kamban', 'Rama', 'Ranganatha Ramayanam', 'Gona Budda Reddy', 'Madhava Kandali', 'Sri Ramacharit Manas', 'Sri Ramacharit Manas', 'Premanand', 'Krittibas Ojha', 'Vilanka Ramayana', 'Dandi Ramayana', 'Balarama Dasa', 'Narahari', 'Sridhara', 'Chanda', 'Jha', 'Rashtrakavi', 'Mahi Ravana', 'Ravana', 'Hanuman', 'Hanuman', 'Rama', 'Lakshmana', 'the Ahi-Mahi Ravana', 'Ravana', 'Kali', 'Kali', 'Kali', 'Sita', 'Ravana', 'Ravana', 'Ravana', 'Kambar', 'Kulasekhara Alvar', 'Ravana', 'Dasharatha Jataka', 'Dasharatha', 'Benares', 'Benares', 'Ayodhya', 'Rama', 'Rāmapaṇḍita', 'Kaushalya', 'Dasharatha', 'Lakṣmaṇa', 'Lakkhaṇa', 'Rama', 'Sumitra', 'Dasharatha', 'Sita', 'Rama', 'Kaikeyi', 'Bharata', 'Dasharatha', 'Dasharatha', 'Lakkhaṇa', 'Sita', 'Rāmapaṇḍita', 'Bud', 'Buddha', 'Sita', 'Ravana', 'Ravana', 'Rama', 'Ravisena', 'Rama', 'Gunabhadara', 'Rama', 'Ravana', 'Ravana', 'Padmanabh Jaini', 'Baladeva', 'Vasudeva', 'Krishna', 'Jain Puranas', 'Jaini', 'Acharya Bhadrabahu', 'Rama', 'Ravana', 'Rama', 'Jain Soul', 'Lakshmana', 'Ravana', 'Rama', 'Lakshmana', 'Ravana', 'Ravana', 'Tirthankara', 'Dasharatha', 'Suprabha', 'Kaikeyi', 'Aparajita', 'Padma', 'Rama', 'Sumitra', 'Narayana', 'Kaikeyi', 'Bharata', 'Suprabha', 'Shatrughna', 'Ram', 'Sita', 'Jain', 'Rama', 'Maithili', 'Sridama', 'Sita', 'Rama', 'Rama', 'Kevala Jnana', 'Kevala Jnana', 'Rama', 'Ravana', 'Lakshmana', 'Naraka', 'Ravana', 'Sita', 'Granth Sahib', 'Granth Sahib', 'Guru Granth Sahib', 'Ravana', 'Sita', 'Rama', 'Laxman', 'Guru Granth Sahib', 'Dashavatara', 'Rama', 'Ramchandra', 'Guru Granth Sahib', 'Guru Granth Sahib', 'Gobind Singh', 'Dasam Granth', 'Dasam Granth', 'Brahmanas', 'Kaal', 'Bhanubhakta Acharya', 'Bhanubhakta Acharya', 'Bhanubhakta', 'Bhanubhakta', 'Aadi Kavi<', 'Sita', 'Ravana', 'Rama', 'Sita', 'Semar', 'Gareng', 'Petruk', 'Bagong', 'Mpu Sindok', 'Valmiki', 'Ram', 'Kakawin Ramayana', 'Rama', 'Sita', 'Lakhsmana', 'Hanuman', 'Ravana', 'Kumbhak', 'Wayang Wong', 'Lakshmana', 'Rama', 'Lakshmana', 'Rama', 'Hikayat Seri Rama', 'Yama', 'Zatdaw', 'Yamayana', 'Mahar', 'Maharadia', 'Maharadia Lawana', 'Juan R. Francisco', 'Nagasura Madale', 'Francisco', 'Madale', 'Maharadia Lawana', \"Maharadia Lawana's\", 'Francisco', 'Maranao', 'Ram', 'Sita', 'Ravana', 'Mandodari', 'Vibhishana', 'Ravana', 'Ravana', 'Sita', 'Ravana', 'Hanuman', 'Robert P. Goldman', 'Ravana', 'Gona Budda', 'Reddy', 'Tulsida', 'Rama', 'Chitrakuta', 'Hanuman', 'Sita', 'Sendratari Ramayana', 'Syed Thajudeen', 'Hanuman', 'Sita', 'Hanuman Burns Lanka', 'Rama', 'Rama', 'Rama', 'Rama Chandra Series', 'Ashok Banker', 'Ashok Banker', 'Ashok Banker', 'Anand Neelakantan', 'Devdutt Pattanaik', 'Hanuman', 'Hanoman', 'Rama', 'Ravana', 'Rama', 'Sita', 'Bienvenido Lumbera', 'Salvador Bernal', 'Ryan Cayabyab', 'Alice Reyes', 'Kanch', 'Kanchana Sita', 'R. S. Manohar', 'Patel', 'Sanjay Patel', 'Sanjay Patel', 'Rama', 'Fitra Ismu Kusumo', 'William Buck', 'William Buck', 'Patel', 'Sanjay Patel', 'Sanjay Patel', 'Rama Chandra Series', 'Rama', 'Sagar', 'Ramanand Sagar', 'Ramanand Sagar', 'Ramanand Sagar', 'Khan', 'Sanjay Khan', 'Sanjay Khan', 'Ramanand Sagar', 'Ravana', 'Siya Ke Ram\"', 'Ram Siya Ke Luv Kush', 'Rama', 'Siya', 'Rama Sita', 'Rand', 'Robert Goldman', 'Sally Sutherland Goldman', 'Knut A. Jacobsen', 'William Buck</', 'Mukherjee Pandey', 'Mukherjee', 'Sahitya Akademi', 'Sahitya Akademi', 'Swami Prabhavananda', 'Abbot George Burke', 'Ajay K. Rao', 'Robert P. Goldman', 'Balakanda', 'Motilal Banarsidass', 'Gita Jnana Brahmacharini Sharanya Chaitanya', 'Rama Brings Ahalya Back', 'Rama', 'VISWASRAVAS', 'Dowson', 'Prajapati Pulastya', 'Pulastya', 'Bharadwaja', 'Idavida', 'Ilavida', 'Kuvera', 'J. A. B. van Buitenen', 'Dirk W. Lonne', 'Helmut Nespital<', 'V. V. Mirashi', 'Hari Prasad Shastri', 'Hart', 'George L', 'Heifetz', 'Hank', 'Cattanar', 'Saiva Siddhanta Works', 'Manimekhalai', 'Hooper', 'John Stirling Morley', 'The Kakawin Ramayana', 'George', 'Walter F. Vella', 'Susan Brown Cowing', 'Perbedaan Ramayana', 'Joefe B. Santarita', 'Bali Kecak', 'Sanghyang', 'Rāma', 'Donald Frazier', 'Ravi Prakash', 'M. N. Dutt', 'Ramashraya Sharma', 'Bhattacharji', 'William Buck', 'van Nooten', 'Bhatti', 'Rávana', 'Evi', 'Gauri', 'Kate Milner Rabb', 'Kate Milner', 'Srimad Valmiki Ramayanam', 'Rohman', 'Todd', 'Gabrielle', 'Sara', 'Rāmāyaṇa', 'Vālmīki', 'Krishna Sivaraman', 'Song', 'Muneo Tokunaga', 'Valmiki Ramayana', 'Desiraju Hanumanta Rao', 'K. M. K. Murthy', 'Ralph T. H. Griffith', 'M. N. Dutt', 'Jain Ramayana', 'Maurice Winternitz', 'J. L. Brockington', 'Mary Brockington', 'Rama', 'Aryan', 'Romesh Chunder Dutt', 'Shanta', 'Rama', 'Rama', 'Raja', 'Ravi Varm', 'Tara', 'Nala', 'Khara', 'Dushan', 'Narantaka-Devantaka', 'Lakshmana', 'Janaka', 'Adhyathma', 'Phra Lak', 'Rama', 'Parvati', 'Kali', 'Kali', 'Kali', 'Adi Parashakti', 'Adi Parashakti', 'Purana', 'Rama', 'Lang-sa\"']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTWj86AzxxD7",
        "colab_type": "code",
        "outputId": "b77616d6-6129-470d-aba4-63f3574e0ea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "import requests\n",
        "r = requests.post('https://en.wikipedia.org/wiki/Ramayana')\n",
        "if (r.status_code!= 200):\n",
        "  raise Exception(\"URL not accessible\")\n",
        "\n",
        "#!pip install stanza\n",
        "import stanza\n",
        "# download English model\n",
        "stanza.download('en')\n",
        "# initialize English neural pipeline\n",
        "nlp = stanza.Pipeline('en', processors='tokenize, ner')\n",
        "# run annotation over html from web page\n",
        "j=1000\n",
        "entity_coll=[]\n",
        "while(j<=3000):\n",
        "     doc = nlp(r.text[(j-1000):j])\n",
        "     #print(doc)\n",
        "     for entity in doc.entities:\n",
        "       if (entity.type == 'PERSON'):\n",
        "         #print(entity.type, entity.text)\n",
        "         entity_coll.append(entity.text)\n",
        "     j=j+1000\n",
        "print(entity_coll)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 8.19MB/s]                    \n",
            "2020-05-17 13:48:29 INFO: Downloading default packages for language: en (English)...\n",
            "2020-05-17 13:48:30 INFO: File exists: /root/stanza_resources/en/default.zip.\n",
            "2020-05-17 13:48:35 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-05-17 13:48:35 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2020-05-17 13:48:35 INFO: Use device: cpu\n",
            "2020-05-17 13:48:35 INFO: Loading: tokenize\n",
            "2020-05-17 13:48:35 INFO: Loading: ner\n",
            "2020-05-17 13:48:36 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Rama']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAmbuXo15xkb",
        "colab_type": "code",
        "outputId": "918f1729-4bfc-4ef0-e183-0b4461a5cd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "import requests\n",
        "r = requests.post('https://en.wikipedia.org/wiki/Michael_I._Jordan')\n",
        "print(r.status_code)\n",
        "\n",
        "#!pip install stanza\n",
        "import stanza\n",
        "# download English model\n",
        "stanza.download('en')\n",
        "# initialize English neural pipeline\n",
        "nlp = stanza.Pipeline('en', processors='tokenize, ner')\n",
        "# run annotation over html from web page\n",
        "j=1000\n",
        "PERSON_coll=[]\n",
        "ORG_coll=[]\n",
        "while(j<=10000):\n",
        "     doc = nlp(r.text[(j-1000):j])\n",
        "     for entity in doc.entities:\n",
        "       if (entity.type == 'PERSON'):\n",
        "         PERSON_coll.append(entity.text)\n",
        "       if (entity.type == 'ORG'):\n",
        "         ORG_coll.append(entity.text)\n",
        "     j=j+1000\n",
        "print(PERSON_coll)\n",
        "print(ORG_coll)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 116kB [00:00, 9.43MB/s]                    \n",
            "2020-05-17 13:56:45 INFO: Downloading default packages for language: en (English)...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-17 13:56:46 INFO: File exists: /root/stanza_resources/en/default.zip.\n",
            "2020-05-17 13:56:53 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2020-05-17 13:56:53 INFO: Loading these models for language: en (English):\n",
            "=========================\n",
            "| Processor | Package   |\n",
            "-------------------------\n",
            "| tokenize  | ewt       |\n",
            "| ner       | ontonotes |\n",
            "=========================\n",
            "\n",
            "2020-05-17 13:56:53 INFO: Use device: cpu\n",
            "2020-05-17 13:56:53 INFO: Loading: tokenize\n",
            "2020-05-17 13:56:53 INFO: Loading: ner\n",
            "2020-05-17 13:56:54 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['Michael I. Jordan', 'Michael I. Jordan', 'Michael Jordan', 'Michael Jordan', 'Michael Jordan', 'Michael Jordan</div', 'Michael Irwin Jordan', 'John von Neumann Medal']\n",
            "['wgCSPNonce', 'University of California, San Diego', 'the American Statistical Association', 'the Association for the Advancement of Artificial Intelligence\"', 'UC Berkeley College of Engineering', 'the Association for Computing Machinery\"', 'the United States National Academy of Sciences', 'Arts and Sciences', 'the United States National Academy of Engineering\"', 'wgRelevantPageIsProbablyEditable', 'Wikipedia', 'University of California, San Diego</td', 'National Academy of Sciences', 'AAAI', 'IJCAI Award for Research Excellence', 'University of California', 'University of California, Berkeley', 'University of California', 'University of California', 'Massachusetts Institute of Technology', 'Massachusetts Institute of Technology']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}